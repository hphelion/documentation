<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE topic PUBLIC "-//OASIS//DTD DITA Topic//EN" "topic.dtd">
<topic id="topic_fld_zzy_lt">
  <title>HP Helion <tm tmtype="reg">OpenStack</tm> 2.0: Removing a Compute Node</title>
  <body><!--Needs Work-->
  <section id="removeNodes"> The process for removing a compute node requires that you run these
      steps. Note that to run any playbooks whatsoever for cloud maintenance, you will always run
      from the deployer/lifecycle-manager node.<ol>
        <li>Disable provisioning to prevent new instances from being created on this node. </li>
        <li>If possible migrate any instances on the node to other nodes. </li>
        <li>Shut down the node or stop the nova-compute service. </li>
        <li>Delete the compute node from nova </li>
        <li>Amend servers.yml in the cloud configuration to remove entry for this node, commit the
          change and re run the config processor </li>
        <li>Remove the node from cobbler</li>
        <li>If you have availability zones configured, first remove nodes in availability zones
          steps first.</li>
      </ol>
    </section>
    
    <section id="removeAZ"><title>Remove Hosts from Host Aggregates</title> When removing a compute
      node, if availability zones have been configured, either manually or using the Nova playbook
      <b>nova-cloud-configure.yml</b>, or you have manually configured any host aggregates, then before
      executing the <codeph>service-delete</codeph> command you need to remove the host(s) being deleted from any
      host aggregates. For example: <ol>
        <li>Disable the
          service<codeblock>stack@padawan-ccp-c0-m1-mgmt:~$ nova service-disable --reason="HNOV-240 - removed" padawan-ccp-comp0002-mgmt nova-compute</codeblock><codeblock>+---------------------------+--------------+----------+--------------------+
| Host                      | Binary       | Status   | Disabled Reason    |
+---------------------------+--------------+----------+--------------------+
| padawan-ccp-comp0002-mgmt | nova-compute | disabled | HNOV-240 - removed |
+---------------------------+--------------+----------+--------------------+</codeblock></li>
        <li>Get nova service
          list<codeblock>stack@padawan-ccp-c0-m1-mgmt:~$ nova service-list</codeblock><codeblock>+----+------------------+---------------------------+----------+----------+-------+----------------------------+--------------------+
| Id | Binary           | Host                      | Zone     | Status   | State | Updated_at                 | Disabled Reason    |
+----+------------------+---------------------------+----------+----------+-------+----------------------------+--------------------+
| 1  | nova-conductor   | padawan-ccp-c1-m1-mgmt    | internal | enabled  | up    | 2015-10-12T08:46:12.000000 | -                  |
| 4  | nova-scheduler   | padawan-ccp-c1-m1-mgmt    | internal | enabled  | up    | 2015-10-12T08:46:13.000000 | -                  |
| 7  | nova-conductor   | padawan-ccp-c1-m3-mgmt    | internal | enabled  | up    | 2015-10-12T08:46:14.000000 | -                  |
| 10 | nova-conductor   | padawan-ccp-c1-m2-mgmt    | internal | enabled  | up    | 2015-10-12T08:46:12.000000 | -                  |
| 13 | nova-scheduler   | padawan-ccp-c1-m3-mgmt    | internal | enabled  | up    | 2015-10-12T08:46:13.000000 | -                  |
| 16 | nova-consoleauth | padawan-ccp-c1-m1-mgmt    | internal | enabled  | up    | 2015-10-12T08:46:14.000000 | -                  |
| 19 | nova-scheduler   | padawan-ccp-c1-m2-mgmt    | internal | enabled  | up    | 2015-10-12T08:46:13.000000 | -                  |
| 22 | nova-compute     | padawan-ccp-comp0002-mgmt | AZ2      | disabled | up    | 2015-10-12T08:46:12.000000 | HNOV-240 - removed |
| 25 | nova-compute     | padawan-ccp-comp0001-mgmt | AZ1      | enabled  | up    | 2015-10-12T08:46:11.000000 | -                  |
| 28 | nova-compute     | padawan-ccp-comp0003-mgmt | AZ3      | enabled  | up    | 2015-10-12T08:46:11.000000 | -                  |
+----+------------------+---------------------------+----------+----------+-------+----------------------------+--------------------+</codeblock></li>
        <li>Get availability
          zones<codeblock>stack@padawan-ccp-c0-m1-mgmt:~$ nova aggregate-list</codeblock><codeblock>+----+------+-------------------+
| Id | Name | Availability Zone |
+----+------+-------------------+
| 1  | AZ1  | AZ1               |
| 4  | AZ2  | AZ2               |
| 7  | AZ3  | AZ3               |
+----+------+-------------------+</codeblock></li>
        <!--  TODO missing content here -->
        <li>Check that the AZ has been
          removed:<codeblock>stack@padawan-ccp-c0-m1-mgmt:~$ nova aggregate-remove-host AZ2 padawan-ccp-comp0002-mgmt</codeblock><codeblock>Host padawan-ccp-comp0002-mgmt has been successfully removed from aggregate 4</codeblock><codeblock>+----+------+-------------------+-------+-------------------------+
| Id | Name | Availability Zone | Hosts | Metadata                |
+----+------+-------------------+-------+-------------------------+
| 4  | AZ2  | AZ2               |       | 'availability_zone=AZ2' |
+----+------+-------------------+-------+-------------------------+</codeblock></li>
        <li>Get Availability Zone aggregate
          details<codeblock>stack@padawan-ccp-c0-m1-mgmt:~$ nova aggregate-details AZ2</codeblock><codeblock>+----+------+-------------------+-------+-------------------------+
| Id | Name | Availability Zone | Hosts | Metadata                |
+----+------+-------------------+-------+-------------------------+
| 4  | AZ2  | AZ2               |       | 'availability_zone=AZ2' |
+----+------+-------------------+-------+-------------------------+</codeblock></li>
        <li>Delete service ID 22 (AZ2) and check that is deleted using <codeph>nova
          service-list</codeph><codeblock>stack@padawan-ccp-c0-m1-mgmt:~$ nova service-delete 22
stack@padawan-ccp-c0-m1-mgmt:~$ nova service-list</codeblock><codeblock>+----+------------------+---------------------------+----------+---------+-------+----------------------------+-----------------+
| Id | Binary           | Host                      | Zone     | Status  | State | Updated_at                 | Disabled Reason |
+----+------------------+---------------------------+----------+---------+-------+----------------------------+-----------------+
| 1  | nova-conductor   | padawan-ccp-c1-m1-mgmt    | internal | enabled | up    | 2015-10-12T08:47:56.000000 | -               |
| 4  | nova-scheduler   | padawan-ccp-c1-m1-mgmt    | internal | enabled | up    | 2015-10-12T08:47:53.000000 | -               |
| 7  | nova-conductor   | padawan-ccp-c1-m3-mgmt    | internal | enabled | up    | 2015-10-12T08:47:54.000000 | -               |
| 10 | nova-conductor   | padawan-ccp-c1-m2-mgmt    | internal | enabled | up    | 2015-10-12T08:47:52.000000 | -               |
| 13 | nova-scheduler   | padawan-ccp-c1-m3-mgmt    | internal | enabled | up    | 2015-10-12T08:47:53.000000 | -               |
| 16 | nova-consoleauth | padawan-ccp-c1-m1-mgmt    | internal | enabled | up    | 2015-10-12T08:47:54.000000 | -               |
| 19 | nova-scheduler   | padawan-ccp-c1-m2-mgmt    | internal | enabled | up    | 2015-10-12T08:47:53.000000 | -               |
| 25 | nova-compute     | padawan-ccp-comp0001-mgmt | AZ1      | enabled | up    | 2015-10-12T08:47:51.000000 | -               |
| 28 | nova-compute     | padawan-ccp-comp0003-mgmt | AZ3      | enabled | up    | 2015-10-12T08:47:51.000000 | -               |
+----+------------------+---------------------------+----------+---------+-------+----------------------------+-----------------+</codeblock>
        </li>
      </ol>
    </section>
    <section><title>Remove the Nodes</title>
    <ol>
    <li>For example, using a cloud administrator account first disable provisioning and then run
      <codeph>nova service-list</codeph>
      <codeblock>~$ nova service-disable --reason="HNOV-240 - removed" hlm004-ccp-comp0004-mgmt nova-compute
~$ nova service-list</codeblock>
      to see the
      result<codeblock>+----+------------------+--------------------------+----------+----------+-------+----------------------------+--------------------+
| Id | Binary           | Host                     | Zone     | Status  | State | Updated_at | Disabled Reason |
+----+------------------+--------------------------+----------+----------+-------+----------------------------+--------------------+
...
| 40 | nova-compute     | hlm004-ccp-comp0005-mgmt | nova     | enabled  | up    | 2015-09-17T10:29:53.000000 | -                  |
| 46 | nova-compute     | hlm004-ccp-comp0002-mgmt | nova     | enabled  | up    | 2015-09-17T10:29:52.000000 | -                  |
| 49 | nova-compute     | hlm004-ccp-comp0006-mgmt | nova     | enabled  | up    | 2015-09-17T10:29:53.000000 | -                  |
| 52 | nova-compute     | hlm004-ccp-comp0003-mgmt | nova     | enabled  | up    | 2015-09-17T10:29:52.000000 | -                  |
| 55 | nova-compute     | hlm004-ccp-comp0001-mgmt | nova     | enabled  | up    | 2015-09-17T10:29:56.000000 | -                  |
| 58 | nova-compute     | hlm004-ccp-comp0004-mgmt | nova     | disabled | up    | 2015-09-17T10:29:55.000000 | HNOV-240 - removed |
+----+------------------+--------------------------+----------+----------+-------+----------------------------+--------------------+</codeblock>
  </li><li>    Next, run<codeblock>~$ nova list --host=hlm004-ccp-comp0004-mgmt --all_tenants=1</codeblock>
      to see all
      tenants<codeblock>+--------------------------------------+--------+----------------------------------+--------+------------+-------------+-----------------+
| ID                                   | Name   | Tenant ID                        | Status | Task State | Power State | Networks        |
+--------------------------------------+--------+----------------------------------+--------+------------+-------------+-----------------+
| 78fdb938-a89c-4a0c-a0d4-b88f1555c3b9 | paul4d | 5e9998f1b1824ea9a3b06ad142f09ca5 | ACTIVE | -          | Running     | paul=10.10.10.7 |
+--------------------------------------+--------+----------------------------------+--------+------------+-------------+-----------------+</codeblock>
    </li><li> Now, perform the
          migration:<codeblock>~$ nova live-migration --block-migrate 78fdb938-a89c-4a0c-a0d4-b88f1555c3b9
~$ nova list --host=hlm004-ccp-comp0004-mgmt --all_tenants=1</codeblock>
          and run nova list (above) to get the
          status:<codeblock>+--------------------------------------+--------+----------------------------------+-----------+------------+-------------+-----------------+
| ID                                   | Name   | Tenant ID                        | Status    | Task State | Power State | Networks        |
+--------------------------------------+--------+----------------------------------+-----------+------------+-------------+-----------------+
| 78fdb938-a89c-4a0c-a0d4-b88f1555c3b9 | paul4d | 5e9998f1b1824ea9a3b06ad142f09ca5 | MIGRATING | migrating  | Running     | paul=10.10.10.7 |
+--------------------------------------+--------+----------------------------------+-----------+------------+-------------+-----------------+</codeblock>
        </li><li> Run nova list again
          <codeblock>~$ nova list --host=hlm004-ccp-comp0004-mgmt --all_tenants=1</codeblock> to see
          that the running instance has been
          migrated:<codeblock>+----+------+-----------+--------+------------+-------------+----------+
| ID | Name | Tenant ID | Status | Task State | Power State | Networks |
+----+------+-----------+--------+------------+-------------+----------+
+----+------+-----------+--------+------------+-------------+----------+</codeblock>
        </li><li> Log into the compute node and stop the nova service <note>The specified node "ccp-0004" (which
            is the node's 'cobbler' name) should match the desired node (hlm004-ccp-comp0004-mgmt).
            However, ccp-0004 does not necessarily match hlm004-ccp-comp0004-mgmt. This means you
            could easily power down the wrong node because, for example, ccp-0004 might actually map
            to hlm004-ccp-comp0008-mgmt. So, to ensure that you are powering down the correct node,
            you need to map from the hlm004-ccp-comp0004-mgmt system name to the matching cobbler
            name. To do so, find the IP address of hlm004-ccp-comp0004-mgmt by searching in the
              <b>/etc/hosts</b> file. Then search for IP address value in the
              <b>/home/stack/helion/my_cloud/definition/data/servers.yml</b> file and choose the
            corresponding <b>id field</b> value. That will be the cobbler ID of the node you are
            looking for.</note>
          <codeblock>~$ ssh stack@hlm004-ccp-comp0004-mgmt "sudo systemctl stop nova-compute"</codeblock>
          or shut down the node. (alternatively, you may re-image the
          node):<codeblock>~$ ssh stack@hlm004-ccp-comp0004-mgmt "sudo shutdown now"</codeblock>Alternatively,
          from the deployer, run the <b>bm-power-down.yml </b>playbook <codeblock>~$ cd ~/helion/hos/ansible
    ~/helion/hos/ansible$ ansible-playbook -i hosts/localhost bm-power-down.yml -e nodelist=cpn-0004</codeblock>
          <codeblock>PLAY [localhost] **************************************************************
    GATHERING FACTS *************************************************************** 
    ok: [localhost]
    TASK: [cobbler | get-nodelist | User-specified target list] ******************* 
    ok: [localhost]
    TASK: [cobbler | get-nodelist | Check we have targets] ************************ 
    skipping: [localhost]
    TASK: [debug var=target_nodes] ************************************************ 
    ok: [localhost] => {
    "var": {
    "target_nodes": [
    "cpn-0004"
    ]
    }
    }
    TASK: [cobbler | power-down | Power the nodes down] *************************** 
    changed: [localhost] => (item=cpn-0004)
    PLAY RECAP ******************************************************************** 
    cobbler | power-down | Power the nodes down ----------------------------- 1.48s
    cobbler | get-nodelist | User-specified target list --------------------- 0.02s
    debug var=target_nodes -------------------------------------------------- 0.01s
    cobbler | get-nodelist | Check we have targets -------------------------- 0.01s
    -------------------------------------------------------------------------------
    Total: ------------------------------------------------------------------ 3.54s
    localhost : ok=4 changed=1 unreachable=0 failed=0</codeblock>
        </li><li>Next, delete the nova compute node:
      <codeblock>~$ nova service-delete 58
~$ nova service-list</codeblock> And run nova
      service-list (above) to see that it s
      gone:<codeblock>+----+------------------+--------------------------+----------+----------+-------+----------------------------+--------------------+
| Id | Binary           | Host                     | Zone     | Status  | State | Updated_at | Disabled Reason |
+----+------------------+--------------------------+----------+----------+-------+----------------------------+--------------------+
...
| 40 | nova-compute     | hlm004-ccp-comp0005-mgmt | nova     | enabled  | up    | 2015-09-17T10:29:53.000000 | -                  |
| 46 | nova-compute     | hlm004-ccp-comp0002-mgmt | nova     | enabled  | up    | 2015-09-17T10:29:52.000000 | -                  |
| 49 | nova-compute     | hlm004-ccp-comp0006-mgmt | nova     | enabled  | up    | 2015-09-17T10:29:53.000000 | -                  |
| 52 | nova-compute     | hlm004-ccp-comp0003-mgmt | nova     | enabled  | up    | 2015-09-17T10:29:52.000000 | -                  |
| 55 | nova-compute     | hlm004-ccp-comp0001-mgmt | nova     | enabled  | up    | 2015-09-17T10:29:56.000000 | -                  |
+----+------------------+--------------------------+----------+----------+-------+----------------------------+--------------------+</codeblock>
      </li><li>Then get hypervisor status:<codeblock>~$ nova hypervisor-list</codeblock> And check that the
      node has been removed from the
      list:<codeblock>+----+--------------------------+-------+---------+
| ID | Hypervisor hostname      | State | Status  |
+----+--------------------------+-------+---------+
| 1  | hlm004-ccp-comp0005-mgmt | up    | enabled |
| 7  | hlm004-ccp-comp0002-mgmt | up    | enabled |
| 10 | hlm004-ccp-comp0006-mgmt | up    | enabled |
| 13 | hlm004-ccp-comp0003-mgmt | up    | enabled |
| 16 | hlm004-ccp-comp0001-mgmt | up    | enabled |
+----+--------------------------+-------+---------+</codeblock>
      </li><li>Then, on the deployer/lifecycle-manager node, remove the node from <b>servers.yml </b><note>Make
            sure you are removing the correct node from <b>servers.yml</b> by ensuring you remove
            the stanza that contains the IP address that matches the node to be removed.</note> Edit
            <b>servers.yml </b>to remove the entry for removed node.
          <codeblock>cd ~/helion/my_cloud/definition/data
git checkout site</codeblock>
        </li><li>Then, commit the
        change, and rerun the config
        processor:
          <codeblock>git commit -a -m "Removed node &lt;name>"
cd ~/helion/hos/ansible
ansible-playbook -i hosts/localhost config-processor-run.yml
ansible-playbook -i hosts/localhost ready-deployment.yml</codeblock>
        </li><li>There is no need to run the site.yml playbook. However you should remove the node from
      cobbler, as shown
      here:<codeblock>sudo cobbler system remove --name=&lt;node>
ansible-playbook -i hosts/localhost cobbler-deploy.yml</codeblock>
      </li></ol>
    </section>
  
  </body>
</topic>
