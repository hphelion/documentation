<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE topic PUBLIC "-//OASIS//DTD DITA Topic//EN" "topic.dtd">
<topic id="remove_node">
  <title><ph conkeyref="HOS-conrefs/product-title"/>Removing a Compute Node</title>
  <body>
    <p conkeyref="HOS-conrefs/applies-to"/>
    <note type="attention">Hyperlinks intermittently do not work in the Google Chrome browser. <xref
        href="../../helion/operations/remove_node.html" scope="external"
        format="html">Click here</xref> for a frameless version of this page where the links should
      work.</note>
    <section id="about">
      <p>You may have a need to remove a Compute node and these steps will help you achieve
        this.</p>
      <p>The steps involved are:</p>
      <ol>
        <li><xref href="remove_node.dita#remove_node/disable_provisioning">Disable Provisioning on
            the Compute Host</xref></li>
        <li><xref href="remove_node.dita#remove_node/remove_az">Remove the Compute Host from it's
            Availability Zone</xref></li>
        <li><xref href="remove_node.dita#remove_node/live_migration">Use Live Migration to Move Any
            Instances on This Host to Other Hosts</xref></li>
        <li><xref href="remove_node.dita#remove_node/shutdown_node">Shutdown or Stop the Nova
            Service on the Compute Host</xref></li>
        <li><xref href="remove_node.dita#remove_node/delete_node">Delete The Compute Host from
            Nova</xref></li>
        <li><xref href="remove_node.dita#remove_node/remove_node">Remove the Compute Host from the
            servers.yml File and Run the Configuration Processor</xref></li>
        <li><xref href="remove_node.dita#remove_node/remove_cobbler">Remove the Compute Host from
            Cobbler</xref></li>
        <li><xref href="remove_node.dita#remove_node/remove_monitoring">Remove the Compute Host from
            Monitoring</xref></li>
      </ol>
    </section>

    <section id="disable_provisioning"><title>Disable Provisioning on the Compute Host</title>
      <ol>
        <li>Get a list of the Nova services running which will provide us with the details we need
          to disable the provisionong on the Compute host you are wanting to remove: <codeblock>nova service-list</codeblock>
          <p>Here is an example below. I've highlighted the Compute node we are going to remove in
            the examples:</p>
          <codeblock>$ nova service-list
+----+------------------+--------------------------+----------+---------+-------+----------------------------+-----------------+
| Id | Binary           | Host                     | Zone     | Status  | State | Updated_at                 | Disabled Reason |
+----+------------------+--------------------------+----------+---------+-------+----------------------------+-----------------+
| 1  | nova-conductor   | helion-cp1-c1-m1-mgmt    | internal | enabled | up    | 2015-11-22T22:50:43.000000 | -               |
| 10 | nova-scheduler   | helion-cp1-c1-m1-mgmt    | internal | enabled | up    | 2015-11-22T22:50:34.000000 | -               |
| 13 | nova-conductor   | helion-cp1-c1-m3-mgmt    | internal | enabled | up    | 2015-11-22T22:50:43.000000 | -               |
| 16 | nova-conductor   | helion-cp1-c1-m2-mgmt    | internal | enabled | up    | 2015-11-22T22:50:43.000000 | -               |
| 25 | nova-consoleauth | helion-cp1-c1-m1-mgmt    | internal | enabled | up    | 2015-11-22T22:50:38.000000 | -               |
| 28 | nova-scheduler   | helion-cp1-c1-m2-mgmt    | internal | enabled | up    | 2015-11-22T22:50:38.000000 | -               |
| 31 | nova-scheduler   | helion-cp1-c1-m3-mgmt    | internal | enabled | up    | 2015-11-22T22:50:42.000000 | -               |
| 34 | nova-compute     | helion-cp1-comp0001-mgmt | AZ1      | enabled | up    | 2015-11-22T22:50:35.000000 | -               |
<b>| 37 | nova-compute     | helion-cp1-comp0002-mgmt | AZ2      | enabled | up    | 2015-11-22T22:50:44.000000 | -               |</b>
+----+------------------+--------------------------+----------+---------+-------+----------------------------+-----------------+</codeblock></li>
        <li>Disable the Nova service on the Compute node you are wanting to remove which will ensure
          it is taken out of the scheduling rotation: <codeblock>nova service-disable --reason "&lt;enter reason here>" &lt;node hostname> nova-compute</codeblock>
          <p>Here is an example if I wanted to remove the <codeph>helion-cp1-comp0002-mgmt</codeph>
            in the output above:</p>
          <codeblock>$ nova service-disable --reason "hardware reallocation" helion-cp1-comp0002-mgmt nova-compute
+--------------------------+--------------+----------+-----------------------+
| Host                     | Binary       | Status   | Disabled Reason       |
+--------------------------+--------------+----------+-----------------------+
| helion-cp1-comp0002-mgmt | nova-compute | disabled | hardware reallocation |
+--------------------------+--------------+----------+-----------------------+</codeblock></li>
      </ol>
    </section>
    <section id="remove_az"><title>Remove the Compute Host from it's Availability Zone</title>
      <p>If you configured the Compute host to be part of an availability zone, these steps will
        show you how to remove it.</p>
      <ol>
        <li>Get a list of the Nova services running which will provide us with the details we need
          to remove a Compute node: <codeblock>nova service-list</codeblock>
          <p>Here is an example below. I've highlighted the Compute node we are going to remove in
            the examples:</p>
          <codeblock>$ nova service-list
+----+------------------+--------------------------+----------+---------+-------+----------------------------+-----------------------+
| Id | Binary           | Host                     | Zone     | Status  | State | Updated_at                 | Disabled Reason       |
+----+------------------+--------------------------+----------+---------+-------+----------------------------+-----------------------+
| 1  | nova-conductor   | helion-cp1-c1-m1-mgmt    | internal | enabled | up    | 2015-11-22T22:50:43.000000 | -                     |
| 10 | nova-scheduler   | helion-cp1-c1-m1-mgmt    | internal | enabled | up    | 2015-11-22T22:50:34.000000 | -                     |
| 13 | nova-conductor   | helion-cp1-c1-m3-mgmt    | internal | enabled | up    | 2015-11-22T22:50:43.000000 | -                     |
| 16 | nova-conductor   | helion-cp1-c1-m2-mgmt    | internal | enabled | up    | 2015-11-22T22:50:43.000000 | -                     |
| 25 | nova-consoleauth | helion-cp1-c1-m1-mgmt    | internal | enabled | up    | 2015-11-22T22:50:38.000000 | -                     |
| 28 | nova-scheduler   | helion-cp1-c1-m2-mgmt    | internal | enabled | up    | 2015-11-22T22:50:38.000000 | -                     |
| 31 | nova-scheduler   | helion-cp1-c1-m3-mgmt    | internal | enabled | up    | 2015-11-22T22:50:42.000000 | -                     |
| 34 | nova-compute     | helion-cp1-comp0001-mgmt | AZ1      | enabled | up    | 2015-11-22T22:50:35.000000 | -                     |
<b>| 37 | nova-compute     | helion-cp1-comp0002-mgmt | AZ2      | enabled | up    | 2015-11-22T22:50:44.000000 | hardware reallocation |</b>
+----+------------------+--------------------------+----------+---------+-------+----------------------------+-----------------------+</codeblock></li>
        <li>You can remove the Compute host from the availability zone it was a part of with this
          command: <codeblock>nova aggregate-remove-host &lt;availability zone> &lt;nova hostname></codeblock>
          <p>So for the same example as the previous step, the
              <codeph>helion-cp1-comp0002-mgmt</codeph> host was in the <codeph>AZ2</codeph>
            availability zone so I would use this command to remove it:</p>
          <codeblock>$ nova aggregate-remove-host AZ2 helion-cp1-comp0002-mgmt
Host helion-cp1-comp0002-mgmt has been successfully removed from aggregate 4
+----+------+-------------------+-------+-------------------------+
| Id | Name | Availability Zone | Hosts | Metadata                |
+----+------+-------------------+-------+-------------------------+
| 4  | AZ2  | AZ2               |       | 'availability_zone=AZ2' |
+----+------+-------------------+-------+-------------------------+</codeblock></li>
        <li>You can confirm the last two steps completed successfully by running another
            <codeph>nova service-list</codeph>. <p>Here is an example which confirms that the node
            has been disabled and that it has been removed from the availability zone. I have
            highlighted these:</p>
          <codeblock>$ nova service-list
+----+------------------+--------------------------+----------+----------+-------+----------------------------+-----------------------+
| Id | Binary           | Host                     | Zone     | Status   | State | Updated_at                 | Disabled Reason       |
+----+------------------+--------------------------+----------+----------+-------+----------------------------+-----------------------+
| 1  | nova-conductor   | helion-cp1-c1-m1-mgmt    | internal | enabled  | up    | 2015-11-22T23:04:33.000000 | -                     |
| 10 | nova-scheduler   | helion-cp1-c1-m1-mgmt    | internal | enabled  | up    | 2015-11-22T23:04:34.000000 | -                     |
| 13 | nova-conductor   | helion-cp1-c1-m3-mgmt    | internal | enabled  | up    | 2015-11-22T23:04:33.000000 | -                     |
| 16 | nova-conductor   | helion-cp1-c1-m2-mgmt    | internal | enabled  | up    | 2015-11-22T23:04:33.000000 | -                     |
| 25 | nova-consoleauth | helion-cp1-c1-m1-mgmt    | internal | enabled  | up    | 2015-11-22T23:04:28.000000 | -                     |
| 28 | nova-scheduler   | helion-cp1-c1-m2-mgmt    | internal | enabled  | up    | 2015-11-22T23:04:28.000000 | -                     |
| 31 | nova-scheduler   | helion-cp1-c1-m3-mgmt    | internal | enabled  | up    | 2015-11-22T23:04:32.000000 | -                     |
| 34 | nova-compute     | helion-cp1-comp0001-mgmt | AZ1      | enabled  | up    | 2015-11-22T23:04:25.000000 | -                     |
<b>| 37 | nova-compute     | helion-cp1-comp0002-mgmt | nova     | disabled | up    | 2015-11-22T23:04:34.000000 | hardware reallocation |</b>
+----+------------------+--------------------------+----------+----------+-------+----------------------------+-----------------------+</codeblock></li>
      </ol>
    </section>
    <section id="live_migration"><title>Use Live Migration to Move Any Instances on This Host to
        Other Hosts</title>
      <ol>
        <li>You will need to verify if the Compute node is currently hosting any instances on it.
          You can do this with the command below: <codeblock>nova list --host=&lt;nova hostname> --all_tenants=1</codeblock>
          <p>Here is an example below which shows that we have a single running instance on this
            node currently:</p>
          <codeblock>$ nova list --host=helion-cp1-comp0002-mgmt --all_tenants=1
+--------------------------------------+--------+----------------------------------+--------+------------+-------------+-----------------+
| ID                                   | Name   | Tenant ID                        | Status | Task State | Power State | Networks        |
+--------------------------------------+--------+----------------------------------+--------+------------+-------------+-----------------+
| 78fdb938-a89c-4a0c-a0d4-b88f1555c3b9 | paul4d | 5e9998f1b1824ea9a3b06ad142f09ca5 | ACTIVE | -          | Running     | paul=10.10.10.7 |
+--------------------------------------+--------+----------------------------------+--------+------------+-------------+-----------------+</codeblock></li>
        <li>You will likely want to migrate this instance off of this node before removing it. You
          can do this with the live migration functionality within Nova. The command will look like
          this: <codeblock>nova live-migration --block-migrate &lt;nova instance ID></codeblock>
          <p>Here is an example using the instance in the previous step:</p>
          <codeblock>$ nova live-migration --block-migrate 78fdb938-a89c-4a0c-a0d4-b88f1555c3b9</codeblock>
          <p>You can check the status of the migration using the same command from the previous
            step:</p>
          <codeblock>$ nova list --host=helion-cp1-comp0002-mgmt --all_tenants=1
+--------------------------------------+--------+----------------------------------+-----------+------------+-------------+-----------------+
| ID                                   | Name   | Tenant ID                        | Status    | Task State | Power State | Networks        |
+--------------------------------------+--------+----------------------------------+-----------+------------+-------------+-----------------+
| 78fdb938-a89c-4a0c-a0d4-b88f1555c3b9 | paul4d | 5e9998f1b1824ea9a3b06ad142f09ca5 | MIGRATING | migrating  | Running     | paul=10.10.10.7 |
+--------------------------------------+--------+----------------------------------+-----------+------------+-------------+-----------------+</codeblock>
        </li>
        <li> Run nova list again
          <codeblock>$ nova list --host=helion-cp1-comp0002-mgmt --all_tenants=1</codeblock> to see
          that the running instance has been
          migrated:<codeblock>+----+------+-----------+--------+------------+-------------+----------+
| ID | Name | Tenant ID | Status | Task State | Power State | Networks |
+----+------+-----------+--------+------------+-------------+----------+
+----+------+-----------+--------+------------+-------------+----------+</codeblock>
        </li>
      </ol>
    </section>
    <section id="shutdown_node"><title>Shutdown or Stop the Nova Service on the Compute Host</title>
      <p>To do this step you have a few options. You can SSH to the Compute host and run the
        following commands:</p>
      <codeblock>sudo systemctl stop nova-compute
sudo shutdown now</codeblock>
      <p>OR</p>
      <p>From the lifecycle manager you can use the <codeph>bm-power-down.yml</codeph> playbook to
        shut the node down:</p>
      <codeblock>cd ~/helion/hos/ansible
ansible-playbook -i hosts/localhost bm-power-down.yml -e nodelist=&#60;node name></codeblock>
      <note>The <codeph>&#60;node name></codeph> value will be the value corresponding to this node
        in Cobbler. You can run <codeph>sudo cobbler system list</codeph> to retrieve these
        names.</note>
    </section>
    <section id="delete_node"><title>Delete The Compute Host from Nova</title>
      <p>Retrieve the list of Nova services:</p>
      <codeblock>nova service-list</codeblock>
      <p>Here is an example highlighting the Compute host we're going to remove:</p>
      <codeblock>$ nova service-list
+----+------------------+--------------------------+----------+----------+-------+----------------------------+-----------------------+
| Id | Binary           | Host                     | Zone     | Status   | State | Updated_at                 | Disabled Reason       |
+----+------------------+--------------------------+----------+----------+-------+----------------------------+-----------------------+
| 1  | nova-conductor   | helion-cp1-c1-m1-mgmt    | internal | enabled  | up    | 2015-11-22T23:04:33.000000 | -                     |
| 10 | nova-scheduler   | helion-cp1-c1-m1-mgmt    | internal | enabled  | up    | 2015-11-22T23:04:34.000000 | -                     |
| 13 | nova-conductor   | helion-cp1-c1-m3-mgmt    | internal | enabled  | up    | 2015-11-22T23:04:33.000000 | -                     |
| 16 | nova-conductor   | helion-cp1-c1-m2-mgmt    | internal | enabled  | up    | 2015-11-22T23:04:33.000000 | -                     |
| 25 | nova-consoleauth | helion-cp1-c1-m1-mgmt    | internal | enabled  | up    | 2015-11-22T23:04:28.000000 | -                     |
| 28 | nova-scheduler   | helion-cp1-c1-m2-mgmt    | internal | enabled  | up    | 2015-11-22T23:04:28.000000 | -                     |
| 31 | nova-scheduler   | helion-cp1-c1-m3-mgmt    | internal | enabled  | up    | 2015-11-22T23:04:32.000000 | -                     |
| 34 | nova-compute     | helion-cp1-comp0001-mgmt | AZ1      | enabled  | up    | 2015-11-22T23:04:25.000000 | -                     |
<b>| 37 | nova-compute     | helion-cp1-comp0002-mgmt | nova     | disabled | up    | 2015-11-22T23:04:34.000000 | hardware reallocation |</b>
+----+------------------+--------------------------+----------+----------+-------+----------------------------+-----------------------+</codeblock>
      <p>Delete the host from Nova using the command below:</p>
      <codeblock>nova service-delete &lt;service ID></codeblock>
      <p>Following our example above, you would use:</p>
      <codeblock>nova service-delete 37</codeblock>
      <p>Use the command below to confirm that the Compute host has been completely removed from
        Nova:</p>
      <codeblock>nova hypervisor-list</codeblock>
    </section>
    <section id="remove_node"><title>Remove the Compute Host from the servers.yml File and Run the
        Configuration Processor</title>
      <p>Complete these steps from the lifecycle manager to remove the Compute node:</p>
      <ol>
        <li>Log in to the lifecycle manager</li>
        <li>Edit your <codeph>servers.yml</codeph> file in the location below to remove references
          to the Compute node(s) you want to remove:
          <codeblock>~/helion/my_cloud/definition/data/servers.yml</codeblock></li>
        <li>You may also need to edit your <codeph>control_plane.yml</codeph> file to update the
          values for <codeph>member-count</codeph>, <codeph>min-count</codeph>, and
            <codeph>max-count</codeph> if you used those to ensure they reflect the proper number of
          nodes you are using. <p>See <xref href="../input_model.dita#input_model/co_controlplane"
              >Input Model - Control Plane</xref> for more details.</p></li>
        <li>Commit the changes to git:
          <codeblock>git commit -a -m "Remove node &lt;name>"</codeblock></li>
        <li>Run the configuration processor: <codeblock>cd ~/helion/hos/ansible
ansible-playbook -i hosts/localhost config-processor-run.yml</codeblock>
          <p>You may want to use the <codeph>remove_deleted_servers</codeph> and
              <codeph>free_unused_addresses</codeph> switches to free up the resources when running
            the configuration processor. See <xref
              href="../input_model.dita#input_model/persisteddata">Persisted Data</xref> for more
            details.</p>
          <codeblock>ansible-playbook -i hosts/localhost config-processor-run.yml -e remove_deleted_servers="y" -e free_unused_addresses="y"</codeblock></li>
        <li>Run the ready deployment playbook:
          <codeblock>cd ~/helion/hos/ansible
ansible-playbook -i hosts/localhost ready-deployment.yml</codeblock>
        </li>
      </ol>
    </section>
    <section id="remove_cobbler"><title>Remove the Compute Host from Cobbler</title>
      <p>Complete these steps to remove the node from Cobbler:</p>
      <ol>
        <li>Confirm the system name in Cobbler with this command:
          <codeblock>sudo cobbler system list</codeblock></li>
        <li>Remove the system from Cobbler using this command:
          <codeblock>sudo cobbler system remove --name=&lt;node></codeblock></li>
        <li>Run the <codeph>cobbler-deploy.yml</codeph> playbook to complete the process:
          <codeblock>cd ~/helion/hos/ansible
ansible-playbook -i hosts/localhost cobbler-deploy.yml</codeblock></li>
      </ol>
    </section>
    <section id="remove_monitoring"><title>Remove the Compute Host from Monitoring</title>
      <p>Once you have removed the Compute nodes, the alarms against them will trigger so there are
        additional steps to take to resolve this issue.</p>
      <p>You will want to SSH to each of the Monasca API servers and edit the
          <codeph>/etc/monasca/agent/conf.d/host_alive.yaml</codeph> file to remove references to
        the Compute node you removed. This will require <codeph>sudo</codeph> access. The entries
        will look similar to the one below:</p>
      <codeblock>
- alive_test: ping
  built_by: HostAlive
  host_name: helion-cp1-comp0001-mgmt
  name: helion-cp1-comp0001-mgmt ping</codeblock>
      <p>Once you have removed the references on each of your Monasca API servers you then need to
        restart the Monasca Agent on each of those servers with this command:</p>
      <codeblock>sudo service monasca-agent restart</codeblock>
      <p>With the Compute node references removed and the Monasca Agent restarted, you can then
        delete the corresponding alarm to finish this process. To do so we recommend using the
        Monasca CLI which should be installed on each of your Monasca API servers by default:</p>
      <codeblock>monasca alarm-list --metric-name host_alive_status --metric-dimensions hostname=&#60;compute node deleted></codeblock>
      <p>For example, if your Compute node looked like the example above then you would use this
        command to get the alarm ID:</p>
      <codeblock>monasca alarm-list --metric-name host_alive_status --metric-dimensions hostname=helion-cp1-comp0001-mgmt</codeblock>
      <p>You can then delete the alarm with this command:</p>
      <codeblock>monasca alarm-delete &#60;alarm ID></codeblock>
    </section>
  </body>
</topic>
