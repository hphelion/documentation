<?xml version="1.0" encoding="UTF-8"?>
<!--This work by HPE Helion Openstack is licensed under a Creative Commons Attribution-ShareAlike 3.0 Unported License. See the accompanying LICENSE file for more information.-->
<!DOCTYPE concept PUBLIC "-//OASIS//DTD DITA Concept//EN" "concept.dtd">
<concept id="input_model">
  <title>HPE Helion <tm tmtype="reg">OpenStack</tm> 2.0: Input Model</title>
  <conbody>
    <section id="toc"><title>Table of Contents</title>
      <ul>
        <li><xref href="#input_model/introduction">Introduction</xref></li>
        <li><xref href="#input_model/concepts">HPE Helion OpenStack 2.0 Concepts</xref>
          <ul>
            <li><xref href="#input_model/cloud">Cloud</xref></li>
            <li><xref href="#input_model/controlplanes">Control Planes</xref>
              <ul>
                <li><xref href="#input_model/controlplanes_regions">Control Planes and
                    Regions</xref></li>
              </ul></li>
            <li><xref href="#input_model/services">Services</xref></li>
            <li><xref href="#input_model/serverroles">Server Roles</xref></li>
            <li><xref href="#input_model/diskmodel">Disk Model</xref></li>
            <li><xref href="#input_model/servers">Servers</xref></li>
            <li><xref href="#input_model/servergroups">Server Groups</xref>
              <ul>
                <li><xref href="#input_model/servergroups_failurezones">Server Groups and Failure
                    Zones</xref></li>
                <li><xref href="#input_model/servergroups_networks">Server Groups and
                    Networks</xref></li>
              </ul></li>
            <li><xref href="#input_model/networking">Networking</xref>
              <ul>
                <li><xref href="#input_model/networkgroups">Network Groups</xref>
                  <ul>
                    <li><xref href="#input_model/loadbalancers">Load Balancers</xref></li>
                    <li><xref href="#input_model/networktags">Network Tags</xref></li>
                  </ul></li>
                <li><xref href="#input_model/networks">Networks</xref></li>
                <li><xref href="#input_model/interfacemodel">Interface Model</xref></li>
                <li><xref href="#input_model/nicmapping">NIC Mapping</xref></li>
                <li><xref href="#input_model/firewallconfiguration">Firewall
                  Configuration</xref></li>
              </ul></li>
          </ul></li>
        <li><xref href="#input_model/configurationobjects">HPE Helion OpenStack 2.0 Configuration
            Objects</xref>
          <ul>
            <li><xref href="#input_model/co_cloud">Cloud</xref></li>
            <li><xref href="#input_model/co_controlplane">Control Plane</xref>
              <ul>
                <li><xref href="#input_model/co_clusters">Clusters</xref></li>
                <li><xref href="#input_model/co_resources">Resources</xref></li>
              </ul></li>
            <li><xref href="#input_model/co_servers">Servers</xref></li>
            <li><xref href="#input_model/co_servergroups">Server Groups</xref></li>
            <li><xref href="#input_model/co_serverroles">Server Roles</xref></li>
            <li><xref href="#input_model/co_diskmodels">Disk Models</xref>
              <ul>
                <li><xref href="#input_model/co_volumegroups">Volume Groups</xref></li>
                <li><xref href="#input_model/co_devicegroups">Device Groups</xref></li>
              </ul></li>
            <li><xref href="#input_model/co_interfacemodels">Interface Models</xref>
              <ul>
                <li><xref href="#input_model/co_bonddata">Bond Data</xref></li>
              </ul></li>
            <li><xref href="#input_model/co_nicmappings">NIC Mappings</xref></li>
            <li><xref href="#input_model/co_networkgroups">Network Groups</xref>
              <ul>
                <li><xref href="#input_model/co_networktags">Network Tags</xref></li>
              </ul></li>
            <li><xref href="#input_model/co_networks">Networks</xref></li>
            <li><xref href="#input_model/co_firewallrules">Firewall Rules</xref>
              <ul>
                <li><xref href="#input_model/co_rule">Rule</xref></li>
              </ul></li>
            <li><xref href="#input_model/passthrough">Passthrough</xref></li>
          </ul></li>
        <li><xref href="#input_model/othertopics">Other Topics</xref>
          <ul>
            <li><xref href="#input_model/namegeneration">Name Generation</xref>
              <ul>
                <li><xref href="#input_model/o_clusters"> Clusters</xref></li>
                <li><xref href="#input_model/o_resourcenodes">Resource Nodes</xref></li>
              </ul></li>
            <li><xref href="#input_model/persisteddata">Persisted Data</xref>
              <ul>
                <li><xref href="#input_model/persistedserverallocations">Persisted Server
                    Allocations</xref></li>
                <li><xref href="#input_model/persistedaddressallocations">Persisted Address
                    Allocations</xref></li>
              </ul></li>
            <li><xref href="#input_model/serverallocation">Server Allocation</xref></li>
            <li><xref href="#input_model/servernetworkselection">Server Network
              Selection</xref></li>
            <li><xref href="#input_model/networkroutevalidation">Network Route
              Validation</xref></li>
            <li><xref href="#input_model/configneutronprovidervlans">Configuring Neutron Provider
                VLANs</xref></li>
          </ul></li>
        <li><xref href="#input_model/cpinfofiles">Configuration Processor Information Files</xref>
          <ul>
            <li><xref href="#input_model/address_info_yml">Address_info.yml</xref></li>
            <li><xref href="#input_model/firewall_info_yml">Firewall_info.yml</xref></li>
            <li><xref href="#input_model/net_info_yml">Net_info.yml</xref></li>
            <li><xref href="#input_model/route_info_yml">Route_info.yml</xref></li>
            <li><xref href="#input_model/server_info_yml">Server_info.yml</xref></li>
            <li><xref href="#input_model/service_info_yml">Service_info.yml</xref></li>
            <li><xref href="#input_model/explain_txt">Explain.txt</xref></li>
            <li><xref href="#input_model/clouddiagram_txt">CloudDiagram.txt</xref></li>
          </ul></li>
      </ul>
    </section>
    <section id="introduction"><title>Introduction</title>
      <p>This document describes how the HPE Helion OpenStack input model can be used to define and
        configure the cloud.</p>
      <p>HPE Helion OpenStack ships with a set of example input models that can be used as starting
        points for defining a custom cloud.</p>
      <p>The input model allows you, the cloud administrator, to describe the cloud configuration in
        terms of:</p>
      <ul>
        <li>Which OpenStack services run on which server nodes</li>
        <li>How individual servers are configured in terms of disk and network adapters</li>
        <li>The overall network configuration of the cloud</li>
        <li>Network traffic separation</li>
        <li>CIDR and VLAN assignments</li>
      </ul>
      <p>The input model is consumed by the Configuration Processor which parses and validates the
        input model and outputs the effective configuration that will be deployed to each server
        that makes up your cloud.</p>
      <p>The document is structured as follows:</p>
      <ul>
        <li><uicontrol>Concepts</uicontrol> - This explains the ideas behind the declarative model
          approach used in HPE Helion OpenStack 2.0 and the core concepts used in describing that
          model</li>
        <li><uicontrol>Input Model</uicontrol> - This section provides a description of each of the
          configuration entities in the input model</li>
        <li><uicontrol>Core Examples</uicontrol> - In this section we provide samples and
          definitions of some of the more important configuration entities</li>
      </ul>
    </section>
    <section id="concepts"><title>HPE Helion OpenStack 2.0 Concepts</title>
      <p>An HPE Helion OpenStack 2.0 cloud is defined by a declarative model that is described in a
        series of configuration objects. These configuration objects are represented in YAML files
        which together constitute the various example configurations provided as templates with this
        release. These examples can be used nearly unchanged, with the exception of necessary
        changes to IP addresses and other site and hardware-specific identifiers. Alternatively, the
        examples may be customized to meet site requirements.</p>
      <p>The following diagram shows the set of configuration objects and their relationships. All
        objects have a name that you may set to be something meaningful for your context. In the
        examples these names are provided in capital letters as a convention. These names have no
        significance to HPE Helion OpenStack, rather it is the relationships between them that
        define the configuration.</p>
      <p><image href="../media/inputmodel/hphelionopenstack_concepts.png"/></p>
      <p><xref href="../media/inputmodel/hphelionopenstack_concepts_lg.png" scope="external"
          format="html">Download a high-res version</xref></p>
      <p>The Configuration Processor reads and validates the input model described in the YAML files
        discussed above, combines it with the service definitions provided by HPE Helion OpenStack
        and any persisted state information about the current deployment to produce a set of Ansible
        variables that can be used to deploy the cloud. It also produces a set of information files
        that provide details about the configuration.</p>
      <p>The relationship between the file systems on the HPE Helion OpenStack deployment server and
        the Configuration Processor is shown in the following diagram. Below the line are the
        directories that you, the cloud administrator, interact with. Above the line are the
        directories that are maintained by HPE Helion OpenStack.</p>
      <p><image href="../media/inputmodel/hphelionopenstack_directories.png"/></p>
      <p><xref href="../media/inputmodel/hphelionopenstack_directories_lg.png" scope="external"
          format="html">Download a high-res version</xref></p>
      <p>The input model is read from the <codeph>~/helion/my_cloud/definition</codeph> directory.
        Although the supplied examples use separate files for each type of object in the model, the
        names and layout of the files have no significance to the Configuration Processor, it simply
        reads all of the .yml files in this directory. Cloud administrators are therefore free to
        use whatever structure is best for their context. For example, you may decide to maintain
        separate files or sub-directories for each physical rack of servers.</p>
      <p>As mentioned, the examples use the conventional upper casing for object names, but these
        strings are used only to define the relationship between objects. They have no specific
        significance to the Configuration Processor.</p>
    </section>
    <section id="cloud"><title>Cloud</title>
      <p>The Cloud definition includes a few top-level configuration values such as the name of the
        cloud, the host prefix, details of external services (NTP, DNS, SMTP) and the firewall
        settings.</p>
      <p>The location of the cloud configuration file also tells the Configuration Processor where
        to look for the files that define all of the other objects in the input model.</p>
    </section>
    <section id="controlplanes"><title>Control Planes</title>
      <p><i>A control-plane runs one or more <uicontrol>services</uicontrol> distributed across
            <uicontrol>clusters</uicontrol> and <uicontrol>resource groups</uicontrol></i>.</p>
      <p><i>A control-plane uses servers with a particular
        <uicontrol>server-role</uicontrol></i>.</p>
      <p>A <uicontrol>control-plane</uicontrol> provides the operating environment for a set of
          <uicontrol>services</uicontrol>; normally consisting of a set of shared services (MySQL,
        RabbitMQ, HA Proxy, Apache, etc), OpenStack control services (API, schedulers, etc) and the
          <uicontrol>resources</uicontrol> they are managing (compute, storage, etc).</p>
      <p>A simple cloud may have a single <uicontrol>control-plane</uicontrol> which runs all of the
          <uicontrol>services</uicontrol>. A more complex cloud may have multiple
          <uicontrol>control-planes</uicontrol> with a relationship between them. (Note that HP
        Helion OpenStack 2.0 only supports a single control-plane). Services that need to consume
        (use) another service (such as Neutron consuming MySQL, Nova consuming Neutron) always use
        the service within the same <uicontrol>control-plane</uicontrol> before looking in any
        related <uicontrol>control-planes</uicontrol>. It is one of the functions of the
        Configuration Processor to resolve these relationships and make sure that each
        consumer/service is provided with the configuration details to connect to the appropriate
        provider/service.</p>
      <p>Each <uicontrol>control-plane</uicontrol> is structured as <uicontrol>clusters</uicontrol>
        and <uicontrol>resources</uicontrol>. The <uicontrol>clusters</uicontrol> are typically used
        to host the OpenStack services that manage the cloud such as API servers, database servers,
        Neutron agents, and Swift proxies, while the <uicontrol>resources</uicontrol> are used to
        host the scale-out OpenStack services such as Nova-Compute or Swift-Object services. This is
        a representation convenience rather than a strict rule, for example it is possible to run
        the Swift-Object service in the management cluster in a smaller-scale cloud that is not
        designed for scale-out object serving.</p>
      <p>A cluster can contain one or more <uicontrol>servers</uicontrol> and you can have one or
        more <uicontrol>clusters</uicontrol> depending on the capacity and scalability needs of the
        cloud that you are building. Spreading services across multiple
          <uicontrol>clusters</uicontrol> provides greater scalability, but it requires a greater
        number of physical servers. A common pattern for a large cloud is to run high data volume
        services such as monitoring and logging in a separate cluster. A cloud with a high object
        storage requirement will typically also run the Swift service in its own cluster.</p>
      <p>Clusters in this context are a mechanism for grouping service components in physical
        servers, but all instances of a component in a <uicontrol>control-plane</uicontrol> work
        collectively. For example, if HA Proxy is configured to run on multiple clusters within the
        same <uicontrol>control-plane</uicontrol> then all of those instances will work as a single
        instance of the ha-proxy service.</p>
      <p>Both <uicontrol>clusters</uicontrol> and <uicontrol>resources</uicontrol> define the type
        (via a list of <uicontrol>server-roles</uicontrol>) and number of servers (min and max or
        count) they require.</p>
      <p>The <uicontrol>control-plane</uicontrol> can also define a list of failure-zones
          (<uicontrol>server-groups</uicontrol>) from which to allocate servers.</p>
    </section>
    <section id="controlplanes_regions"><title>Control Planes and Regions</title>
      <p>A region in OpenStack terms is a collection of URLs that together provide a set of services
        (Nova, Neutron, Swift, etc). Regions are represented in the Keystone identity service
        catalog and clients can decide which region they want to use.</p>
      <p>For the owner of a cloud, regions provide a way of segmenting resources for scale,
        resilience, and isolation. However, each region needs some resources for its
          <uicontrol>control-plane</uicontrol>.</p>
      <p>Regions don't have to be disjointed; for example, you can have a Swift service shared
        across more than one region, in which case the Swift URL for both regions will be the same.
        However, some services, such as Nova, Neutron, and Cinder, do have to be co-located in the
        same region.</p>
      <p>Thus in the cloud model we say that a <uicontrol>control-plane</uicontrol> may provide some
        or all of the endpoints for one or more Regions.</p>
    </section>
    <section id="services"><title>Services</title>
      <p><i>A <uicontrol>control-plane</uicontrol> runs one or more
          <uicontrol>services</uicontrol>.</i></p>
      <p>A service is the collection of <uicontrol>service-components</uicontrol> that provide a
        particular feature; for example, Nova provides the compute service and consists of the
        following service-components: nova-api, nova-scheduler, nova-conductor, nova-novncproxy, and
        nova-compute. Some services, like the authentication/identity service Keystone, only consist
        of a single service-component.</p>
      <p>To define your cloud, all you need to know about a service are the names of the
          <uicontrol>service-components</uicontrol>. The details of the services themselves and how
        they interact with each other is captured in service definition files provided by HPE Helion
        OpenStack.</p>
      <p>When specifying your HPE Helion OpenStack cloud you have to decide where components will
        run and how they connect to the networks. For example, should they all run in one
          <uicontrol>control-plane</uicontrol> sharing common services or be distributed across
        multiple <uicontrol>control-planes</uicontrol> to provide separate instances of some
        services? The HPE Helion OpenStack supplied examples provide solutions for some typical
        configurations.</p>
      <p>Where services run is defined in the <uicontrol>control-plane</uicontrol>. How they connect
        to networks is defined in the <uicontrol>network-groups</uicontrol>.</p>
    </section>
    <section id="serverroles"><title>Server Roles</title>
      <p><i><uicontrol>Clusters</uicontrol> and <uicontrol>resources</uicontrol> use
            <uicontrol>servers</uicontrol> with a particular
        <uicontrol>server-role</uicontrol>.</i></p>
      <p>You're going to be running the services on physical <uicontrol>servers</uicontrol>, and
        you're going to need a way to specify which type of servers you want to use where. This is
        defined via the <uicontrol>server-role</uicontrol>. Each <uicontrol>server-role</uicontrol>
        describes how to configure the physical aspects of a server to fulfill the needs of a
        particular role. You'll generally use a different role whenever the servers are physically
        different (have different disks or network interfaces) or if you want to use some specific
        servers in a particular role (for example to choose which of a set of identical servers are
        to be used in the control plane).</p>
      <p>Each <uicontrol>server-role</uicontrol> has a relationship to two other entities, the
        disk-model and the interface-model: <ul>
          <li>The <uicontrol>disk-model</uicontrol> specifies how to configure and use its local
            storage. This is described in the next section.</li>
          <li>The <uicontrol>interface-model</uicontrol> describes how its network interfaces are to
            be configured and used. This is covered in more details in the networking section.</li>
        </ul>
      </p>
    </section>
    <section id="diskmodel"><title>Disk Model</title>
      <p><i>Each physical disk device is associated with a <uicontrol>device-group</uicontrol> or a
            <uicontrol>volume-group</uicontrol>.</i></p>
      <p><i><uicontrol>Device-groups</uicontrol> are consumed by
          <uicontrol>services</uicontrol>.</i></p>
      <p><i><uicontrol>Volume-groups</uicontrol> are divided into
            <uicontrol>logical-volumes</uicontrol>.</i></p>
      <p><i><uicontrol>Logical-volumes</uicontrol> are mounted as file systems or consumed by
          services.</i></p>
      <p>Disk-models define how local storage is to be configured and presented to
          <uicontrol>services</uicontrol>. Disk-models are identified by a name, which you will
        specify. The HPE Helion OpenStack examples provide some typical configurations. As this is
        an area that varies with respect to the services that are hosted on a server and the number
        of disks available, it is impossible to cover all possible permutations you may need to
        express via modifications to the examples.</p>
      <p>Within a <uicontrol>disk-model</uicontrol>, disk devices are assigned to either a
          <uicontrol>device-group</uicontrol> or a <uicontrol>volume-group</uicontrol>.</p>
      <p><image href="../media/inputmodel/hphelionopenstack_diskmodels.png"/></p>
      <p><xref href="../media/inputmodel/hphelionopenstack_diskmodels_lg.png" scope="external"
          format="html">Download a high-res version</xref></p>
      <p>A <uicontrol>device-group</uicontrol> is a set of one or more disks that are to be consumed
        directly by a service. For example, a set of disks to be used by Swift. The device-group
        identifies the list of disk devices, the service, and a few service-specific attributes that
        tell the service about the intended use (for example, in the case of Swift this is the ring
        names). When a device is assigned to a device-group, the associated service is responsible
        for the management of the disks. This management includes the creation and mounting of file
        systems. (Swift can provide additional data integrity when it has full control over the file
        systems and mount points.)</p>
      <p>A <uicontrol>volume-group</uicontrol> is used to present disk devices in a LVM volume
        group. It also contains details of the logical volumes to be created including the file
        system type and mount point. Logical volume sizes are expressed as a percentage of the total
        capacity of the volume group. A <uicontrol>logical-volume</uicontrol> can also be consumed
        by a service in the same way as a <uicontrol>device-group</uicontrol>. This allows services
        to manage their own devices on configurations that have limited numbers of disk drives.</p>
    </section>
    <section id="servers"><title>Servers</title>
      <p><i><uicontrol>Servers</uicontrol> have a <uicontrol>server-role</uicontrol> which
          determines how they will be used in the cloud.</i></p>
      <p><uicontrol>Servers</uicontrol> (in the disk model) enumerate the resources available for
        your cloud. In addition, in this definition file you can either provide HPE Helion OpenStack
        with all of the details it needs to PXE boot and install an operating system onto the
        server, or, if you prefer to use your own operating system installation tooling you can
        simply provide the details needed to be able to SSH into the servers and start the
        deployment.</p>
      <p>The address specified for the server will be the one used by HPE Helion OpenStack for
        lifecycle management and must be part of a network which is in the input model. If you are
        using HPE Helion OpenStack to install the operating system this network must be an untagged
        VLAN. The first server must be installed manually from the HPE Helion OpenStack ISO and this
        server must be included in the input model as well.</p>
      <p>In addition to the network details used to install or connect to the server, each server
        defines what its <uicontrol>server-role</uicontrol> is and to which
          <uicontrol>server-group</uicontrol> it belongs.</p>
    </section>
    <section id="servergroups"><title>Server Groups</title>
      <p><i>A <uicontrol>server</uicontrol> is associated with a
          <uicontrol>server-group</uicontrol>.</i></p>
      <p><i>A <uicontrol>control-plane</uicontrol> can use <uicontrol>server-groups</uicontrol> as
          failure zones for server allocation.</i></p>
      <p><i>A <uicontrol>server-group</uicontrol> may be associated with a list of
            <uicontrol>networks</uicontrol>.</i></p>
      <p><i>A <uicontrol>server-group</uicontrol> can contain other
            <uicontrol>server-groups</uicontrol>.</i></p>
      <p>The practice of locating physical servers in a number of racks or enclosures in a data
        center is common. Such racks generally provide a degree of physical isolation that allows
        for separate power and/or network connectivity.</p>
      <p>In the HPE Helion OpenStack model we support this configuration by allowing you to define a
        hierarchy of <uicontrol>server-groups</uicontrol>. Each <uicontrol>server</uicontrol> is
        associated with one <uicontrol>server-group</uicontrol>, normally at the bottom of the
        hierarchy.</p>
      <p><uicontrol>Server-groups</uicontrol> are an optional part of the input model - if you donâ€™t
        define any then all <uicontrol>servers</uicontrol> and <uicontrol>networks</uicontrol> will
        be allocated as if they are part of the same <uicontrol>server-group</uicontrol>.</p>
    </section>
    <section id="servergroups_failurezones"><title>Server Groups and Failure Zones</title>
      <p>A <uicontrol>control-plane</uicontrol> defines a list of
          <uicontrol>server-groups</uicontrol> as the failure zones from which it wants to use
        servers. All servers in a <uicontrol>server-group</uicontrol> listed as a failure zone in
        the <uicontrol>control-plane</uicontrol> and any <uicontrol>server-groups</uicontrol> they
        contain are considered part of that failure zone for allocation purposes. The following
        example shows how three levels of <uicontrol>server-groups</uicontrol> can be used to model
        a failure zone consisting of multiple racks, each of which in turn contains a number of
          <uicontrol>servers</uicontrol>.</p>
      <p><image href="../media/inputmodel/hphelionopenstack_servergroups.png"/></p>
      <p><xref href="../media/inputmodel/hphelionopenstack_servergroups_lg.png" scope="external"
          format="html">Download a high-res version</xref></p>
      <p>When allocating <uicontrol>servers</uicontrol>, the Configuration Processor will traverse
        down the hierarchy of <uicontrol>server-groups</uicontrol> listed as failure zones until it
        can find an available server with the required <uicontrol>server-role</uicontrol>. If the
        allocation policy is defined to be strict, it will allocate <uicontrol>servers</uicontrol>
        equally across each of the failure zones. A <uicontrol>cluster</uicontrol> or
          <uicontrol>resource-group</uicontrol> can also independently specify the failure zones it
        wants to use if needed.</p>
    </section>
    <section id="servergroups_networks"><title>Server Groups and Networks</title>
      <p>Each L3 <uicontrol>network</uicontrol> in a cloud must be associated with all or some of
        the <uicontrol>servers</uicontrol>, typically following a physical pattern (such as having
        separate networks for each rack or set of racks). This is also represented in the HPE Helion
        OpenStack model via <uicontrol>server-groups</uicontrol>, each group lists zero or more
        networks to which <uicontrol>servers</uicontrol> associated with
          <uicontrol>server-groups</uicontrol> at or below this point in the hierarchy are
        connected.</p>
      <p>When the Configuration Processor needs to resolve the specific
          <uicontrol>network</uicontrol> a <uicontrol>server</uicontrol> should be configured to
        use, it traverses up the hierarchy of <uicontrol>server-groups</uicontrol>, starting with
        the group the server is directly associated with, until it finds a server-group that lists a
        network in the required network group.</p>
      <p>The level in the <uicontrol>server-group</uicontrol> hierarchy at which a
          <uicontrol>network</uicontrol> is associated will depend on the span of connectivity it
        must provide. In the above example there might be networks in some
          <uicontrol>network-groups</uicontrol> which are per rack (i.e. Rack 1 and Rack 2 list
        different networks from the same <uicontrol>network-group</uicontrol>) and
          <uicontrol>networks</uicontrol> in a different <uicontrol>network-group</uicontrol> that
        span failure zones (the network used to provide floating IP addresses to virtual machines
        for example).</p>
    </section>
    <section id="networking"><title>Networking</title>
      <p>In addition to the mapping of <uicontrol>services</uicontrol> to specific
          <uicontrol>clusters</uicontrol> and <uicontrol>resources</uicontrol> we must also be able
        to define how the <uicontrol>services</uicontrol> connect to one or more
          <uicontrol>networks</uicontrol>.</p>
      <p>In a simple cloud there may be a single L3 network but more typically there are functional
        and physical layers of network separation that need to be expressed.</p>
      <p>Functional network separation provides different networks for different types of traffic;
        for example, it is common practice in even small clouds to separate the External APIs that
        users will use to access the cloud and the external IP addresses that users will use to
        access their virtual machines. In more complex clouds it's common to also separate out
        virtual networking between virtual machines, block storage traffic, and volume traffic onto
        their own sets of networks. In the input model, this level of separation is represented by
          <uicontrol>network-groups</uicontrol>.</p>
      <p>Physical separation is required when there are separate L3 network segments providing the
        same type of traffic; for example, where each rack uses a different subnet. This level of
        separation is represented in the input model by the <uicontrol>networks</uicontrol> within
        each <uicontrol>network-group</uicontrol>.</p>
    </section>
    <section id="networkgroups"><title>Network Groups</title>
      <p><i>Service endpoints attach to <uicontrol>networks</uicontrol> in a specific
            <uicontrol>network-group</uicontrol>.</i></p>
      <p><i><uicontrol>Network-groups</uicontrol> can define routes to other
            <uicontrol>networks</uicontrol>.</i></p>
      <p><i><uicontrol>Network-groups</uicontrol> encapsulate the configuration for
            <uicontrol>services</uicontrol> via <uicontrol>network-tags</uicontrol></i></p>
      <p>A <uicontrol>network-group</uicontrol> defines the traffic separation model and all of the
        properties that are common to the set of L3 networks that carry each type of traffic. They
        define where services are attached to the network model and the routing within that
        model.</p>
      <p>In terms of <uicontrol>service</uicontrol> connectivity, all that has to be captured in the
          <uicontrol>network-groups</uicontrol> definition is the same service-component names that
        are used when defining <uicontrol>control-planes</uicontrol>. HPE Helion OpenStack also
        allows a default attachment to be used to specify "all service-components" that aren't
        explicitly connected to another <uicontrol>network-group</uicontrol>. So, for example, to
        isolate Swift traffic, the swift-account, swift-container, and swift-object service
        components are attached to an "Object" <uicontrol>network-group</uicontrol> and all other
        services are connected to "Management" <uicontrol>network-group</uicontrol> via the default
        relationship.</p>
      <p>The details of how each service connects, such as what port it uses, if it should be behind
        a load balancer, if and how it should be registered in Keystone, and so forth, are defined
        in the service definition files provided by HPE Helion OpenStack.</p>
      <p>In any configuration with multiple networks, controlling the routing is a major
        consideration. In HPE Helion OpenStack, routing is controlled at the
          <uicontrol>network-group</uicontrol> level. First, all <uicontrol>networks</uicontrol> are
        configured to provide the route to any other <uicontrol>networks</uicontrol> in the same
          <uicontrol>network-group</uicontrol>. In addition, a <uicontrol>network-group</uicontrol>
        are configured to provide the route any other <uicontrol>networks</uicontrol> in the same
          <uicontrol>network-group</uicontrol>; for example, if the internal APIs are in a dedicated
          <uicontrol>network-group</uicontrol> (a common configuration in a complex network because
        a network group with load balancers cannot be segmented) then other
          <uicontrol>network-groups</uicontrol> may need to include a route to the internal API
          <uicontrol>network-group</uicontrol> so that services can access the internal API
        endpoints. Routes may also be required to define how to access an external storage network
        or to define a general default route.</p>
      <p>As part of the HPE Helion OpenStack deployment, networks are configured to act as the
        default route for all traffic that was received via that network (so that response packets
        always return via the network the request came from).</p>
      <p>Note that HPE Helion OpenStack will configure the routing rules on the servers it deploys
        and will validate that the routes between services exist in the model, but ensuring that
        gateways can provide the required routes is the responsibility of your network
        configuration. The Configuration Processor provides information about the routes it is
        expecting to be configured.</p>
      <p>For a detailed description of how the Configuration Processor validates routes, refer to
          <xref href="input_model.dita#input_model/networkroutevalidation">Network Route
          Validation</xref>.</p>
    </section>
    <section id="loadbalancers"><title>Load Balancers</title>
      <p><uicontrol>Load-balancers</uicontrol> provide a specific type of routing and are also
        defined in <uicontrol>network-groups</uicontrol> as a relationship between the virtual IP
        address (VIP) on a network in one <uicontrol>network group</uicontrol> and a set of service
        endpoints (which may be on <uicontrol>networks</uicontrol> in the same or a different
          <uicontrol>network-group</uicontrol>).</p>
      <p>Each <uicontrol>load-balancer</uicontrol> is defined as part of the
          <uicontrol>network-group</uicontrol> where the virtual IP will be presented - it follows
        that a <uicontrol>network-group</uicontrol> containing a
          <uicontrol>load-balancer</uicontrol> can only have one <uicontrol>network</uicontrol>
        associated to it.</p>
      <p>The <uicontrol>load-balancer</uicontrol> definition includes a list of
          <uicontrol>service-components</uicontrol> and endpoint roles it will provide A virtual IP
        for. This model allows service-specific <uicontrol>load-balancers</uicontrol> to be defined
        on different <uicontrol>network-groups</uicontrol>. A "default" value is used to express
        "all service-components" which require a virtual IP address and are not explicitly
        configured in another <uicontrol>load-balancer</uicontrol> configuration. The details of how
        the <uicontrol>load-balancer</uicontrol> should be configured for each service, such as
        which ports to use, how to check for service liveness, etc, are provided in the HPE Helion
        OpenStack supplied service definition files.</p>
      <p>The list of endpoint roles for a <uicontrol>load-balancer</uicontrol> make it possible to
        configure separate <uicontrol>load-balancers</uicontrol> for public and internal access to
        services, and the Configuration Processor uses this information to both ensure the correct
        registrations in Keystone and to make sure the internal traffic is routed to the correct
        endpoint. HPE Helion OpenStack services are configured to only connect to other services via
        internal virtual IP addresses and endpoints, allowing the name and security certificate of
        public endpoints to be controlled by the customer and set to values that may not be
        resolvable/accessible from the servers making up the cloud.</p>
      <p>Note that each <uicontrol>load-balancer</uicontrol> defined in the input model will be
        allocated a separate virtual IP address even when the load-balancers are part of the same
          <uicontrol>network-group</uicontrol>. Because of the need to be able to separate both
        public and internal access, HPE Helion OpenStack will not allow a single
          <uicontrol>load-balancer</uicontrol> to provide both public and internal access.
          <uicontrol>Load-balancers</uicontrol> in this context are logical entities (sets of rules
        to transfer traffic from a virtual IP address to one or more endpoints). Multiple
          <uicontrol>load-balancers</uicontrol> may be implemented by the same service within the
        cloud (e.g. a HA Proxy cluster).</p>
      <p>The following diagram shows a possible configuration in which the hostname associated with
        the public URL has been configured to resolve to a firewall controlling external access to
        the cloud. Within the cloud, HPE Helion OpenStack services are configured to use the
        internal URL to access a separate virtual IP address.</p>
      <p><image href="../media/inputmodel/hphelionopenstack_loadbalancers.png"/></p>
      <p><xref href="../media/inputmodel/hphelionopenstack_loadbalancers_lg.png" scope="external"
          format="html">Download a high-res version</xref></p>
    </section>
    <section id="networktags"><title>Network Tags</title>
      <p>Network tags are defined by some HPE Helion OpenStack
          <uicontrol>service-components</uicontrol> and are used to convey information between the
        network model and the service, allowing the dependent aspects of the service to be
        automatically configured. For example, an option in a service configuration file that needs
        the IP address of the corresponding network device on a server where that service-component
        is installed.</p>
      <p>Network tags also convey requirements a service may have for aspects of the server network
        configuration, for example, that a bridge is required on the corresponding network device on
        a server where that service-component is installed.</p>
      <p>See <xref href="#input_model/co_networktags">Network Tags</xref> for more information on
        specific tags and their usage.</p>
    </section>
    <section id="networks"><title>Networks</title>
      <p><i>A <uicontrol>network</uicontrol> is part of a
        <uicontrol>network-group</uicontrol>.</i></p>
      <p><uicontrol>Networks</uicontrol> are fairly simple definitions. Each
          <uicontrol>network</uicontrol> defines the details of its VLAN, optional address details
        (CIDR, start and end address, gateway address), and which
          <uicontrol>network-group</uicontrol> it is a member of.</p>
    </section>
    <section id="interfacemodel"><title>Interface Model</title>
      <p><i>A <uicontrol>server-role</uicontrol> identifies an
            <uicontrol>interface-model</uicontrol> that describes how its network interfaces are to
          be configured and used.</i>></p>
      <p>Networks are mapped onto specific network interfaces via an
          <uicontrol>interface-model</uicontrol>, which describes the network devices that need to
        be created (bonds, ovs-bridges, etc), their properties, and the
          <uicontrol>network-groups</uicontrol> with which they are associated.</p>
      <p>An <uicontrol>interface-model</uicontrol> acts like a template; it can define how some or
        all of the <uicontrol>network-groups</uicontrol> are to be mapped for a particular
        combination of physical NICs. However, it is the <uicontrol>service-components</uicontrol>
        on each server that determine which <uicontrol>network-groups</uicontrol> are required and
        hence which interfaces and <uicontrol>networks</uicontrol> will be configured. This means
        that <uicontrol>interface-models</uicontrol> can be shared between different
          <uicontrol>server-roles</uicontrol>. For example, an API role and a database role may
        share an interface model even though they may have different disk models and they will
        require a different subset of the <uicontrol>network-groups</uicontrol>.</p>
      <p>Within an <uicontrol>interface-model</uicontrol>, physical ports are identified by a device
        name, which in turn is resolved to a physical port via a <uicontrol>nic-mapping</uicontrol>.
        To allow different physical servers to share an <uicontrol>interface-model</uicontrol>, the
          <uicontrol>nic-mapping</uicontrol> is defined as a property of each
          <uicontrol>server</uicontrol>.</p>
    </section>
    <section id="nicmapping"><title>NIC Mapping</title>
      <p>When a <uicontrol>server</uicontrol> has more than a single physical network port, a
          <uicontrol>nic-mapping</uicontrol> is required to unambiguously identify each port.
        Standard Linux mapping of ports to interface names at the time of initial discovery (e.g.
        eth0, eth1, eth2, ...) is not uniformly consister from server to server, so a mapping of PCI
        bus address to interface name is instead.</p>
      <p>This level of abstraction will also allow network functions on SRIOV-capable network cards
        to be used for network connections and consumed by services in a future release.</p>
    </section>
    <section id="firewallconfiguration"><title>Firewall Configuration</title>
      <p>The Configuration Processor uses the details it has about which networks and ports
          <uicontrol>service-components</uicontrol> use to create a set of firewall rules for each
        server. The model allows additional user-defined rules on a per
          <uicontrol>network-group</uicontrol> basis.</p>
    </section>
    <section id="configurationobjects"><title>HPE Helion OpenStack 2.0 Configuration Objects</title>
    </section>
    <section id="co_cloud"><title>Cloud</title>
      <p>The top-level cloud configuration file, <uicontrol>cloudConfig.yml</uicontrol>, defines
        some global values for the HPE Helion OpenStack Cloud, as described in the table below.</p>
      <table frame="all" rowsep="1" colsep="1" id="cloud_config">
        <tgroup cols="2">
          <colspec colname="c1" colnum="1"/>
          <colspec colname="c2" colnum="2"/>
          <thead>
            <row>
              <entry>Key</entry>
              <entry>Value Description</entry>
            </row>
          </thead>
          <tbody>
            <row>
              <entry>name</entry>
              <entry>An administrator-defined name for the cloud</entry>
            </row>
            <row>
              <entry>hostname-data (optional)</entry>
              <entry>Provides control over some parts of the generated names (see <xref
                  href="#input_model/namegeneration">Name Generation</xref>) <p>Consists of two
                  values: <ul>
                    <li>host-prefix - default is to use the cloud name (above)</li>
                    <li>member-prefix - default is "-m"</li>
                  </ul></p></entry>
            </row>
            <row>
              <entry>ntp-servers (optional)</entry>
              <entry>A list of external NTP servers your cloud has access to. If specified by name
                then the names need to be resolvable via the external DNS nameservers you specify in
                the next section. All servers running the "ntp-server" component will be configured
                to use these external NTP servers.</entry>
            </row>
            <row>
              <entry>dns-settings (optional)</entry>
              <entry>DNS configuration data that will be applied to all servers. See example
                configuration for a full list of values.</entry>
            </row>
            <row>
              <entry>smtp-settings (optional)</entry>
              <entry>SMTP client configuration data that will be applied to all servers. See example
                configurations for a full list of values.</entry>
            </row>
            <row>
              <entry>firewall-settings (optional)</entry>
              <entry>Used to enable/disable the firewall feature and to enable/disable logging of
                dropped packets.</entry>
            </row>
          </tbody>
        </tgroup>
      </table>
    </section>
    <section id="co_controlplane"><title>Control Plane</title>
      <p>The snippet below shows the start of the control plane definition file.</p>
      <codeblock>---
  product:
     version: 2
        
  control-planes:
     - name: control-plane-1
       control-plane-prefix: cp1
       region-name: region1
       failure-zones:
         - AZ1
         - AZ2
         - AZ3
       common-service-components:
         - logging-producer
         - monasca-agent
         - freezer-agent
         - stunnel
         - lifecycle-manager-target
       clusters:
         - name: cluster1
           cluster-prefix: c1
           server-role: CONTROLLER-ROLE
           member-count: 3
           allocation-policy: strict
           service-components:
             - lifecycle-manager
             - ntp-server
             - swift-ring-builder
             - mysql
             - ip-cluster
             ...
        
       resources:
         - name: compute
           resource-prefix: comp
           server-role: COMPUTE-ROLE
           allocation-policy: any
           min-count: 0
           service-components:
              - ntp-client
              - nova-compute
              - nova-compute-kvm
              - neutron-l3-agent
              ...</codeblock>
      <p>
        <table frame="all" rowsep="1" colsep="1" id="control_plane">
          <tgroup cols="2">
            <colspec colname="c1" colnum="1"/>
            <colspec colname="c2" colnum="2"/>
            <thead>
              <row>
                <entry>Key</entry>
                <entry>Value Description</entry>
              </row>
            </thead>
            <tbody>
              <row>
                <entry>name</entry>
                <entry>This name identifies the control plane. This value is used to persist server
                  allocations (see <xref href="#input_model/persisteddata">Persisted Data</xref>)
                  and cannot be changed once servers have been allocated.</entry>
              </row>
              <row>
                <entry>control-plane-prefix (optional)</entry>
                <entry>The control-plane-prefix is used as part of the hostname (see <xref
                    href="#input_model/namegeneration">Name Generation</xref>). If not specified,
                  the control plane name is used.</entry>
              </row>
              <row>
                <entry>region-name</entry>
                <entry>This name identifies the Keystone region within which services in the control
                  plane will be registered.</entry>
              </row>
              <row>
                <entry>common-service-components (optional)</entry>
                <entry>This lists a set of service components that run on all servers in the control
                  plane (clusters and resource pools)</entry>
              </row>
              <row>
                <entry>failure-zones (optional)</entry>
                <entry>A list of <uicontrol>server-group</uicontrol> names that servers for this
                  control plane will be allocated from. If no failure-zones are specified, only
                  servers not associated with a <uicontrol>server-group</uicontrol> will be used.
                  (see <xref href="#input_model/servergroups_failurezones">Server Groups and Failure
                    Zones</xref> for a description of server-groups as failure zones.)</entry>
              </row>
              <row>
                <entry>clusters</entry>
                <entry>A list of clusters for this control plane (see <xref
                    href="#input_model/co_clusters">Clusters</xref>).</entry>
              </row>
              <row>
                <entry>resources</entry>
                <entry>A list of resource groups for this control plane (see <xref
                    href="#input_model/co_resources">Resources</xref>).</entry>
              </row>
            </tbody>
          </tgroup>
        </table>
      </p>
    </section>
    <section id="co_clusters"><title>Clusters</title>
      <p>
        <table frame="all" rowsep="1" colsep="1" id="clusters">
          <tgroup cols="2">
            <colspec colname="c1" colnum="1"/>
            <colspec colname="c2" colnum="2"/>
            <thead>
              <row>
                <entry>Key</entry>
                <entry>Value Description</entry>
              </row>
            </thead>
            <tbody>
              <row>
                <entry>name</entry>
                <entry>Cluster and resource names must be unique within a control plane. This value
                  is used to persist server allocations (see <xref href="#input_model/persisteddata"
                    >Persisted Data</xref>) and cannot be changed once servers have been
                  allocated.</entry>
              </row>
              <row>
                <entry>cluster-prefix (optional)</entry>
                <entry>The cluster prefix is used in the hostname (see <xref
                    href="#input_model/namegeneration">Name Generation</xref>). If not supplied then
                  the cluster name is used.</entry>
              </row>
              <row>
                <entry>server-role</entry>
                <entry>This can either be a string (for a single role) or a list of roles. Only
                  servers matching one of the specified <uicontrol>server-roles</uicontrol> will be
                  allocated to this cluster. (see <xref href="#input_model/serverroles">Server
                    Roles</xref> for a description of server roles)</entry>
              </row>
              <row>
                <entry>service-components</entry>
                <entry>The list of <uicontrol>service-components</uicontrol> to be deployed on the
                  servers allocated for the cluster. (The common-service-components for the control
                  plane are also deployed.)</entry>
              </row>
              <row>
                <entry>
                  <p>member-count</p>
                  <p>min-count</p>
                  <p>max-count</p>
                  <p>(all optional)</p>
                </entry>
                <entry>
                  <p>Defines the number of servers to add to the cluster.</p>
                  <p>The number of servers that can be supported in a cluster depends on the
                    services it is running. For example MySQL and RabbitMQ can only be deployed on
                    clusters on 1 (non-HA) or 3 (HA) servers. Other services may support different
                    sizes of cluster.</p>
                  <p>If min-count is specified, then at least that number of servers will be
                    allocated to the cluster. If min-count is not specified it defaults to a value
                    of 1.</p>
                  <p>If max-count is specified, then the cluster will be limited to that number of
                    servers. If max-count is not specified then all servers matching the required
                    role and failure-zones will be allocated to the cluster.</p>
                  <p>Specifying member-count is equivalent to specifying min-count and max-count
                    with the same value.</p></entry>
              </row>
              <row>
                <entry>failure-zones (optional)</entry>
                <entry>A list of <uicontrol>server-groups</uicontrol> that servers will be allocated
                  from. If specified, it overrides the list of values specified for the
                  control-plane. If not specified, the control-plane value is used. (see <xref
                    href="#input_model/servergroups_failurezones">Server Groups and Failure
                    Zones</xref> for a description of server groups as failure zones).</entry>
              </row>
              <row>
                <entry>allocation-policy (optional)</entry>
                <entry>
                  <p>Defines how failure zones will be used when allocating servers.</p>
                  <p><b>strict</b>: Server allocations will be distributed across all specified
                    failure zones. (if max-count is not a whole number, an exact multiple of the
                    number of zones, then some zones may provide one more server than other
                    zones)</p>
                  <p><b>any</b>: Server allocations will be made from any combination of failure
                    zones.</p>
                  <p>The default allocation-policy for a cluster is <i>strict</i></p>. </entry>
              </row>
            </tbody>
          </tgroup>
        </table>
      </p>
    </section>
    <section id="co_resources"><title>Resources</title>
      <p>
        <table frame="all" rowsep="1" colsep="1" id="tb_resources">
          <tgroup cols="2">
            <colspec colname="c1" colnum="1"/>
            <colspec colname="c2" colnum="2"/>
            <thead>
              <row>
                <entry>Key</entry>
                <entry>Value Description</entry>
              </row>
            </thead>
            <tbody>
              <row>
                <entry>name</entry>
                <entry><p>The name of this group of resources. Cluster names and resource-node names
                    must be unique within a control plane. Additionally, clusters and resources
                    cannot share names within a control-plane.</p> This value is used to persist
                  server allocations (see <xref href="#input_model/persisteddata">Persisted
                    Data</xref>) and cannot be changed once servers have been allocated. </entry>
              </row>
              <row>
                <entry>resource-prefix</entry>
                <entry>The resource-prefix is used in the name generation. (see <xref
                    href="#input_model/namegeneration">Name Generation</xref>)</entry>
              </row>
              <row>
                <entry>server-role</entry>
                <entry>This can either be a string (for a single role) or a list of roles. Only
                  servers matching one of the specified <uicontrol>server-roles</uicontrol> will be
                  allocated to this resource group. (see <xref href="#input_model/serverroles"
                    >Server Roles</xref> for a description of server roles).</entry>
              </row>
              <row>
                <entry>service-components</entry>
                <entry>The list of <uicontrol>service-components</uicontrol> to be deployed on the
                  servers in this resource group. (The common-service-components for the control
                  plane are also deployed.)</entry>
              </row>
              <row>
                <entry>
                  <p>member-count</p>
                  <p>min-count</p>
                  <p>max-count</p>
                  <p>(all optional)</p>
                </entry>
                <entry>
                  <p>Defines the number of servers to add to the cluster.</p>
                  <p>The number of servers that can be supported in a cluster depends on the
                    services it is running. For example MySQL and RabbitMQ can only be deployed on
                    clusters on 1 (non-HA) or 3 (HA) servers. Other services may support different
                    sizes of cluster.</p>
                  <p>If min-count is specified, then at least that number of servers will be
                    allocated to the cluster. If min-count is not specified it defaults to a value
                    of 1.</p>
                  <p>If max-count is specified, then the cluster will be limited to that number of
                    servers. If max-count is not specified then all servers matching the required
                    role and failure-zones will be allocated to the cluster.</p>
                  <p>Specifying member-count is equivalent to specifying min-count and max-count
                    with the same value.</p>
                </entry>
              </row>
              <row>
                <entry>failure-zones (optional)</entry>
                <entry>A list of <uicontrol>server-groups</uicontrol> that servers will be allocated
                  from. If specified, it overrides the list of values specified for the
                  control-plane. If not specified, the control-plane value is used. (see <xref
                    href="#input_model/servergroups_failurezones">Server Groups and Failure
                    Zones</xref> for a description of server groups as failure zones).</entry>
              </row>
              <row>
                <entry>allocation-policy (optional)</entry>
                <entry>
                  <p>Defines how failure zones will be used when allocating servers.</p>
                  <p><b>strict</b>: Server allocations will be distributed across all specified
                    failure zones. (if max-count is not a whole number, an exact multiple of the
                    number of zones, then some zones may provide one more server than other
                    zones)</p>
                  <p><b>any</b>: Server allocations will be made from any combination of failure
                    zones.</p>
                  <p>The default allocation-policy for a cluster is <i>any</i></p>. </entry>
              </row>
            </tbody>
          </tgroup>
        </table>
      </p>
    </section>
    <section id="co_servers"><title>Servers</title>
      <p>The <uicontrol>servers</uicontrol> configuration object is used to list the available
        servers for deploying the cloud.</p>
      <p>Optionally, it can be used as an input file to the operating system installation process,
        in which case some additional fields (identified below) will be necessary.</p>
      <codeblock>---
  product:
    version: 2
        
  baremetal:
    subnet: 192.168.10.0
    netmask: 255.255.255.0
        
  servers:
    - id: controller1
      ip-addr: 192.168.10.3
      role: CONTROLLER-ROLE
      server-group: RACK1
      nic-mapping: HP-DL360-4PORT
      mac-addr: b2:72:8d:ac:7c:6f
      ilo-ip: 192.168.9.3
      ilo-password: password
      ilo-user: admin
      
    - id: controller2
      ip-addr: 192.168.10.4
      role: CONTROLLER-ROLE
      server-group: RACK2
      nic-mapping: HP-DL360-4PORT
      mac-addr: 8a:8e:64:55:43:76
      ilo-ip: 192.168.9.4
      ilo-password: password
      ilo-user: admin</codeblock>
      <p>
        <table frame="all" rowsep="1" colsep="1" id="tb_servers">
          <tgroup cols="2">
            <colspec colname="c1" colnum="1"/>
            <colspec colname="c2" colnum="2"/>
            <thead>
              <row>
                <entry>Key</entry>
                <entry>Value Description</entry>
              </row>
            </thead>
            <tbody>
              <row>
                <entry>id</entry>
                <entry>An administrator-defined identifier for the server. IDs must be unique and
                  are used to track server allocations. (see <xref href="#input_model/persisteddata"
                    >Persisted Data</xref>).</entry>
              </row>
              <row>
                <entry>ip-addr</entry>
                <entry>
                  <p>The IP address is used by the Configuration Processor to install and configure
                    the service components on this server.</p>
                  <p>This IP address must be within the range of a <uicontrol>network</uicontrol>
                    defined in this model.</p>
                  <p>When the servers file is being used for operating system installation, this IP
                    address will be assigned to the node by the installation process, and the
                    associated <uicontrol>network</uicontrol> must be an untagged VLAN.</p>
                </entry>
              </row>
              <row>
                <entry>role</entry>
                <entry>Identifies the <uicontrol>server-role</uicontrol> of the server. (see <xref
                    href="#input_model/serverroles">Server Roles</xref> for a description of server
                  roles)</entry>
              </row>
              <row>
                <entry>nic-mapping</entry>
                <entry>Name of the <uicontrol>nic-mappings</uicontrol> entry to apply to this
                  server. (see <xref href="#input_model/co_nicmappings">NIC Mappings</xref>)</entry>
              </row>
              <row>
                <entry>server-group (optional)</entry>
                <entry>Identifies the <uicontrol>server-groups</uicontrol> entry that this server
                  belongs to. (see <xref href="#input_model/servergroups">Server
                  Groups</xref>)</entry>
              </row>
              <row>
                <entry>mac-addr (optional)</entry>
                <entry>Needed when servers file is being used for operating system installation.
                  This identifies the MAC address on the server that will be used to network install
                  the operating system.</entry>
              </row>
              <row>
                <entry>kopt-extras (optional)</entry>
                <entry>Provides additional command line arguments to be passed to the booting
                  network kernel. For example, <codeph>vga=769</codeph> sets the video mode for the
                  install to low resolution which can be useful for remote console users.</entry>
              </row>
              <row>
                <entry>ilo-ip (optional)</entry>
                <entry>Needed when servers file is being used for operating system installation.
                  This provides the IP address of the power management (e.g. IPMI, iLO)
                  subsystem.</entry>
              </row>
              <row>
                <entry>ilo-user (optional)</entry>
                <entry>Needed when servers file is being used for operating system installation.
                  This provides the user name of the power management (e.g. ipmi-ip, iLO)
                  subsystem.</entry>
              </row>
              <row>
                <entry>ilo-password (optional)</entry>
                <entry>Needed when servers file is being used for operating system installation.
                  This provides the user password of the power management (e.g. ipmi-ip, iLO)
                  subsystem.</entry>
              </row>
              <row>
                <entry>ilo-extras (optional)</entry>
                <entry>Needed when servers file is being used for operating system installation.
                  Additional options to pass to ipmitool. For example, this may be required if the
                  servers require additional IPMI addressing parameters.</entry>
              </row>
              <row>
                <entry>moonshot (optional)</entry>
                <entry>Provides the node identifier for HPE Moonshot servers, e.g.
                    <codeph>c4n1</codeph> where c4 is the cartridge and n1 is node 1.</entry>
              </row>
            </tbody>
          </tgroup>
        </table>
      </p>
    </section>
    <section id="co_servergroups"><title>Server Groups</title>
      <p>The server-groups configuration object provides a mechanism for organizing servers and
        networks into a hierarchy that can be used for allocation and network resolution (see <xref
          href="#input_model/servergroups">Server Groups</xref>).</p>
      <codeblock>---
  product:
     version: 2
        
     - name: CLOUD
        server-groups:
         - AZ1
         - AZ2
         - AZ3
        networks:
         - EXTERNAL-API-NET
         - EXTERNAL-VM-NET
         - GUEST-NET
         - MANAGEMENT-NET
        
     #
     # Create a group for each failure zone
     #
     - name: AZ1
       server-groups:
         - RACK1
        
     - name: AZ2
       server-groups:
         - RACK2
        
     - name: AZ3
       server-groups:
         - RACK3
        
     #
     # Create a group for each rack
     #
     - name: RACK1
     - name: RACK2
     - name: RACK3</codeblock>
      <p>
        <table frame="all" rowsep="1" colsep="1" id="tb_servergroups">
          <tgroup cols="2">
            <colspec colname="c1" colnum="1"/>
            <colspec colname="c2" colnum="2"/>
            <thead>
              <row>
                <entry>Key</entry>
                <entry>Value Description</entry>
              </row>
            </thead>
            <tbody>
              <row>
                <entry>name</entry>
                <entry>An administrator-defined name for the server group. The name is used to link
                  server-groups together and to identify server-groups to be used as failure zones
                  in a <uicontrol>control-plane</uicontrol>. (see <xref
                    href="#input_model/co_controlplane">Control Plane</xref>)</entry>
              </row>
              <row>
                <entry>server-groups (optional)</entry>
                <entry>A list of server-group names that are nested below this group in the
                  hierarchy. Each server group can only be listed in one other server group (i.e. in
                  a strict tree topology).</entry>
              </row>
              <row>
                <entry>networks (optional)</entry>
                <entry>A list of network names (see <xref href="#input_model/networks"
                    >Networks</xref>). See <xref href="#input_model/servergroups_networks">Server
                    Groups and Networks</xref> for a description of how networks are matched to
                  servers via server groups.</entry>
              </row>
            </tbody>
          </tgroup>
        </table>
      </p>
    </section>
    <section id="co_serverroles"><title>Server Roles</title>
      <p>The server-roles configuration object is a list of the various server roles that you can
        use in your cloud. Each server role is linked to two other configuration objects:</p>
      <p>
        <ul>
          <li>Disk model (see <xref href="#input_model/co_diskmodels">Disk Models</xref>)</li>
          <li>Interface model (see <xref href="#input_model/co_interfacemodels">Interface
              Models</xref>)</li>
        </ul>
      </p>
      <p>Server roles are referenced in the servers (see <xref href="#input_model/co_servers"
          >Servers</xref>) configuration object above.</p>
      <codeblock>---
  product:
     version: 2
        
  server-roles:
        
     - name: CONTROLLER-ROLE
       interface-model: CONTROLLER-INTERFACES
       disk-model: CONTROLLER-DISKS
        
     - name: COMPUTE-ROLE
       interface-model: COMPUTE-INTERFACES
       disk-model: COMPUTE-DISKS
        
     - name: VSA-ROLE
       interface-model: VSA-INTERFACES
       disk-model: VSA-DISKS</codeblock>
      <p>
        <table frame="all" rowsep="1" colsep="1" id="server_roles">
          <tgroup cols="2">
            <colspec colname="c1" colnum="1"/>
            <colspec colname="c2" colnum="2"/>
            <thead>
              <row>
                <entry>Key</entry>
                <entry>Value Description</entry>
              </row>
            </thead>
            <tbody>
              <row>
                <entry>name</entry>
                <entry>An administrator-defined name for the role.</entry>
              </row>
              <row>
                <entry>interface-model</entry>
                <entry>The name of the <uicontrol>interface-model</uicontrol> to be used for this
                  server-role. <p>Different server-roles can use the same
                  interface-model.</p></entry>
              </row>
              <row>
                <entry>disk-model</entry>
                <entry>The name of the <uicontrol>disk-model</uicontrol> to use for this
                  server-role. <p>Different server-roles can use the same disk-model.</p></entry>
              </row>
            </tbody>
          </tgroup>
        </table>
      </p>
    </section>
    <section id="co_diskmodels"><title>Disk Models</title>
      <p>The disk-models configuration object is used to specify how the directly attached disks on
        the server should be configured. It can also identify which service or service component
        consumes the disk, e.g. Swift object server, and provide service-specific information
        associated with the disk.</p>
      <p>Disks can be used as raw devices or as logical volumes and the disk model provides a
        configuration item for each.</p>
      <p>If the operating system has been installed by the HPE Helion OpenStack installation process
        then the root disk will already have been set up as a volume-group with a single
        logical-volume. This logical-volume will have been created on a partition identified,
        symbolically, in the configuration files as <codeph>/dev/sda_root</codeph>. This is due to
        the fact that different BIOS systems (UEFI, Legacy) will result in different partition
        numbers on the root disk.</p>
      <codeblock>---
  product:
     version: 2
          
  disk-models:
  - name: VSA-DISKS
          
    volume-groups:
       - ...
    device-groups:
       - ...</codeblock>
      <p>
        <table frame="all" rowsep="1" colsep="1" id="disk_models">
          <tgroup cols="2">
            <colspec colname="c1" colnum="1"/>
            <colspec colname="c2" colnum="2"/>
            <thead>
              <row>
                <entry>Key</entry>
                <entry>Value Description</entry>
              </row>
            </thead>
            <tbody>
              <row>
                <entry>name</entry>
                <entry>The name of the disk-model that is referenced from one or more
                  server-roles.</entry>
              </row>
              <row>
                <entry>volume-groups</entry>
                <entry>A list of volume-groups to be configured (see below). There must be at least
                  one volume-group describing the root file system.</entry>
              </row>
              <row>
                <entry>device-groups (optional)</entry>
                <entry>A list of device-groups (see below)</entry>
              </row>
            </tbody>
          </tgroup>
        </table>
      </p>
    </section>
    <section id="co_volumegroups"><title>Volume Groups</title>
      <p>The <uicontrol>volume-groups</uicontrol> configuration object is used to define volume
        groups and their constituent logical volumes.</p>
      <p>Note that volume-groups are not exact analogs of device-groups. A volume-group specifies a
        set of physical volumes used to make up a volume-group that is then subdivided into multiple
        logical volumes.</p>
      <p>The HPE Helion OpenStack operating system installation automatically creates a volume-group
        name "hlm-vg" on the first drive in the system. It creates a "root" logical volume there.
        The volume-group can be expanded by adding more physical-volumes (see examples). In
        addition, it is possible to create more logical-volumes on this volume-group to provide
        dedicated capacity for different services or file system mounts.</p>
      <codeblock>
   volume-groups:
     - name: hlm-vg
       physical-volumes:
         - /dev/sda_root
        
       logical-volumes: 
         - name: root
           size: 35%
           fstype: ext4
           mount: /
        
         - name: log
           size: 50%
           mount: /var/log
           fstype: ext4
           mkfs-opts: -O large_file
        
         - ...
         
     - name: vg-comp
       physical-volumes:
         - /dev/sdb
       logical-volumes:
         - name: compute
           size: 95%
           mount: /var/lib/nova
           fstype: ext4
           mkfs-opts: -O large_file</codeblock>
      <p>
        <table frame="all" rowsep="1" colsep="1" id="volume_groups">
          <tgroup cols="2">
            <colspec colname="c1" colnum="1"/>
            <colspec colname="c2" colnum="2"/>
            <thead>
              <row>
                <entry>Key</entry>
                <entry>Value Descriptions</entry>
              </row>
            </thead>
            <tbody>
              <row>
                <entry>name</entry>
                <entry>The name that will be assigned to the volume-group</entry>
              </row>
              <row>
                <entry>physical-volumes</entry>
                <entry><p>A list of physical disks that make up the volume group.</p> As installed
                  by the HPE Helion OpenStack operating system install process, the volume group
                  "hlm-vg" will use a large partition (sda_root) on the first disk. This can be
                  expanded by adding additional disk(s).</entry>
              </row>
              <row>
                <entry>logical-volumes</entry>
                <entry>A list of logical volume devices to create from the above named volume
                  group.</entry>
              </row>
              <row>
                <entry>name</entry>
                <entry>The name to assign to the logical volume.</entry>
              </row>
              <row>
                <entry>size</entry>
                <entry>The size, expressed as a percentage of the entire volume group capacity, to
                  assign to the logical volum.e</entry>
              </row>
              <row>
                <entry>fstype (optional)</entry>
                <entry>The file system type to create on the logical volume. If non specified the
                  volume is not formatted.</entry>
              </row>
              <row>
                <entry>mkfs-opts (optional)</entry>
                <entry>Options, e.g. <codeph>-O large_file</codeph> to pass to the mkfs
                  command.</entry>
              </row>
              <row>
                <entry>mount (optional)</entry>
                <entry>Mount point for the file system.</entry>
              </row>
              <row>
                <entry>consumer attributes (optional, consumer dependent)</entry>
                <entry>
                  <p>These will vary according to the service consuming the device group. The
                    examples section provides sample content for the different services.</p>
                  <p>Note, not all services support the use of logical volumes. VSA requires raw
                    devices.</p></entry>
              </row>
            </tbody>
          </tgroup>
        </table>
      </p>
    </section>
    <section id="co_devicegroups"><title>Device Groups</title>
      <p>The device-groups configuration object provides the mechanism to make the whole of a
        physical disk available to a service.</p>
      <codeblock>
   device-groups:
       - name: vsa-data
         consumer:
           name: vsa
           usage: data
         devices:
           - name: /dev/sdc
       - name: vsa-cache
         consumer:
           name: vsa
           usage: adaptive-optimization
         devices:
           - name: /dev/sdb</codeblock>
      <p>
        <table frame="all" rowsep="1" colsep="1" id="device_groups">
          <tgroup cols="2">
            <colspec colname="c1" colnum="1"/>
            <colspec colname="c2" colnum="2"/>
            <thead>
              <row>
                <entry>Key</entry>
                <entry>Value Descriptions</entry>
              </row>
            </thead>
            <tbody>
              <row>
                <entry>name</entry>
                <entry>An administrator-defined name for the device group.</entry>
              </row>
              <row>
                <entry>devices</entry>
                <entry>A list of named devices to be assigned to this group. There must be at least
                  one device in the group.</entry>
              </row>
              <row>
                <entry>consumer</entry>
                <entry>Identifies the name of one of the storage services (e.g. one of the
                  following: Swift, Cinder, Ceph, VSA, etc) that will consume the disks in this
                  device group.</entry>
              </row>
              <row>
                <entry>consumer attributes</entry>
                <entry>These will vary according to the service consuming the device group. The
                  examples section provides sample content for the different services.</entry>
              </row>
            </tbody>
          </tgroup>
        </table>
      </p>
    </section>
    <section id="co_interfacemodels"><title>Interface Models</title>
      <p>The interface-models configuration object describes how network interfaces are bonded and
        the mapping of network groups onto interfaces. Interface devices are identified by name and
        mapped to a particular physical port by the <uicontrol>nic-mapping</uicontrol> (see <xref
          href="#input_model/nicmapping">NIC Mapping</xref>).</p>
      <codeblock>---
  product:
     version: 2
        
  interface-models:
     - name: INTERFACE_SET_CONTROLLER
       network-interfaces:
          - name: BONDED_INTERFACE
            device:
              name: bond0
            bond-data:
              provider: linux
              devices:
                - name: hed3
                - name: hed4
              options:
                mode: active-backup
                miimon: 200
                primary: hed3
            network-groups:
               - EXTERNAL_API
               - EXTERNAL_VM
               - GUEST
        
          - name: UNBONDED_INTERFACE
            device:
               name: hed0
            network-groups:
               - MGMT</codeblock>
      <p>
        <table frame="all" rowsep="1" colsep="1" id="tb_interface_model">
          <tgroup cols="2">
            <colspec colname="c1" colnum="1"/>
            <colspec colname="c2" colnum="2"/>
            <thead>
              <row>
                <entry>Key</entry>
                <entry>Value Description</entry>
              </row>
            </thead>
            <tbody>
              <row>
                <entry>name</entry>
                <entry>An administrator-defined name for the interface model.</entry>
              </row>
              <row>
                <entry>network-interfaces</entry>
                <entry>A list of network interface definitions.</entry>
              </row>
            </tbody>
          </tgroup>
        </table>
      </p>
      <p>The network-interfaces configuration object has the following attributes:</p>
      <p>
        <table frame="all" rowsep="1" colsep="1" id="network_interface">
          <tgroup cols="2">
            <colspec colname="c1" colnum="1"/>
            <colspec colname="c2" colnum="2"/>
            <thead>
              <row>
                <entry>Key</entry>
                <entry>Value Description</entry>
              </row>
            </thead>
            <tbody>
              <row>
                <entry>name</entry>
                <entry>An administrator-defined name for the interface</entry>
              </row>
              <row>
                <entry>device</entry>
                <entry>
                  <p>A dictionary containing the network device name as seen on the associated
                    server.</p>
                  <p>When configuring a bond, this is used as the bond device name and the names of
                    the devices to be bonded are specified in the bond-data section.</p>
                  <p>If the interface is not bonded this must be the name of the device specified by
                    the <uicontrol>nic-mapping</uicontrol> (see <xref href="#input_model/nicmapping"
                      >NIC Mapping</xref>).</p>
                </entry>
              </row>
              <row>
                <entry>bond-data (optional)</entry>
                <entry>Used to define a bond. See <xref href="#input_model/co_bonddata" type="table"
                    >Bond Data</xref> for details.</entry>
              </row>
              <row>
                <entry>network-groups (optional if forced-network-groups is defined)</entry>
                <entry>A list of one or more <uicontrol>network-groups</uicontrol> (see <xref
                    href="#input_model/co_networkgroups">Network Groups</xref>) containing
                    <uicontrol>networks</uicontrol> (see <xref href="#input_model/co_networks"
                    >Networks</xref>) that can be accessed via this interface. Networks in these
                  groups will only be configured if there is at least one
                    <uicontrol>service-component</uicontrol> on the server which matches the list of
                  component-endpoints defined in the <uicontrol>network-group</uicontrol>.</entry>
              </row>
              <row>
                <entry>forced-network-groups (optional if network-groups is defined)</entry>
                <entry>A list of one or more <uicontrol>network-groups</uicontrol> (see <xref
                    href="#input_model/co_networkgroups">Network Groups</xref>) containing
                    <uicontrol>networks</uicontrol> (see <xref href="#input_model/co_networks"
                    >Networks</xref>) that can be accessed via this interface. Networks in these
                  groups are always configured on the server.</entry>
              </row>
            </tbody>
          </tgroup>
        </table>
      </p>
    </section>
    <section id="co_bonddata"><title>Bond Data</title>
      <p>A <uicontrol>bond-data</uicontrol> definition is used to configure a bond device, and
        consists of the following attributes:</p>
      <p>
        <table frame="all" rowsep="1" colsep="1" id="bond_data">
          <tgroup cols="2">
            <colspec colname="c1" colnum="1"/>
            <colspec colname="c2" colnum="2"/>
            <thead>
              <row>
                <entry>Key</entry>
                <entry>Value Descriptions</entry>
              </row>
            </thead>
            <tbody>
              <row>
                <entry>provider</entry>
                <entry>Identifies the software used to instantiate the bond device. The only
                  supported value is â€œlinuxâ€, which uses the Linux bonding driver. Other providers
                  may be supported in a future release.</entry>
              </row>
              <row>
                <entry>devices</entry>
                <entry>A dictionary containing network device names used to form the bond. The
                  device names must be the logical-name specified by the
                    <uicontrol>nic-mapping</uicontrol> (see <xref href="#input_model/nicmapping">NIC
                    mapping</xref>.</entry>
              </row>
              <row>
                <entry>options</entry>
                <entry>A dictionary containing bond configuration options. The â€œ<i>linuxâ€</i>
                  provider options are described in the <xref href="#input_model/bonddataoptions"
                    >Bond Data Options</xref> section.</entry>
              </row>
            </tbody>
          </tgroup>
        </table>
      </p>
    </section>
    <section id="bonddataoptions"><title>Bond Data Options for the "linux" Provider</title>
      <p>The Linux bonding driver supports a large number of parameters that control the operation
        of the bond, as described in the <xref
          href="https://www.kernel.org/doc/Documentation/networking/bonding.txt" scope="external"
          format="html">Linux Ethernet Bonding Driver HOWTO</xref> document. The parameter names and
        values may be specified as key-value pairs in the <codeph>options</codeph> section of
          <codeph>bond-data</codeph>.</p>
      <p>Options used in the HPE Helion OpenStack examples are:</p><table frame="all" rowsep="1"
        colsep="1" id="table_cj5_llk_tt">
        <tgroup cols="2">
          <colspec colname="c1" colnum="1"/>
          <colspec colname="c2" colnum="2"/>
          <thead>
            <row>
              <entry>Key</entry>
              <entry>Value Descriptions</entry>
            </row>
          </thead>
          <tbody>
            <row>
              <entry>mode</entry>
              <entry>Specifies the bonding policy. Possible values are: <ul>
                  <li>balance-rr - Transmit packets in sequential order from the first available
                    slave through the last.</li>
                  <li>active-backup - Only one slave in the bond is active. A different slave
                    becomes active if, and only if, the active slave fails.</li>
                  <li>balance-xor - Transmit based on the selected transmit hash policy.</li>
                  <li>broadcast - Transmits everything on all slave interfaces.</li>
                  <li>802.3ad - IEEE 802.3ad Dynamic link aggregation.</li>
                  <li>balance-tlb - Adaptive transmit load balancing: channel bonding that does not
                    require any special switch support.</li>
                  <li>balance-alb - Adaptive load balancing: includes balance-tlb plus receive load
                    balancing (rlb) for IPV4 traffic and does not require any special switch
                    support.</li>
                </ul>
              </entry>
            </row>
            <row>
              <entry>miimon</entry>
              <entry>Specifies the MII link monitoring frequency in milliseconds. This determines
                how often the link state of each slave is inspected for link failures. Accepts
                values in milliseconds.</entry>
            </row>
            <row>
              <entry>primary</entry>
              <entry>The device to use as the primary when the mode is one of the possible values
                below: <ul>
                  <li>active-backup</li>
                  <li>balance-tlb</li>
                  <li>balance-alb</li>
                </ul></entry>
            </row>
          </tbody>
        </tgroup>
      </table>
    </section>
    <section id="co_nicmappings"><title>NIC Mappings</title>
      <p>The <uicontrol>nic-mappings</uicontrol> configuration object is used to ensure that the
        network device name used by the operating system always maps to the same physical device. A
          <uicontrol>nic-mapping</uicontrol> is associated to a <uicontrol>server</uicontrol> in the
        server definition file. (see <xref href="#input_model/co_servers">Servers</xref>). Devices
        should be named <codeph>hedN</codeph> to avoid name clashes with any other devices
        configured during the operating system install as well as any interfaces that are not being
        managed by HPE Helion OpenStack.</p>
      <codeblock>---
  product:
    version: 2
        
  nic-mappings:
       
    - name: HP-DL360-4PORT
      physical-ports:
        - logical-name: hed1
          type: simple-port
          bus-address: "0000:07:00.0"
        
        - logical-name: hed2
          type: simple-port
          bus-address: "0000:08:00.0"
        
        - logical-name: hed3
          type: simple-port
          bus-address: "0000:09:00.0"
        
        - logical-name: hed4
          type: simple-port
          bus-address: "0000:0a:00.0"</codeblock>
      <p>Each entry in the <uicontrol>nic-mappings</uicontrol> list has the following
        attributes:</p>
      <p>
        <table frame="all" rowsep="1" colsep="1" id="nic_mappings">
          <tgroup cols="2">
            <colspec colname="c1" colnum="1"/>
            <colspec colname="c2" colnum="2"/>
            <thead>
              <row>
                <entry>Key</entry>
                <entry>Value Description</entry>
              </row>
            </thead>
            <tbody>
              <row>
                <entry>name</entry>
                <entry>An administrator-defined name for the mapping. This name may be used in a
                  server definition (see <xref href="#input_model/co_servers">Servers</xref>) to
                  apply the mapping to that server.</entry>
              </row>
              <row>
                <entry>physical-ports</entry>
                <entry>A list containing device name to address mapping information.</entry>
              </row>
            </tbody>
          </tgroup>
        </table>
      </p>
      <p>Each entry in the <uicontrol>physical-ports</uicontrol> list has the following
        attributes:</p>
      <p>
        <table frame="all" rowsep="1" colsep="1" id="physical_ports">
          <tgroup cols="2">
            <colspec colname="c1" colnum="1"/>
            <colspec colname="c2" colnum="2"/>
            <thead>
              <row>
                <entry>Key</entry>
                <entry>Value Description</entry>
              </row>
            </thead>
            <tbody>
              <row>
                <entry>logical-name</entry>
                <entry>The network device name that will be associated with the device at the
                  specified <i>bus-address</i>. The logical-name specified here can be used as a
                  device name in network interface model definitions. (see <xref
                    href="#input_model/co_interfacemodels">Interface Models</xref>)</entry>
              </row>
              <row>
                <entry>type</entry>
                <entry>The type of port. The current implementation supports only "simple-port";
                  other port types may be added in a future release.</entry>
              </row>
              <row>
                <entry>bus-address</entry>
                <entry>PCI bus address of the port. Enclose the bus address in quotation marks so
                  yaml does not misinterpret the embedded colon (:) characters.</entry>
              </row>
            </tbody>
          </tgroup>
        </table>
      </p>
    </section>
    <section id="co_networkgroups"><title>Network Groups</title>
      <p>Network-groups define the overall network topology, including where service-components
        connect, what load balancers are to be deployed, which connections use TLS, and network
        routing. They also provide the data needed to map Neutron's network configuration to the
        physical networking.</p>
      <codeblock>---
  product:
     version: 2
        
  network-groups:
        
     - name: EXTERNAL-API
       hostname-suffix: extapi
        
       load-balancers:
         - provider: ip-cluster
           name: extlb
           external-name:
        
           tls-components:
             - default
           roles:
            - public
           cert-file: my-public-cert
        
      - name: EXTERNAL-VM
        tags:
          - neutron.l3_agent.external_network_bridge
        
      - name: GUEST
        hostname-suffix: guest
        tags:
          - neutron.networks.vxlan
        
      - name: MANAGEMENT
        hostname-suffix: mgmt
        hostname: true
        
        component-endpoints:
          - default
        
        routes:
          - default
        
        load-balancers:
          - provider: ip-cluster
            name: lb
            components:
              - default
            roles:
              - internal
              - admin
        
        tags:
          - neutron.networks.vlan:
              provider-physical-network: physnet1</codeblock>
      <p>
        <table frame="all" rowsep="1" colsep="1" id="network_groups">
          <tgroup cols="2">
            <colspec colname="c1" colnum="1"/>
            <colspec colname="c2" colnum="2"/>
            <thead>
              <row>
                <entry>Key</entry>
                <entry>Value Description</entry>
              </row>
            </thead>
            <tbody>
              <row>
                <entry>name</entry>
                <entry>An administrator-defined name for the network group. The name is used to make
                  references from other parts of the input model.</entry>
              </row>
              <row>
                <entry>component-endpoints (optional)</entry>
                <entry>The list of <uicontrol>service-components</uicontrol> that will bind to or
                  need direct access to networks in this network-group.</entry>
              </row>
              <row>
                <entry>hostname (optional)</entry>
                <entry>If set to true, the name of the address associated with a network in this
                  group will be used to set the hostname of the server.</entry>
              </row>
              <row>
                <entry>hostname-suffix (optional)</entry>
                <entry>If supplied, this string will be used in the name generation (see <xref
                    href="#input_model/namegeneration">Name Generation</xref>). If not specified,
                  the name of the network-group will be used.</entry>
              </row>
              <row>
                <entry>load-balancers (optional)</entry>
                <entry>A list of load balancers to be configured on networks in this network-group.
                  Because load balances need a virtual IP address, any network group that contains a
                  load balancer can only have one network associated with it.</entry>
              </row>
              <row>
                <entry>routes (optional)</entry>
                <entry><p>A list of <uicontrol>network-groups</uicontrol> that networks in this
                    group provide access to via their gateway. This can include the value â€œdefaultâ€
                    to define the default route.</p> A network group with no services attached to it
                  can be used to define routes to external networks.</entry>
              </row>
              <row>
                <entry>tags (optional)</entry>
                <entry>A list of network tags. Tags provide the linkage between the physical network
                  configuration and the Neutron network configuration.</entry>
              </row>
            </tbody>
          </tgroup>
        </table>
      </p>
      <p>A load balancer definition has the following attributes:</p>
      <p>
        <table frame="all" rowsep="1" colsep="1" id="table_gv1_wlt_jt">
          <tgroup cols="2">
            <colspec colname="c1" colnum="1"/>
            <colspec colname="c2" colnum="2"/>
            <thead>
              <row>
                <entry>Key</entry>
                <entry>Value Description</entry>
              </row>
            </thead>
            <tbody>
              <row>
                <entry>name</entry>
                <entry>An administrator-defined name for the load balancer.</entry>
              </row>
              <row>
                <entry>provider</entry>
                <entry>The service component that implements the load balancer. Currently only
                  "ip-cluster" (ha-proxy) is supported. Future releases will provide support for
                  external load balancers.</entry>
              </row>
              <row>
                <entry>roles</entry>
                <entry>The list of endpoint roles that this load balancer provides (see below).
                  Valid roles are "public", "internal", and "admin'. To ensure separation of
                  concerns, the role "public" cannot be combined with any other role. See <xref
                    href="#input_model/loadbalancers">Load Balancers</xref> for an example of how
                  the role provides endpoint separation.</entry>
              </row>
              <row>
                <entry>components (optional)</entry>
                <entry>The list of <uicontrol>service-components</uicontrol> for which the load
                  balancer provides a non-encrypted virtual IP address for.</entry>
              </row>
              <row>
                <entry>tls-components (optional)</entry>
                <entry>The list of <uicontrol>service-components</uicontrol> for which the load
                  balancer provides TLS-terminated virtual IP addresses for. In HPE Helion OpenStack
                  2.0 TLS is only supported for public endpoints.</entry>
              </row>
              <row>
                <entry>external-name (optional)</entry>
                <entry>The name to be registered in Keystone for the publicURL. If not specified,
                  the virtual IP address will be registered. Note that this value cannot be changed
                  after the initial deployment.</entry>
              </row>
              <row>
                <entry>cert-file (optional)</entry>
                <entry>The name of the certificate file to be used for public endpoints.</entry>
              </row>
            </tbody>
          </tgroup>
        </table>
      </p>
    </section>
    <section id="co_networktags"><title>Network Tags</title>
      <p>HPE Helion OpenStack supports a small number of network tags which may be used to convey
        information between the input model and the service components (currently only Neutron uses
        network tags). A network tag consists minimally of a tag name; but some network tags have
        additional attributes.</p>
      <p><b>neutron.networks.vxlan</b></p>
      <p>
        <table frame="all" rowsep="1" colsep="1" id="neutron_networks_vxlan">
          <tgroup cols="2">
            <colspec colname="c1" colnum="1"/>
            <colspec colname="c2" colnum="2"/>
            <thead>
              <row>
                <entry>Tag</entry>
                <entry>Value Description</entry>
              </row>
            </thead>
            <tbody>
              <row>
                <entry>neutron.networks.vxlan</entry>
                <entry>This tag causes Neutron to be configured to use VxLAN as the underlay for
                  tenant networks. The associated network group will carry the VxLAN
                  traffic.</entry>
              </row>
              <row>
                <entry>tenant-vxlan-id-range (optional)</entry>
                <entry>Used to specify the VxLAN identifier range in the format
                  â€œ&lt;min-id&gt;:&lt;max-id&gt;â€. The default range is â€œ1001:65535â€. Enclose the
                  range in quotation marks.</entry>
              </row>
            </tbody>
          </tgroup>
        </table>
      </p>
      <p>Example using the default ID range:
        <codeblock>
  tags:
    - neutron.networks.vxlan</codeblock></p>
      <p>Example using a user-defined ID range:
        <codeblock>
  tags:
    - neutron.networks.vxlan:
        tenant-vxlan-id-range: â€œ1:20000â€</codeblock></p>
      <p id="neutron.networks.vlan"><b>neutron.networks.vlan</b></p>
      <p>
        <table frame="all" rowsep="1" colsep="1" id="neutron_networks_vlan">
          <tgroup cols="2">
            <colspec colname="c1" colnum="1"/>
            <colspec colname="c2" colnum="2"/>
            <thead>
              <row>
                <entry>Tag</entry>
                <entry>Value Description</entry>
              </row>
            </thead>
            <tbody>
              <row>
                <entry>neutron.networks.vlan</entry>
                <entry>
                  <p>This tag causes Neutron to be configured for provider VLAN networks, and
                    optionally to use VLAN as the underlay for tenant networks. The associated
                    network group will carry the VLAN traffic. This tag can be specified on multiple
                    network groups.</p>
                  <p>NOTE: this tag does not cause any Neutron networks to be created, that must be
                    done in Neutron after the cloud is deployed.</p></entry>
              </row>
              <row>
                <entry>provider-physical-network</entry>
                <entry>The provider network name. This is the name to be used in the Neutron API for
                  the <i>provider:physical_network</i> parameter of network objects.</entry>
              </row>
              <row>
                <entry>tenant-vlan-id-range (optional)</entry>
                <entry>This attribute causes Neutron to use VLAN for tenant networks; omit this
                  attribute if you are using provider VLANs only. It specifies the VLAN ID range for
                  tenant networks, in the format â€œ&lt;min-id&gt;:&lt;max-id&gt;â€. Enclose the range
                  in quotation marks.</entry>
              </row>
            </tbody>
          </tgroup>
        </table>
      </p>
      <p>Example using a provider vlan only (may be used with tenant VxLAN:
        <codeblock>
  tags:
    - neutron.networks.vlan:
        provider-physical-network: physnet1</codeblock></p>
      <p>Example using a tenant and provider VLAN:
        <codeblock>
  tags:
    - neutron.networks.vlan:
        provider-physical-network: physnet1
        tenant-vlan-id-range: â€œ100:200â€</codeblock></p>
      <p><b>neutron.networks.flat</b></p>
      <p>
        <table frame="all" rowsep="1" colsep="1" id="neutron_networks_flat">
          <tgroup cols="2">
            <colspec colname="c1" colnum="1"/>
            <colspec colname="c2" colnum="2"/>
            <thead>
              <row>
                <entry>Tag</entry>
                <entry>Value Description</entry>
              </row>
            </thead>
            <tbody>
              <row>
                <entry>neutron.networks.flat</entry>
                <entry>
                  <p>This tag causes Neutron to be configured for provider flat networks. The
                    associated network group will carry the traffic. This tag can be specified on
                    multiple network groups.</p>
                  <p>NOTE: this tag does not cause any Neutron networks to be created, that must be
                    done in Neutron after the cloud is deployed.</p>
                </entry>
              </row>
              <row>
                <entry>provider-physical-network</entry>
                <entry>The provider network name. This is the name to be used in the Neutron API for
                  the <i>provider:physical_network</i> parameter of network objects. When specified
                  on multiple network groups, the name must be unique for each network
                  group.</entry>
              </row>
            </tbody>
          </tgroup>
        </table>
      </p>
      <p>Example using a provider flat network:
        <codeblock>
  tags:
    - neutron.networks.flat:
         provider-physical-network: flatnet1</codeblock></p>
      <p><b>neutron.l3_agent.external_network_bridge</b></p>
      <p>
        <table frame="all" rowsep="1" colsep="1" id="neutron_l3_agent">
          <tgroup cols="2">
            <colspec colname="c1" colnum="1"/>
            <colspec colname="c2" colnum="2"/>
            <thead>
              <row>
                <entry>Tag</entry>
                <entry>Value Description</entry>
              </row>
            </thead>
            <tbody>
              <row>
                <entry>neutron.l3_agent.external_network_bridge</entry>
                <entry>
                  <p>This tag causes the Neutron L3 Agent to be configured to use the associated
                    network group as the Neutron external network for floating IP addresses. A CIDR
                      <b>should not</b> be defined for the associated physical network, as that will
                    cause addresses from that network to be configured in the hypervisor. When this
                    tag is used, provider networks cannot be used as external networks.</p>
                  <p>NOTE: this tag does not cause a Neutron external networks to be created, that
                    must be done in Neutron after the cloud is deployed.</p>
                </entry>
              </row>
            </tbody>
          </tgroup>
        </table>
      </p>
      <p>Example using neutron.l3_agent.external_network_bridge:
        <codeblock>
  tags:
    - neutron.l3_agent.external_network_bridge</codeblock></p>
    </section>
    <section id="co_networks"><title>Networks</title>
      <p>A network definition represents a physical L3 network used by the cloud infrastructure.
        Note that these are different from the network definitions that are created/configured in
        Neutron, although some of the networks may be used by Neutron.</p>
      <codeblock>---
   product:
     version: 2
        
   networks:
     - name: NET_EXTERNAL_VM
       vlanid: 102
       tagged-vlan: true
       network-group: EXTERNAL_VM
        
     - name: NET_GUEST
       vlanid: 103
       tagged-vlan: true
       cidr: 10.1.1.0/24
       gateway-ip: 10.1.1.1
       network-group: GUEST
        
     - name: NET_MGMT
       vlanid: 100
       tagged-vlan: false
       cidr: 10.2.1.0/24
       start-address: 10.2.1.10
       end-address: 10.2.1.40
       gateway-ip: 10.2.1.1
       network-group: MGMT</codeblock>
      <p>
        <table frame="all" rowsep="1" colsep="1" id="tb_networks">
          <tgroup cols="2">
            <colspec colname="c1" colnum="1"/>
            <colspec colname="c2" colnum="2"/>
            <thead>
              <row>
                <entry>Key</entry>
                <entry>Value Description</entry>
              </row>
            </thead>
            <tbody>
              <row>
                <entry>name</entry>
                <entry>The name of this network. The network <i>name</i> may be used in a
                  server-group definition (see <xref href="#input_model/co_servergroups">Server
                    Groups</xref>) to specify a particular network from within a network-group to be
                  associated with a set of servers.</entry>
              </row>
              <row>
                <entry>network-group</entry>
                <entry>The name of the associated network group.</entry>
              </row>
              <row>
                <entry>vlanid (optional)</entry>
                <entry>The IEEE 802.1Q VLAN Identifier, a value in the range 1 through 4094. A
                    <i>vlanid</i> must be specified when <i>tagged-vlan</i> is true.</entry>
              </row>
              <row>
                <entry>tagged-vlan (optional)</entry>
                <entry>May be set to â€œtrueâ€ or â€œfalseâ€. If true, packets for this network carry the
                    <i>vlanid </i>in the packet header; such packets are referred to as VLAN-tagged
                  frames in IEEE 802.1Q.</entry>
              </row>
              <row>
                <entry>cidr (optional)</entry>
                <entry>The IP subnet associated with this network.</entry>
              </row>
              <row>
                <entry>start-address (optional)</entry>
                <entry>An IP address within the <i>CIDR</i> which will be used as the start of the
                  range of IP addresses from which server addresses may be allocated. The default
                  value is the first host address within the <i>CIDR</i> (e.g. the .1
                  address).</entry>
              </row>
              <row>
                <entry>end-address (optional)</entry>
                <entry>An IP address within the <i>CIDR</i> which will be used as the end of the
                  range of IP addresses from which server addresses may be allocated. The default
                  value is the last host address within the <i>CIDR</i> (e.g. the .254 address of a
                  /24).</entry>
              </row>
              <row>
                <entry>gateway-ip (optional)</entry>
                <entry>The IP address of the gateway for this network. Gateway addresses must be
                  specified if the associated <uicontrol>network-group</uicontrol> provides
                  routes.</entry>
              </row>
            </tbody>
          </tgroup>
        </table>
      </p>
    </section>
    <section id="co_firewallrules">
      <title>Firewall Rules</title>
      <p>The Configuration Processor will automatically generate "allow" firewall rules for each
        server based on the services deployed and block all other ports. The firewall rules in the
        input model allow the customer to define additional rules for each network group.</p>
      <p>Administrator-defined rules are applied after all rules generated by the Configuration
        Processor.</p>
      <codeblock>---
  product:
     version: 2
        
  firewall-rules:
        
     - name: PING
       network-groups:
       - MANAGEMENT
       - GUEST
       - EXTERNAL-API
       rules:
       # open ICMP echo request (ping)
       - type: allow
         remote-ip-prefix:  0.0.0.0/0
         # icmp type
         port-range-min: 8
         # icmp code
         port-range-max: 0
         protocol: icmp</codeblock>
      <p>
        <table frame="all" rowsep="1" colsep="1" id="table_zxz_yrk_tt">
          <tgroup cols="2">
            <colspec colname="c1" colnum="1"/>
            <colspec colname="c2" colnum="2"/>
            <thead>
              <row>
                <entry>Key</entry>
                <entry>Value Description</entry>
              </row>
            </thead>
            <tbody>
              <row>
                <entry>name</entry>
                <entry>An administrator-defined name for the group of rules.</entry>
              </row>
              <row>
                <entry>network-groups</entry>
                <entry>A list of <uicontrol>network-group</uicontrol> names that the rules apply to.
                  A value of "all" matches all network-groups.</entry>
              </row>
              <row>
                <entry>final (optional)</entry>
                <entry>If "true", these rules are applied at the end of any other user-defined
                  rules. If not specified, this defaults to <b>false</b>. The deny-all rule, which
                  turns the firewall on, must have this value set to true.</entry>
              </row>
              <row>
                <entry>rules</entry>
                <entry>A list of rules. Rules are applied in the order in which they appear in the
                  list, apart from the control provided by the "final" option (see above). The order
                  between sets of rules is indeterminate.</entry>
              </row>
            </tbody>
          </tgroup>
        </table>
      </p>
    </section>
    <section id="co_rule">
      <title>Rule</title>
      <p>Each rule in the list takes the following parameters (which match the parameters of a
        Neutron security group rule):</p>
      <table frame="all" rowsep="1" colsep="1" id="table_uvr_lsk_tt">
        <tgroup cols="2">
          <colspec colname="c1" colnum="1"/>
          <colspec colname="c2" colnum="2"/>
          <thead>
            <row>
              <entry>Key</entry>
              <entry>Value Description</entry>
            </row>
          </thead>
          <tbody>
            <row>
              <entry>type</entry>
              <entry>Must be one of "allow" or "deny"</entry>
            </row>
            <row>
              <entry>remote-ip-prefix</entry>
              <entry>Range of remote addresses in CIDR format that this rule applies to.</entry>
            </row>
            <row>
              <entry>port-range-min<p>port-range-max</p></entry>
              <entry>Defines the range of ports covered by the rule. Note that if the protocol is
                "icmp" then port-range-min is the ICMP type and port-range-max is the ICMP
                code.</entry>
            </row>
            <row>
              <entry>protocol</entry>
              <entry>Must be one of "tcp", "udp", or "icmp".</entry>
            </row>
          </tbody>
        </tgroup>
      </table>
    </section>
    <section id="passthrough"><title>Pass Through</title>
      <p>Through pass_through definitions, certain configuration values can be assigned and
        used.</p>
      <codeblock>product:
  version: 2
  pass-through:
  global:
  esx_cloud: true
  servers:
      data:
      vmware:
      cert_check: false
      vcenter_cluster: Cluster1
      vcenter_id: BC9DED4E-1639-481D-B190-2B54A2BF5674
      vcenter_ip: 10.1.200.41
      vcenter_port: 443
      vcenter_username: administrator@vsphere.local
      id: 7d8c415b541ca9ecf9608b35b32261e6c0bf275a</codeblock>
      <p>
        <table frame="all" rowsep="1" colsep="1" id="table_dnf_c5f_pt">
          <tgroup cols="2">
            <colspec colname="c1" colnum="1"/>
            <colspec colname="c2" colnum="2"/>
            <thead>
              <row>
                <entry>Key</entry>
                <entry>Value Description</entry>
              </row>
            </thead>
            <tbody>
              <row>
                <entry>global</entry>
                <entry>These values will be used at the cloud level.</entry>
              </row>
              <row>
                <entry>servers </entry>
                <entry>These values will be assigned to a specific server(s) using the
                  server-id.</entry>
              </row>
            </tbody>
          </tgroup>
        </table>
      </p>
    </section>


    <section id="othertopics"><title>Other Topics</title></section>
    <section id="namegeneration"><title>Name Generation</title>
      <p>Names are generated by the Configuration Processor for all allocated IP addresses. A server
        connected to multiple networks will have multiple names associated with it. One of these may
        be assigned as the hostname for a server via the network-group configuration (see <xref
          href="#input_model/co_nicmappings">NIC Mappings</xref>). Names are generated from data
        taken from various parts of the input model as described in the following sections.</p>
    </section>
    <section id="o_clusters"><title>Clusters</title>
      <p>Names generated for servers in a cluster have the following form:</p>
      <p><codeblock>&lt;cloud>-&lt;control-plane>-&lt;cluster>&lt;member-prefix>&lt;member_id>-&lt;network></codeblock></p>
      <p>Example: <codeph>helion-cp1-core-m1-mgmt</codeph></p>
      <table frame="all" rowsep="1" colsep="1" id="cluster_node_names">
        <tgroup cols="2">
          <colspec colname="c1" colnum="1" colwidth="1.0*"/>
          <colspec colname="c2" colnum="2" colwidth="1.0*"/>
          <thead>
            <row>
              <entry>Name</entry>
              <entry>Description</entry>
            </row>
          </thead>
          <tbody>
            <row>
              <entry>&lt;cloud></entry>
              <entry>Comes from the hostname-data section of the <uicontrol>cloud</uicontrol> object
                (see <xref href="#input_model/co_cloud">Cloud</xref>)</entry>
            </row>
            <row>
              <entry>&lt;control-plane></entry>
              <entry>is the <uicontrol>control-plane</uicontrol> prefix or name (see <xref
                  href="#input_model/co_controlplane">Control Plane</xref>)</entry>
            </row>
            <row>
              <entry>&lt;cluster></entry>
              <entry>is the <uicontrol>cluster-prefix</uicontrol> name (see <xref
                  href="#input_model/clusters" type="table">Clusters</xref>)</entry>
            </row>
            <row>
              <entry>&lt;member-prefix></entry>
              <entry>comes from the hostname-data section of the <uicontrol>cloud</uicontrol> object
                (see <xref href="#input_model/co_cloud">Cloud</xref>)</entry>
            </row>
            <row>
              <entry>&lt;member_id></entry>
              <entry>is the ordinal within the cluster, generated by the Configuration Processor as
                servers are allocated to the cluster</entry>
            </row>
            <row>
              <entry>&lt;network></entry>
              <entry>comes from the <uicontrol>hostname-suffix</uicontrol> of the network group to
                which the network belongs (see <xref href="#input_model/co_nicmappings">NIC
                  Mappings</xref>).</entry>
            </row>
          </tbody>
        </tgroup>
      </table>
    </section>



    <section id="o_resourcenodes"><title>Resource Nodes</title>
      <p>Names generated for servers in a resource group have the following form:</p>
      <p><codeblock>&lt;cloud>-&lt;control-plane>-&lt;resource-prefix>&lt;member_id>-&lt;network></codeblock></p>
      <p>Example: <codeph>helion-cp1-comp0001-mgmt</codeph></p>
      <table frame="all" rowsep="1" colsep="1" id="resource_node_names">
        <tgroup cols="2">
          <colspec colname="c1" colnum="1" colwidth="1.0*"/>
          <colspec colname="c2" colnum="2" colwidth="1.0*"/>
          <thead>
            <row>
              <entry>Name</entry>
              <entry>Description</entry>
            </row>
          </thead>
          <tbody>
            <row>
              <entry>&lt;cloud></entry>
              <entry>Comes from the hostname-data section of the <uicontrol>cloud</uicontrol> object
                (see <xref href="#input_model/co_cloud">Cloud</xref>).</entry>
            </row>
            <row>
              <entry>&lt;control-plane></entry>
              <entry>is the <uicontrol>control-plane</uicontrol> prefix or name (see <xref
                  href="#input_model/co_controlplane">Control Plane</xref>).</entry>
            </row>
            <row>
              <entry>&lt;resource-prefix></entry>
              <entry>is the <uicontrol>resource-prefix</uicontrol> value name (see <xref
                  href="#input_model/co_resources" type="table">Resources</xref>).</entry>
            </row>
            <row>
              <entry>&lt;member_id></entry>
              <entry>is the ordinal within the cluster, generated by the Configuration Processor as
                servers are allocated to the cluster, padded with leading zeroes to four
                digits.</entry>
            </row>
            <row>
              <entry>&lt;network></entry>
              <entry>comes from the <uicontrol>hostname-suffix</uicontrol> of the network group to
                which the network belongs to (see <xref href="#input_model/co_nicmappings">NIC
                  Mappings</xref>)</entry>
            </row>
          </tbody>
        </tgroup>
      </table>
    </section>





    <section id="persisteddata"><title>Persisted Data</title>
      <p>The Configuration Processor is making allocation decisions on servers and needs to remember
        IP addresses between successive runs so that if new servers are added to the input model
        they donâ€™t disrupt the previously deployed allocations.</p>
      <p>To allow users to make multiple iterations of the input model before deployment HPE Helion
        OpenStack will only persist data when the administrator confirms that they are about to
        deploy the results via the "ready-deployment" operation. To under this better, consider the
        following example:</p>
      <p>Imagine you have completed your HPE Helion OpenStack deployment with servers A, B, and C
        and you want to add two new compute nodes by adding servers D and E to the input model.</p>
      <p>When you add these to the input model and re-run the Configuration Processor it will read
        the persisted data for A, B, and C and allocate D and E as new servers. The Configuration
        Processor now has allocation data for A, B, C, D, and E -- which it keeps in a staging area
        (actually a special branch in git) until we get confirmation that the Configuration
        Processor has done what you intended and you are ready to deploy the revised
        configuration.</p>
      <p>If you noticed that the role of E was wrong and it became a Swift node instead of a Nova
        node you need to be able to change the input mode and re-run the Configuration Processor.
        This is fine because the allocations of D and E have not been confirmed, and so the
        Configuration Processor will re-read the data about A, B, C and re-allocate D and E now to
        the correct clusters, updating the persisted data in the staging area.</p>
      <p>You can loop though this as many times as needed. Each time, the Configuration Processor is
        processing the deltas to what is deployed, not the results of the previous run. When you are
        ready to use the results of the Configuration Processor, you run
          <codeph>ready-deployment.yml</codeph> which commits the data in the staging area into the
        persisted data. The next run of the Configuration Processor will then start from the
        persisted data for A, B, C, D, and E.</p>
    </section>


    <section id="persistedserverallocations"><title>Persisted Server Allocations</title>
      <p>Server allocations are persisted by the administrator-defined server ID (see <xref
          href="#input_model/co_servers">Servers</xref>), and include the control plane,
        cluster/resource name, and ordinal within the cluster or resource group.</p>
      <p>To guard against data loss, the Configuration Processor persists server allocations even
        when the server ID no longer exists in the input model -- for example, if a server was
        removed accidentally and the Configuration Processor allocated a new server to the same
        ordinal, then it would be very difficult to recover from that situation.</p>
      <p>The following example illustrates the behavior:</p>
      <p>A cloud is deployed with four servers with IDs of A, B, C, and D that can all be used in a
        resource group with <codeph>min-size=0</codeph> and <codeph>max-size=3</codeph>. At the end
        of this deployment they persisted state is as follows:</p>
      <p>
        <table frame="all" rowsep="1" colsep="1" id="persist_exam_1">
          <tgroup cols="6">
            <colspec colname="c1" colnum="1"/>
            <colspec colname="c2" colnum="2"/>
            <colspec colname="c3" colnum="3"/>
            <colspec colname="c4" colnum="4"/>
            <colspec colname="c5" colnum="5"/>
            <colspec colname="newCol6" colnum="6" colwidth="1*"/>
            <thead>
              <row>
                <entry>ID</entry>
                <entry>Control Plane</entry>
                <entry>Resource Group</entry>
                <entry>Ordinal</entry>
                <entry>State</entry>
                <entry>Deployed As</entry>
              </row>
            </thead>
            <tbody>
              <row>
                <entry>A</entry>
                <entry>ccp</entry>
                <entry>compute</entry>
                <entry>1</entry>
                <entry>Allocated</entry>
                <entry>mycloud-ccp-comp0001</entry>
              </row>
              <row>
                <entry>B</entry>
                <entry>ccp</entry>
                <entry>compute</entry>
                <entry>2</entry>
                <entry>Allocated</entry>
                <entry>mycloud-ccp-comp0002</entry>
              </row>
              <row>
                <entry>C</entry>
                <entry>ccp</entry>
                <entry>compute</entry>
                <entry>3</entry>
                <entry>Allocated</entry>
                <entry>mycloud-ccp-comp0003</entry>
              </row>
              <row>
                <entry>D</entry>
                <entry/>
                <entry/>
                <entry/>
                <entry>Available</entry>
                <entry/>
              </row>
            </tbody>
          </tgroup>
        </table>
      </p>
      <p>(In this example server D has not been allocated because the group is at its max size, and
        there are no other groups that required this server)</p>
      <p>If server B is removed from the input model and the Configuration Processor is re-run, the
        state is changed to:</p>
      <p>
        <table frame="all" rowsep="1" colsep="1" id="persist_exam_2">
          <tgroup cols="6">
            <colspec colname="c1" colnum="1"/>
            <colspec colname="c2" colnum="2"/>
            <colspec colname="c3" colnum="3"/>
            <colspec colname="c4" colnum="4"/>
            <colspec colname="c5" colnum="5"/>
            <colspec colname="newCol6" colnum="6" colwidth="1*"/>
            <thead>
              <row>
                <entry>ID</entry>
                <entry>Control Plane</entry>
                <entry>Resource Group</entry>
                <entry>Ordinal</entry>
                <entry>State</entry>
                <entry>Deployed As</entry>
              </row>
            </thead>
            <tbody>
              <row>
                <entry>A</entry>
                <entry>ccp</entry>
                <entry>compute</entry>
                <entry>1</entry>
                <entry>Allocated</entry>
                <entry>mycloud-ccp-comp0001</entry>
              </row>
              <row>
                <entry>B</entry>
                <entry>ccp</entry>
                <entry>compute</entry>
                <entry>2</entry>
                <entry>Deleted</entry>
                <entry/>
              </row>
              <row>
                <entry>C</entry>
                <entry>ccp</entry>
                <entry>compute</entry>
                <entry>3</entry>
                <entry>Allocated</entry>
                <entry>mycloud-ccp-comp0003</entry>
              </row>
              <row>
                <entry>D</entry>
                <entry>ccp</entry>
                <entry>compute</entry>
                <entry>4</entry>
                <entry>Allocated</entry>
                <entry>mycloud-ccp-comp0004</entry>
              </row>
            </tbody>
          </tgroup>
        </table>
      </p>
      <p>The details associated with server B are still retained, but the Configuration Processor
        will not generate any deployment data for this server. Server D has been added to the group
        to meet the minimum size requirement but has been given a different ordinal and hence will
        get different names and IP addresses than were given to server B.</p>
      <p>If server B is added back into the input model the resulting state will be:</p>
      <p>
        <table frame="all" rowsep="1" colsep="1" id="persist_exam_3">
          <tgroup cols="6">
            <colspec colname="c1" colnum="1"/>
            <colspec colname="c2" colnum="2"/>
            <colspec colname="c3" colnum="3"/>
            <colspec colname="c4" colnum="4"/>
            <colspec colname="c5" colnum="5"/>
            <colspec colname="newCol6" colnum="6" colwidth="1*"/>
            <thead>
              <row>
                <entry>ID</entry>
                <entry>Control Plane</entry>
                <entry>Resource Group</entry>
                <entry>Ordinal</entry>
                <entry>State</entry>
                <entry>Deployed As</entry>
              </row>
            </thead>
            <tbody>
              <row>
                <entry>A</entry>
                <entry>ccp</entry>
                <entry>compute</entry>
                <entry>1</entry>
                <entry>Allocated</entry>
                <entry>mycloud-ccp-comp0001</entry>
              </row>
              <row>
                <entry>B</entry>
                <entry>ccp</entry>
                <entry>compute</entry>
                <entry>2</entry>
                <entry>Deleted</entry>
                <entry/>
              </row>
              <row>
                <entry>C</entry>
                <entry>ccp</entry>
                <entry>compute</entry>
                <entry>3</entry>
                <entry>Allocated</entry>
                <entry>mycloud-ccp-comp0003</entry>
              </row>
              <row>
                <entry>D</entry>
                <entry>ccp</entry>
                <entry>compute</entry>
                <entry>4</entry>
                <entry>Allocated</entry>
                <entry>mycloud-ccp-comp0004</entry>
              </row>
            </tbody>
          </tgroup>
        </table>
      </p>
      <p>The Configuration Processor will issue a warning that server B cannot be returned to the
        compute group because it would exceed the max-size constraint. However, because the
        Configuration Processor knows that server B is associated with this group it wonâ€™t allocate
        it to any other group that could use it, since that might lead to data loss on that
        server.</p>
      <p>If the max-size value of the group was increased, then server B would be allocated back to
        the group, with its previous name and addresses
        (<codeph>mycloud-cp1-compute0002</codeph>).</p>
      <p>Note that the Configuration Processor relies on the server ID to identify a physical
        server. If the ID value of a server is changed the Configuration Processor will treat it as
        a new server. Conversely, if a different physical server is added with the same ID as a
        deleted server the Configuration Processor will assume that it is the original server being
        returned to the model.</p>
      <p>You can force the removal of persisted data for server that are no longer in the input
        model by running the Configuration Processor with the
          <codeph>remove_deleted_servers</codeph> option, like below:</p>
      <codeblock>cd ~/helion/hos/ansible
ansible-playbook -i hosts/localhost config-processor-run.yml -e remove_deleted_servers="y"</codeblock>
    </section>
    <section id="persistedaddressallocations"><title>Persisted Address Allocations</title>
      <p>The Configuration Processor persists IP address allocations by the generated name (see
          <xref href="#input_model/namegeneration">Name Generation</xref> for how names are
        generated). As with servers once an address has been allocated, that address will remain
        allocated until the Configuration Processor is explicitly told that it is no longer
        required. The Configuration Processor will generate warnings for addresses that are
        persisted but no longer used.</p>
      <p>You can remove persisted address allocations that are no longer used in the input model by
        running the Configuration Processor with the <codeph>free_unused_addresses</codeph> option,
        like below:</p>
      <codeblock>cd ~/helion/hos/ansible
ansible-playbook -i hosts/localhost config-processor-run.yml -e free_unused_addresses="y"</codeblock>
    </section>
    <section id="serverallocation"><title>Server Allocation</title>
      <p>The Configuration Processor allocates servers to a cluster or resource group in the
        following sequence:</p>
      <ol>
        <li>Any <uicontrol>servers</uicontrol> that are persisted with a state of "allocated" are
          first returned to the <uicontrol>cluster</uicontrol> or <uicontrol>resource
            group</uicontrol>. Such servers are always allocated even if this contradicts the
          cluster size, failure-zones, or list of server roles since it is assumed that these
          servers are actively deployed.</li>
        <li>If the <uicontrol>cluster</uicontrol> or <uicontrol>resource group</uicontrol> is still
          below its minimum size, then any <uicontrol>servers</uicontrol> that are persisted with a
          state of "deleted", but where the server is now listed in the input model (i.e. the server
          was removed but is now back), are added to the group providing they meet the
            <uicontrol>failure-zone</uicontrol> and <uicontrol>server-role</uicontrol> criteria. If
          they do not meet the criteria then a warning is given and the
            <uicontrol>server</uicontrol> remains in a deleted state (i.e. it is still not allocated
          to any other cluster or group). These <uicontrol>servers</uicontrol> are not part of the
          current deployment, and so you must resolve any conflicts before they can be
          redeployed.</li>
        <li>If the <uicontrol>cluster</uicontrol> or <uicontrol>resource group</uicontrol> is still
          below its minimum size, the Configuration Processor will allocate additional
            <uicontrol>servers</uicontrol> that meet the <uicontrol>failure-zone</uicontrol> and
            <uicontrol>server-role</uicontrol> criteria. If the allocation policy is set to "strict"
          then the failure zones of servers already in the cluster or resource group are not
          considered until an equal number of servers has been allocated from each zone.</li>
      </ol>
    </section>
    <section id="servernetworkselection"><title>Server Network Selection</title>
      <p>Once the Configuration Processor has allocated a <uicontrol>server</uicontrol> to a
          <uicontrol>cluster</uicontrol> or <uicontrol>resource group</uicontrol> it uses the
        information in the associated <uicontrol>interface-model</uicontrol> to determine which
          <uicontrol>networks</uicontrol> need to be configured. It does this by:</p>
      <ol>
        <li>Looking at the <uicontrol>service-components</uicontrol> that are to run on the server
          (from the <uicontrol>control-plane</uicontrol> definition)</li>
        <li>Looking to see which <uicontrol>network-group</uicontrol> each of those components is
          attached to (from the <uicontrol>network-groups</uicontrol> definition)</li>
        <li>Looking to see if there are any <uicontrol>network-tags</uicontrol> related to a
            <uicontrol>service-component</uicontrol> running on this server, and if so, adding those
            <uicontrol>network-groups</uicontrol> to the list (also from the
            <uicontrol>network-groups</uicontrol> definition)</li>
        <li>Looking to see if there are any <uicontrol>network-groups</uicontrol> that the
            <uicontrol>interface-model</uicontrol> says should be forced onto the server</li>
        <li>It then searches the <uicontrol>server-group</uicontrol> hierarchy (as described in
            <xref href="#input_model/servergroups_networks">Server Groups and Networks</xref>) to
          find a <uicontrol>network</uicontrol> in each of the <uicontrol>network-groups</uicontrol>
          it needs to attach to</li>
      </ol>
      <p>If there is no <uicontrol>network</uicontrol> available to a server, either because the
          <uicontrol>interface-model</uicontrol> doesn't include the required
          <uicontrol>network-group</uicontrol>, or there is no <uicontrol>network</uicontrol> from
        that group in the appropriate part of the <uicontrol>server-groups</uicontrol> hierarchy,
        then the Configuration Processor will generate an error.</p>
      <p>The Configuration Processor will also generate an error if the
          <uicontrol>server</uicontrol> address does not match any of the networks it will be
        connected to.</p>
    </section>
    <section id="networkroutevalidation"><title>Network Route Validation</title>
      <p>Once the Configuration Processor has allocated all of the required
          <uicontrol>servers</uicontrol> and matched them to the appropriate
          <uicontrol>networks</uicontrol>, it validates that all
          <uicontrol>service-components</uicontrol> have the required network routes to other
          <uicontrol>service-components</uicontrol>.</p>
      <p>It does this by using the data in the services section of the input model which provides
        details of which <uicontrol>service-components</uicontrol> need to connect to each other.
        This data is not configurable by the administrator; however, it is provided as part of the
        HPE Helion OpenStack release.</p>
      <p>For each <uicontrol>server</uicontrol>, the Configuration Processor looks at the list of
          <uicontrol>service-components</uicontrol> it runs and determines the network addresses of
        every other <uicontrol>service-component</uicontrol> it needs to connect to (depending on
        the service, this might be a virtual IP address on a load balancer or a set of addresses for
        the service).</p>
      <p>If the target address is on a <uicontrol>network</uicontrol> that this
          <uicontrol>server</uicontrol> is connected to, then there is no routing required. If the
        target address is on a different <uicontrol>network</uicontrol>, then the Configuration
        Processor looks at each <uicontrol>network</uicontrol> the server is connected to and looks
        at the routes defined in the corresponding <uicontrol>network-group</uicontrol>. If the
          <uicontrol>network-group</uicontrol> provides a route to the
          <uicontrol>network-group</uicontrol> of the target address, then that route is considered
        valid.</p>
      <p><uicontrol>Networks</uicontrol> within the same <uicontrol>network-group</uicontrol> are
        always considered as routed to each other; <uicontrol>networks</uicontrol> from different
          <uicontrol>network-groups</uicontrol> must have an explicit entry in the
          <codeph>routes</codeph> stanza of the <uicontrol>network-group</uicontrol> definition.
        Routes to a named <uicontrol>network-group</uicontrol> are always considered before a
        "default" route.</p>
      <p>A warning is given for any routes which are using the "default" route since it is possible
        that the user did not intend to route this traffic. Such warning can be removed by adding
        the appropriate <uicontrol>network-group</uicontrol> to the list of routes.</p>
      <p>The Configuration Processor provides details of all routes between networks that it is
        expecting to be configured in the <codeph>info/route_info.yml</codeph> file.</p>
      <p>To illustrate how network routing is defined in the input model, consider the following
        example:</p>
      <p>A compute server is configured to run nova-compute which requires access to the Neutron API
        servers and the VSA block storage service. The Neutron API servers have a virtual IP address
        provided by a load balancer in the INTERNAL-API network-group and the VSA service is
        connected to the ISCSI network-group. Nova-compute itself is part of the set of components
        attached by default to the MANAGEMENT network-group. The intention is to have virtual
        machines on the compute server connect to the VSA storage via the ISCSI network.</p>
      <p>The physical network is shown below:</p>
      <p><image href="../media/inputmodel/hphelionopenstack_networkroutevalidation.png"/></p>
      <p><xref href="../media/inputmodel/hphelionopenstack_networkroutevalidation_lg.png"
          scope="external" format="html">Download a high-res version</xref></p>
      <p>The corresponding entries in the <uicontrol>network-groups</uicontrol> are:</p>
      <codeblock>
  - name: INTERNAL-API  
    hostname-suffix: intapi
        
    load-balancers:
       - provider: ip-cluster
         name: lb
         components:
           - default
         roles:
           - internal
           - admin
        
       - name: MANAGEMENT
         hostname-suffix: mgmt
         hostname: true
        
         component-endpoints:
           - default
        
         routes:
           - INTERNAL-API
           - default
        
       - name: ISCSI
         hostname-suffix: iscsi
         
         component-endpoints:
            - vsa</codeblock>
      <p>And the <uicontrol>interface-model</uicontrol> for the compute server looks like this:</p>
      <codeblock>
  - name: INTERFACE_SET_COMPUTE
    network-interfaces:
      - name: BOND0
        device:
           name: bond0
        bond-data:
           options:
              mode: active-backup
              miimon: 200
              primary: hed5
           provider: linux
           devices:
              - name: hed4
              - name: hed5
        network-groups:
          - MANAGEMENT
          - ISCSI</codeblock>
      <p>When validating the route from nova-compute to the Neutron API, the Configuration Processor
        will detect that the target address is on a network in the INTERNAL-API network group, and
        that the MANAGEMENT network (which is connected to the compute server) provides a route to
        this network, and thus considers this route valid.</p>
      <p>When validating the route from nova-compute to VSA, the Configuration Processor will detect
        that the target address is on a network in the ISCSI network group. However, because there
        is no service component on the compute server connected to the ISCSI network (according to
        the network-group definition) the ISCSI network will not have been configured on the compute
        server (see <xref href="#input_model/servernetworkselection">Server Network
        Selection</xref>. The Configuration Processor will detect that the MANAGEMENT network-group
        provides a "default" route and thus considers the route as valid (it is, of course, valid to
        route ISCSI traffic); however, because this is using the default route, a warning will be
        issued:</p>
      <codeblock>#   route-generator-2.0       WRN: Default routing used between networks
The following networks are using a 'default' route rule. To remove this warning 
either add an explicit route in the source network group or force the network to 
attach in the interface model used by the servers.
  MANAGEMENT-NET-RACK1 to ISCSI-NET
    helion-ccp-comp0001
  MANAGEMENT-NET-RACK 2 to ISCSI-NET
    helion-ccp-comp0002
  MANAGEMENT-NET-RACK 3 to SCSI-NET
    helion-ccp-comp0003</codeblock>
      <p>To remove this warning, you can either add ISCSI to the list of routes in the MANAGEMENT
        network group (routed ISCSI traffic is still a valid configuration) or force the compute
        server to attach to the ISCSI network-group by adding it as a forced-network-group in the
        interface-model, like this:</p>
      <codeblock>
  - name: INTERFACE_SET_COMPUTE
      network-interfaces:
        - name: BOND0
          device:
            name: bond0
          bond-data:
            options:
               mode: active-backup
               miimon: 200
               primary: hed5
            provider: linux
            devices:
               - name: hed4
               - name: hed5
          network-groups:
             - MANAGEMENT
          forced-network-groups:
             - ISCSI</codeblock>
      <p>With the attachment to the ISCSI network group forced, the Configuration Processor will
        attach the compute server to a network in that group and validate the route as either being
        direct or between networks in the same network-group.</p>
      <p>The generated <codeph>route_info.yml</codeph> file will include entries such as the
        following, showing the routes that are still expected to be configured between networks in
        the MANAGEMENT network group and the INTERNAL-API network group.</p>
      <codeblock>
  MANAGEMENT-NET-RACK1:
     INTERNAL-API-NET:
        default: false
        used_by:
           nova-compute:
              neutron-server:
              - helion-ccp-comp0001
   MANAGEMENT-NET-RACK2:
     INTERNAL-API-NET:
        default: false
        used_by:
          nova-compute:
            neutron-server:
            - helion-ccp-comp0003</codeblock>
    </section>

    <section id="configneutronprovidervlans"><title>Configuring Neutron Provider VLANs</title>
      <p>Neutron provider VLANs are networks that map directly to an 802.1Q VLAN in the cloud
        providerâ€™s physical network infrastructure. There are four aspects to a provider VLAN
        configuration:</p>
      <ul>
        <li>Network infrastructure configuration (e.g. the top-of-rack switch)</li>
        <li>Server networking configuration (for compute nodes and Neutron network nodes)</li>
        <li>Neutron configuration file settings</li>
        <li>Creation of the corresponding network objects in Neutron</li>
      </ul>
      <p>The physical network infrastructure must be configured to convey the provider VLAN traffic
        as tagged VLANs to the cloud compute nodes and Neutron network nodes. Configuration of the
        physical network infrastructure is outside the scope of the HPE Helion OpenStack 2.0
        software.</p>
      <p>HPE Helion OpenStack 2.0 automates the server networking configuration and the Neutron
        configuration based on information in the cloud definition. To configure the system for
        provider VLANs, specify the <codeph>neutron.networks.vlan</codeph> tag with a
          <codeph>provider-physical-network</codeph> attribute on one or more
          <uicontrol>network-groups</uicontrol> as described in the <xref
          href="#input_model/neutron.networks.vlan">Network Groups</xref> section. For example (some
        attributes omitted for brevity):</p>
      <codeblock>
  network-groups:

    - name: NET_GROUP_A
      tags:
        - neutron.networks.vlan:
              provider-physical-network: physnet1
        
    - name: NET_GROUP_B
      tags:
        - neutron.networks.vlan:
              provider-physical-network: physnet2</codeblock>
      <p>A <uicontrol>network-group</uicontrol> is associated with a server network interface via an
          <uicontrol>interface-model</uicontrol> as described in the <xref
          href="#input_model/co_interfacemodels">Interface Models</xref> section. For example (some
        attributes omitted for brevity):</p>
      <codeblock>
  interface-models:
     - name: INTERFACE_SET_X
       network-interfaces:
        - device:
              name: bond0
          network-groups:
            - NET_GROUP_A
        - device:
              name: hed3
          network-groups:
            - NET_GROUP_B</codeblock>
      <p>A <uicontrol>network-group</uicontrol> used for provider VLANs may contain only a single HP
        Helion OpenStack <uicontrol>network</uicontrol>, because that VLAN must span all compute
        nodes and any Neutron network nodes/controllers (i.e. it is a single L2 segment). The HP
        Helion OpenStack <uicontrol>network</uicontrol> must be defined with <codeph>tagged-vlan:
          false</codeph>, otherwise a linux VLAN network interface will be created. For example:</p>
      <codeblock>
  networks:
     - name: NET_A
       tagged-vlan: false
       network-group: NET_GROUP_A
     - name: NET_B
       tagged-vlan: false
       network-group: NET_GROUP_B</codeblock>
      <p>When the cloud is deployed, HPE Helion OpenStack 2.0 will create the appropriate bridges on
        the servers, and set the appropriate attributes in the Neutron configuration files (e.g.
        bridge_mappings).</p>
      <p>After the cloud has been deployed, create Neutron network objects for each provider VLAN
        using the Neutron CLI:</p>
      <codeblock>neutron net-create --provider:network_type vlan --provider:physical_network physnet1 --provider:segmentation_id 101 mynet101</codeblock>
      <codeblock>neutron net-create --provider:network_type vlan --provider:physical_network physnet2 --provider:segmentation_id 234 mynet234</codeblock>
    </section>
    <section id="cpinfofiles">
      <title>Configuration Processor Information Files</title>
      <p>In addition to producing all of the data needed to deploy and configure the cloud, the
        Configuration Processor also creates a number of information files that provide details of
        the resulting configuration.</p>
      <p>These files can be found in <codeph>~/helion/my_cloud/info</codeph> after the first
        Configuration Processor run. This directory is also rebuilt each time the Configuration
        Processor is run.</p>
      <p>Most of the files are in YAML format, allowing them to be used in further automation tasks
        if required.</p>
      <table frame="all" rowsep="1" colsep="1" id="table">
        <tgroup cols="2">
          <colspec colnum="1" colname="col1"/>
          <colspec colnum="2" colname="col2"/>
          <thead>
            <row>
              <entry>File</entry>
              <entry>Provides details of</entry>
            </row>
          </thead>
          <tbody>
            <row>
              <entry>address_info.yml </entry>
              <entry>IP address assignments on each network</entry>
            </row>
            <row>
              <entry>net_info.yml </entry>
              <entry>IP addresses assigned to services. For example, this provides the data needed
                to complete the configuration of VSA clusters.</entry>
            </row>
            <row>
              <entry>server_info.yml</entry>
              <entry>How servers have been allocated, including their network configuration. Allows
                details of a server to be found from its ID</entry>
            </row>
            <row>
              <entry>firewall_info.yml </entry>
              <entry>All ports that are open on each network by the firewall configuration. Can be
                used if you want to configure an additional firewall in front of the API network,
                for example.</entry>
            </row>
            <row>
              <entry>route_info.yml </entry>
              <entry>Routes that need to be configured between networks. </entry>
            </row>
            <row>
              <entry>service_info.yml</entry>
              <entry>Details of where components of each service are deployed</entry>
            </row>
            <row>
              <entry>CloudDiagram.txt</entry>
              <entry>A pictorial representation of the cloud</entry>
            </row>
            <row>
              <entry>explain.txt </entry>
              <entry>An explanation of the decisions the Configuration Processor has made when
                allocating servers and networks</entry>
            </row>
          </tbody>
        </tgroup>
      </table>
      <p>The following examples are taken from the <codeph>entry-scale-kvm-vsa</codeph> example:</p>
    </section>
    <section id="address_info_yml"><title>Address_info.yml</title>
      <p>This file provides details of all the IP addresses allocated by the Configuration
        Processor:</p>
      <codeblock>
  &#60;Network Groups>
     &#60;List of Networks>
        &#60;IP Address>
           &#60;List of Aliases></codeblock>
      <p>Example:</p>
      <codeblock>
  EXTERNAL-API:
     EXTERNAL-API-NET:
        10.0.1.2:
           - helion-cp1-c1-m1-extapi
        10.0.1.3:
           - helion-cp1-c1-m2-extapi
        10.0.1.4:
           - helion-cp1-c1-m3-extapi
        10.0.1.5:
           - helion-cp1-vip-public-SWF-PRX-extapi
           - helion-cp1-vip-public-FRE-API-extapi
           - helion-cp1-vip-public-GLA-API-extapi
           - helion-cp1-vip-public-HEA-ACW-extapi
           - helion-cp1-vip-public-HEA-ACF-extapi
           - helion-cp1-vip-public-NEU-SVR-extapi
           - helion-cp1-vip-public-KEY-API-extapi
           - helion-cp1-vip-public-MON-API-extapi
           - helion-cp1-vip-public-HEA-API-extapi
           - helion-cp1-vip-public-NOV-API-extapi
           - helion-cp1-vip-public-CND-API-extapi
           - helion-cp1-vip-public-CEI-API-extapi
           - helion-cp1-vip-public-SHP-API-extapi
           - helion-cp1-vip-public-OPS-WEB-extapi
           - helion-cp1-vip-public-HZN-WEB-extapi
           - helion-cp1-vip-public-NOV-VNC-extapi
  EXTERNAL-VM:
     EXTERNAL-VM-NET: {}
  GUEST:
     GUEST-NET:
        10.1.1.2:
           - helion-cp1-c1-m1-guest
        10.1.1.3:
           - helion-cp1-c1-m2-guest
        10.1.1.4:
           - helion-cp1-c1-m3-guest
        10.1.1.5:
           - helion-cp1-comp0001-guest
  MANAGEMENT:
  ...</codeblock>
    </section>
    <section id="firewall_info_yml"><title>Firewall_info.yml</title>
      <p>This file provides details of all the network ports that will be opened on the deployed
        cloud. Data is ordered by network. If you want to configure an external firewall in front of
        the External API network, then you would need to open the ports listed in that section.</p>
      <codeblock>
  &#60;Network Name>
     List of:
        &#60;Port>
        &#60;Protocol>
        &#60;List of IP Addresses>
        &#60;List of Components></codeblock>
      <p>Example:</p>
      <codeblock>
  EXTERNAL-API:
  -   addresses:
      - 10.0.1.5
      components:
      - horizon
      port: '443'
      protocol: tcp
  -   addresses:
      - 10.0.1.5
      components:
      - keystone-api
      port: '5000'
      protocol: tcp</codeblock>
      <p><i>Port 443 (tcp) is open on network EXTERNAL-API for address 10.0.1.5 because it is used
          by Horizon</i></p>
      <p><i>Port 5000 (tcp) is open on network EXTERNAL-API for address 10.0.1.5 because it is used
          by Keystone API</i></p>
    </section>
    <section id="net_info_yml"><title>Net_info.yml</title>
      <p>This file provides details of IP addresses that have been allocated for a service. This
        data is typically used for service configuration after the initial deployment.</p>
      <codeblock>
   service_ips:
      &#60;Service-Name>
          control_plane:  &#60;Control Plane Name>
          cluster: &#60;Cluster or Resource Name>
          network:  &#60;Network Name>
          cluster_ip:
              hostname:  &#60;Hostname alias of address allocated for the cluster>
              ip_address: &#60;IP address allocated for the cluster>
          hosts: (list)
              hostname:  &#60;Hostname of server in the cluster>
              ip_address: &#60;IP address of server the cluster></codeblock>
      <p>Example:</p>
      <codeblock>
   service_ips:
      vsa:
      -   cluster: vsa
          cluster_ip:
              hostname: helion-cp1-vsa-VSA-BLK-mgmt
              ip_address: 192.168.10.7
          control_plane: control-plane-1
          hosts:
          -   hostname: helion-cp1-vsa0001-VSA-BLK-mgmt
              ip_address: 192.168.10.2
          -   hostname: helion-cp1-vsa0002-VSA-BLK-mgmt
              ip_address: 192.168.10.8
          -   hostname: helion-cp1-vsa0003-VSA-BLK-mgmt
              ip_address: 192.168.10.12
          network: MANAGEMENT-NET</codeblock>
      <p><i>Resource group "vsa" in "control-plane-1" has been allocated 192.168.10.7 on network
          MANAGEMENT-NET as a cluster address and consists of 3 servers with addresses 192.168.10.2,
          192.168.192.8, and 192.168.10.12.</i></p>
    </section>
    <section id="route_info_yml"><title>Route_info.yml</title>
      <p>This file provides details of routes between networks that need to be configured. Available
        routes are defined in the input model as part of the <uicontrol>network-groups</uicontrol>
        data; this file shows which routes will actually be used. HPE Helion OpenStack will
        reconfigure routing rules on the servers, you must configure the corresponding routes within
        your physical network. Routes must be configured to be symmetrical -- only the direction in
        which a connection is initiated is captured in this file.</p>
      <p>Note that simple models may not require any routes, with all servers being attached to
        common L3 networks. The following example is taken from the
          <codeph>tech-preview/mid-scale-kvm-vsa</codeph> example.</p>
      <codeblock>
  &#60;Source-Network-Name>
      &#60;Target-Network-Name>
           default:   &#60;true if this is this the result of a "default" route rule>
           used_by:
                &#60;source-service>
                     &#60;target-service>
                     &#60;list of hosts using this route></codeblock>
      <p>Example:</p>
      <codeblock>
MANAGEMENT-NET-RACK1:
    INTERNAL-API-NET:
         default: false
         used_by:
            ceilometer-client:
            ceilometer-api:
            - helion-cp1-mtrmon-m1
            keystone-api:
            - helion-cp1-mtrmon-m1
     MANAGEMENT-NET-RACK2:
         default: false
         used_by:
            cinder-backup:
            rabbitmq:
            - helion-cp1-core-m1</codeblock>
      <p><i>A route is required from network <b>MANAGEMENT-NET-RACK1</b> to network
            <b>INTERNAL-API-NET</b> so that <b>ceilometer-client</b> can connect to
            <b>ceilometer-api</b> from server <b>helion-cp1-mtrmon-m1</b> and to <b>keystone-api
          </b>from the same server.</i></p>
      <p><i>A route is required from network <b>MANAGEMENT-NET-RACK1</b> to network
            <b>MANAGEMENT-NET-RACK2</b> so that <b>cinder-backup</b> can connect to <b>rabbitmq</b>
          from server <b>helion-cp1-core-m1</b></i></p>
    </section>
    <section id="server_info_yml"><title>Server_info.yml</title>
      <p>This file provides details of how servers have been allocated by the Configuration
        Processor. This provides the easiest way to find where a specific physical server
        (identified by <codeph>server-id</codeph>) is being used.</p>
      <codeblock>
   &#60;Server-id>
         failure-zone: &#60;failure zone that the server was allocated from>
         hostname: &#60;hostname of the server>
         net_data: &#60;network configuration>
         state: &#60; "allocated" | "available" ></codeblock>
      <p>Example:</p>
      <codeblock>
   controller1:
         failure-zone: AZ1
         hostname: helion-cp1-c1-m1-mgmt
         net_data:
              BOND0:
                   EXTERNAL-API-NET:
                       addr: 10.0.1.2
                       tagged-vlan: true
                       vlan-id: 101
                   EXTERNAL-VM-NET:
                       addr: null
                       tagged-vlan: true
                       vlan-id: 102
                   GUEST-NET:
                       addr: 10.1.1.2
                       tagged-vlan: true
                       vlan-id: 103
                   MANAGEMENT-NET:
                       addr: 192.168.10.3
                       tagged-vlan: false
                       vlan-id: 100
         state: allocated</codeblock>
    </section>
    <section id="service_info_yml"><title>Service_info.yml</title>
      <p>This file provides details of how services are distributed across the cloud.</p>
      <codeblock>
  #60;control-plane>
      &#60;service>
          &#60;service component>
               &#60;list of hosts></codeblock>
      <p>Example:</p>
      <codeblock>
  control-plane-1:
        neutron:
             neutron-client:
                - helion-cp1-c1-m1-mgmt
                - helion-cp1-c1-m2-mgmt
                - helion-cp1-c1-m3-mgmt
             neutron-dhcp-agent:
                - helion-cp1-c1-m1-mgmt
                - helion-cp1-c1-m2-mgmt
                - helion-cp1-c1-m3-mgmt
             neutron-l3-agent:
                 - helion-cp1-comp0001-mgmt
             neutron-lbaasv2-agent:
                 - helion-cp1-comp0001-mgmt
        ...</codeblock>
    </section>
    <section id="explain_txt"><title>Explain.txt</title>
      <p>This file provides details of the server allocation and network configuration decisions the
        Configuration Processor has made. The sequence of information recorded is:</p>
      <ul>
        <li>Any service components that are automatically added</li>
        <li>Allocation of servers to clusters and resource groups</li>
        <li>Resolution of the network configuration for each server</li>
        <li>Resolution of the network configuration of each load balancer</li>
      </ul>
      <p>Example:</p>
      <codeblock>
        Add required services to control plane control-plane-1
        ======================================================
        control-plane-1: Added nova-metadata required by nova-api
        control-plane-1: Added swift-common required by swift-proxy
        control-plane-1: Added swift-rsync required by swift-account
        
        Allocate Servers for control plane control-plane-1
        ==================================================
        
        cluster: cluster1
        -----------------
          Persisted allocation for server 'controller1' (AZ1)
          Persisted allocation for server 'controller2' (AZ2)
          Searching for server with role ['CONTROLLER-ROLE'] in zones: set(['AZ3'])
          Allocated server 'controller3' (AZ3)
        
        resource: vsa
        -------------
          Persisted allocation for server 'vsa1' (AZ1)
          Persisted allocation for server 'vsa2' (AZ2)
          Persisted allocation for server 'vsa3' (AZ3)
          Searching for server with role ['VSA-ROLE'] in zones: set(['AZ1', 'AZ2', 'AZ3'])
        
        resource: compute
        -----------------
          Persisted allocation for server 'compute1' (AZ1)
          Searching for server with role ['COMPUTE-ROLE'] in zones: set(['AZ1', 'AZ2', 'AZ3'])
        
        Resolve Networks for Servers
        ============================
        server: helion-cp1-c1-m1
        ------------------------
          add EXTERNAL-API for component ip-cluster
          add MANAGEMENT for component ip-cluster
          add MANAGEMENT for lifecycle-manager (default)
          add MANAGEMENT for ntp-server (default)
          ...
          add MANAGEMENT for swift-rsync (default)
          add GUEST for tag neutron.networks.vxlan (neutron-openvswitch-agent)
          add EXTERNAL-VM for tag neutron.l3_agent.external_network_bridge (neutron-vpn-agent)
          Using persisted address 10.0.1.2 for server helion-cp1-c1-m1 on network EXTERNAL-API-NET
          Using address 192.168.10.3 for server helion-cp1-c1-m1 on network MANAGEMENT-NET
          Using persisted address 10.1.1.2 for server helion-cp1-c1-m1 on network GUEST-NET
        
        â€¦
        Define load balancers
        =====================
        
        Load balancer: extlb
        --------------------
          Using persisted address 10.0.1.5 for vip extlb helion-cp1-vip-extlb-extapi on network EXTERNAL-API-NET
          Add nova-api for roles ['public'] due to 'default'
          Add glance-api for roles ['public'] due to 'default'
          ...
        
        Map load balancers to providers
        ===============================
        
        Network EXTERNAL-API-NET
        ------------------------
          10.0.1.5: ip-cluster nova-api roles: ['public'] vip-port: 8774 host-port: 8774
          10.0.1.5: ip-cluster glance-api roles: ['public'] vip-port: 9292 host-port: 9292
          10.0.1.5: ip-cluster keystone-api roles: ['public'] vip-port: 5000 host-port: 5000
          10.0.1.5: ip-cluster swift-proxy roles: ['public'] vip-port: 8080 host-port: 8080
          10.0.1.5: ip-cluster monasca-api roles: ['public'] vip-port: 8070 host-port: 8070
          10.0.1.5: ip-cluster sherpa-api roles: ['public'] vip-port: 21131 host-port: 21131
          10.0.1.5: ip-cluster heat-api-cfn roles: ['public'] vip-port: 8000 host-port: 8000
          10.0.1.5: ip-cluster ops-console-web roles: ['public'] vip-port: 9095 host-port: 9095
          10.0.1.5: ip-cluster heat-api roles: ['public'] vip-port: 8004 host-port: 8004
          10.0.1.5: ip-cluster nova-novncproxy roles: ['public'] vip-port: 6080 host-port: 6080
          10.0.1.5: ip-cluster neutron-server roles: ['public'] vip-port: 9696 host-port: 9696
          10.0.1.5: ip-cluster heat-api-cloudwatch roles: ['public'] vip-port: 8003 host-port: 8003
          10.0.1.5: ip-cluster ceilometer-api roles: ['public'] vip-port: 8777 host-port: 8777
          10.0.1.5: ip-cluster freezer-api roles: ['public'] vip-port: 9090 host-port: 9090
          10.0.1.5: ip-cluster horizon roles: ['public'] vip-port: 443 host-port: 80
          10.0.1.5: ip-cluster cinder-api roles: ['public'] vip-port: 8776 host-port: 8776</codeblock>
    </section>
    <section id="clouddiagram_txt"><title>Cloud_diagram.txt</title>
      <p>This file provides a pictorial representation of the cloud.</p>
      <p>Example:</p>
      <codeblock>
        +-ControlPlane: region1 (control-plane-1)----------------------------------------------------------------------------------------------------------------------+
        |                                                                                                                                                              |
        | +-Cluster cluster1 ()--------------------------------------------------------------------------------------------------------------------------------------+ |
        | |                                                                                                                                                          | |
        | | +-helion-cp1-c1-m1 (192.168.10.3)--------------+    +-helion-cp1-c1-m2 (192.168.10.4)--------------+    +-helion-cp1-c1-m3 (192.168.10.5)--------------+ | |
        | | |                                              |    |                                              |    |                                              | | |
        | | | ceilometer                                   |    | ceilometer                                   |    | ceilometer                                   | | |
        | | |   ceilometer-agent-central                   |    |   ceilometer-agent-central                   |    |   ceilometer-agent-central                   | | |
        | | |   ceilometer-agent-notification              |    |   ceilometer-agent-notification              |    |   ceilometer-agent-notification              | | |
        | | |   ceilometer-api                             |    |   ceilometer-api                             |    |   ceilometer-api                             | | |
        | | |   ceilometer-client                          |    |   ceilometer-client                          |    |   ceilometer-client                          | | |
        | | |   ceilometer-collector                       |    |   ceilometer-collector                       |    |   ceilometer-collector                       | | |
        | | |   ceilometer-common                          |    |   ceilometer-common                          |    |   ceilometer-common                          | | |
        | | |   ceilometer-expirer                         |    |   ceilometer-expirer                         |    |   ceilometer-expirer                         | | |
        | | | cinder                                       |    | cinder                                       |    | cinder                                       | | |
        | | |   cinder-api                                 |    |   cinder-api                                 |    |   cinder-api                                 | | |
        | | |   cinder-backup                              |    |   cinder-backup                              |    |   cinder-backup                              | | |
        | | |   cinder-client                              |    |   cinder-client                              |    |   cinder-client                              | | |
        | | |   cinder-scheduler                           |    |   cinder-scheduler                           |    |   cinder-scheduler                           | | |
        | | |   cinder-volume                              |    |   cinder-volume                              |    |   cinder-volume                              | | |
        | | | foundation                                   |    | foundation                                   |    | foundation                                   | | |
        | | |   apache2                                    |    |   apache2                                    |    |   apache2                                    | | |
        | | |   ip-cluster                                 |    |   ip-cluster                                 |    |   ip-cluster                                 | | |
        | | |   kafka                                      |    |   kafka                                      |    |   kafka                                      | | |
        | | |   memcached                                  |    |   memcached                                  |    |   memcached                                  | | |
        | | |   mysql                                      |    |   mysql                                      |    |   mysql                                      | | |
        | | |   ntp-server                                 |    |   ntp-server                                 |    |   ntp-server                                 | | |
        | | |   openstack-client                           |    |   openstack-client                           |    |   openstack-client                           | | |
        | | |   rabbitmq                                   |    |   rabbitmq                                   |    |   rabbitmq                                   | | |
        | | |   sherpa-api                                 |    |   sherpa-api                                 |    |   sherpa-api                                 | | |
        | | |   storm                                      |    |   storm                                      |    |   storm                                      | | |
        | | |   stunnel                                    |    |   stunnel                                    |    |   stunnel                                    | | |
        | | |   swift-common                               |    |   swift-common                               |    |   swift-common                               | | |
        | | |   swift-rsync                                |    |   swift-rsync                                |    |   swift-rsync                                | | |
        | | |   vertica                                    |    |   vertica                                    |    |   vertica                                    | | |
        | | |   zookeeper                                  |    |   zookeeper                                  |    |   zookeeper                                  | | |
        | | | freezer                                      |    | freezer                                      |    | freezer                                      | | |
        | | |   freezer-agent                              |    |   freezer-agent                              |    |   freezer-agent                              | | |
        | | |   freezer-api                                |    |   freezer-api                                |    |   freezer-api                                | | |
        | | | glance                                       |    | glance                                       |    | glance                                       | | |
        | | |   glance-api                                 |    |   glance-api                                 |    |   glance-api                                 | | |
        | | |   glance-client                              |    |   glance-client                              |    |   glance-client                              | | |
        | | |   glance-registry                            |    |   glance-registry                            |    |   glance-registry                            | | |
        | | | heat                                         |    | heat                                         |    | heat                                         | | |
        | | |   heat-api                                   |    |   heat-api                                   |    |   heat-api                                   | | |
        | | |   heat-api-cfn                               |    |   heat-api-cfn                               |    |   heat-api-cfn                               | | |
        | | |   heat-api-cloudwatch                        |    |   heat-api-cloudwatch                        |    |   heat-api-cloudwatch                        | | |
        | | |   heat-client                                |    |   heat-client                                |    |   heat-client                                | | |
        | | |   heat-engine                                |    |   heat-engine                                |    |   heat-engine                                | | |
        | | | horizon                                      |    | horizon                                      |    | horizon                                      | | |
        | | |   horizon                                    |    |   horizon                                    |    |   horizon                                    | | |
        | | | keystone                                     |    | keystone                                     |    | keystone                                     | | |
        | | |   keystone-api                               |    |   keystone-api                               |    |   keystone-api                               | | |
        | | |   keystone-client                            |    |   keystone-client                            |    |   keystone-client                            | | |
        | | | logging                                      |    | logging                                      |    | logging                                      | | |
        | | |   logging-producer                           |    |   logging-producer                           |    |   logging-producer                           | | |
        | | |   logging-server                             |    |   logging-server                             |    |   logging-server                             | | |
        | | | monasca                                      |    | monasca                                      |    | monasca                                      | | |
        | | |   monasca-agent                              |    |   monasca-agent                              |    |   monasca-agent                              | | |
        | | |   monasca-api                                |    |   monasca-api                                |    |   monasca-api                                | | |
        | | |   monasca-client                             |    |   monasca-client                             |    |   monasca-client                             | | |
        | | |   monasca-notifier                           |    |   monasca-notifier                           |    |   monasca-notifier                           | | |
        | | |   monasca-persister                          |    |   monasca-persister                          |    |   monasca-persister                          | | |
        | | |   monasca-threshold                          |    |   monasca-threshold                          |    |   monasca-threshold                          | | |
        | | | neutron                                      |    | neutron                                      |    | neutron                                      | | |
        | | |   neutron-client                             |    |   neutron-client                             |    |   neutron-client                             | | |
        | | |   neutron-dhcp-agent                         |    |   neutron-dhcp-agent                         |    |   neutron-dhcp-agent                         | | |
        | | |   neutron-metadata-agent                     |    |   neutron-metadata-agent                     |    |   neutron-metadata-agent                     | | |
        | | |   neutron-ml2-plugin                         |    |   neutron-ml2-plugin                         |    |   neutron-ml2-plugin                         | | |
        | | |   neutron-openvswitch-agent                  |    |   neutron-openvswitch-agent                  |    |   neutron-openvswitch-agent                  | | |
        | | |   neutron-server                             |    |   neutron-server                             |    |   neutron-server                             | | |
        | | |   neutron-vpn-agent                          |    |   neutron-vpn-agent                          |    |   neutron-vpn-agent                          | | |
        | | | nova                                         |    | nova                                         |    | nova                                         | | |
        | | |   nova-api                                   |    |   nova-api                                   |    |   nova-api                                   | | |
        | | |   nova-client                                |    |   nova-client                                |    |   nova-client                                | | |
        | | |   nova-conductor                             |    |   nova-conductor                             |    |   nova-conductor                             | | |
        | | |   nova-console-auth                          |    |   nova-console-auth                          |    |   nova-console-auth                          | | |
        | | |   nova-metadata                              |    |   nova-metadata                              |    |   nova-metadata                              | | |
        | | |   nova-novncproxy                            |    |   nova-novncproxy                            |    |   nova-novncproxy                            | | |
        | | |   nova-scheduler                             |    |   nova-scheduler                             |    |   nova-scheduler                             | | |
        | | | operations                                   |    | operations                                   |    | operations                                   | | |
        | | |   lifecycle-manager                          |    |   lifecycle-manager                          |    |   lifecycle-manager                          | | |
        | | |   lifecycle-manager-target                   |    |   lifecycle-manager-target                   |    |   lifecycle-manager-target                   | | |
        | | |   ops-console-monitor                        |    |   ops-console-monitor                        |    |   ops-console-monitor                        | | |
        | | |   ops-console-web                            |    |   ops-console-web                            |    |   ops-console-web                            | | |
        | | | swift                                        |    | swift                                        |    | swift                                        | | |
        | | |   swift-account                              |    |   swift-account                              |    |   swift-account                              | | |
        | | |   swift-client                               |    |   swift-client                               |    |   swift-client                               | | |
        | | |   swift-container                            |    |   swift-container                            |    |   swift-container                            | | |
        | | |   swift-object                               |    |   swift-object                               |    |   swift-object                               | | |
        | | |   swift-proxy                                |    |   swift-proxy                                |    |   swift-proxy                                | | |
        | | |   swift-ring-builder                         |    |   swift-ring-builder                         |    |   swift-ring-builder                         | | |
        | | | vsa-storage                                  |    | vsa-storage                                  |    | vsa-storage                                  | | |
        | | |   cmc-service                                |    |   cmc-service                                |    |   cmc-service                                | | |
        | | |                                              |    |                                              |    |                                              | | |
        | | | -------------------------------------------- |    | -------------------------------------------- |    | -------------------------------------------- | | |
        | | |                                              |    |                                              |    |                                              | | |
        | | | bond0 (hed3, hed4)                           |    | bond0 (hed3, hed4)                           |    | bond0 (hed3, hed4)                           | | |
        | | |   EXTERNAL-API-NET (10.0.1.2)                |    |   EXTERNAL-API-NET (10.0.1.3)                |    |   EXTERNAL-API-NET (10.0.1.4)                | | |
        | | |   EXTERNAL-VM-NET                            |    |   EXTERNAL-VM-NET                            |    |   EXTERNAL-VM-NET                            | | |
        | | |   GUEST-NET (10.1.1.2)                       |    |   GUEST-NET (10.1.1.3)                       |    |   GUEST-NET (10.1.1.4)                       | | |
        | | |   MANAGEMENT-NET (192.168.10.3)              |    |   MANAGEMENT-NET (192.168.10.4)              |    |   MANAGEMENT-NET (192.168.10.5)              | | |
        | | |                                              |    |                                              |    |                                              | | |
        | | +----------------------------------------------+    +----------------------------------------------+    +----------------------------------------------+ | |
        | |                                                                                                                                                          | |
        | +----------------------------------------------------------------------------------------------------------------------------------------------------------+ |
        |                                                                                                                                                              |
        | +-compute------------------------------------------+                                                                                                         |
        | |                                                  |                                                                                                         |
        | | +-COMPUTE-ROLE (AZ1) (1 servers)---------------+ |                                                                                                         |
        | | |                                              | |                                                                                                         |
        | | | foundation                                   | |                                                                                                         |
        | | |   ntp-client                                 | |                                                                                                         |
        | | |   stunnel                                    | |                                                                                                         |
        | | | freezer                                      | |                                                                                                         |
        | | |   freezer-agent                              | |                                                                                                         |
        | | | logging                                      | |                                                                                                         |
        | | |   logging-producer                           | |                                                                                                         |
        | | | monasca                                      | |                                                                                                         |
        | | |   monasca-agent                              | |                                                                                                         |
        | | | neutron                                      | |                                                                                                         |
        | | |   neutron-l3-agent                           | |                                                                                                         |
        | | |   neutron-lbaasv2-agent                      | |                                                                                                         |
        | | |   neutron-metadata-agent                     | |                                                                                                         |
        | | |   neutron-openvswitch-agent                  | |                                                                                                         |
        | | | nova                                         | |                                                                                                         |
        | | |   nova-compute                               | |                                                                                                         |
        | | |   nova-compute-kvm                           | |                                                                                                         |
        | | | operations                                   | |                                                                                                         |
        | | |   lifecycle-manager-target                   | |                                                                                                         |
        | | |                                              | |                                                                                                         |
        | | | -------------------------------------------- | |                                                                                                         |
        | | |                                              | |                                                                                                         |
        | | | bond0 (hed3, hed4)                           | |                                                                                                         |
        | | |   EXTERNAL-VM-NET                            | |                                                                                                         |
        | | |   GUEST-NET (10.1.1.0/24)                    | |                                                                                                         |
        | | |   MANAGEMENT-NET (192.168.10.0/24)           | |                                                                                                         |
        | | |                                              | |                                                                                                         |
        | | +----------------------------------------------+ |                                                                                                         |
        | +--------------------------------------------------+                                                                                                         |
        |                                                                                                                                                              |
        | +-vsa------------------------------------------------------------------------------------------------------------------------------------------------------+ |
        | |                                                                                                                                                          | |
        | | +-VSA-ROLE (AZ1) (1 servers)-------------------+    +-VSA-ROLE (AZ2) (1 servers)-------------------+    +-VSA-ROLE (AZ3) (1 servers)-------------------+ | |
        | | |                                              |    |                                              |    |                                              | | |
        | | | foundation                                   |    | foundation                                   |    | foundation                                   | | |
        | | |   ntp-client                                 |    |   ntp-client                                 |    |   ntp-client                                 | | |
        | | |   stunnel                                    |    |   stunnel                                    |    |   stunnel                                    | | |
        | | | freezer                                      |    | freezer                                      |    | freezer                                      | | |
        | | |   freezer-agent                              |    |   freezer-agent                              |    |   freezer-agent                              | | |
        | | | logging                                      |    | logging                                      |    | logging                                      | | |
        | | |   logging-producer                           |    |   logging-producer                           |    |   logging-producer                           | | |
        | | | monasca                                      |    | monasca                                      |    | monasca                                      | | |
        | | |   monasca-agent                              |    |   monasca-agent                              |    |   monasca-agent                              | | |
        | | | operations                                   |    | operations                                   |    | operations                                   | | |
        | | |   lifecycle-manager-target                   |    |   lifecycle-manager-target                   |    |   lifecycle-manager-target                   | | |
        | | | vsa-storage                                  |    | vsa-storage                                  |    | vsa-storage                                  | | |
        | | |   vsa                                        |    |   vsa                                        |    |   vsa                                        | | |
        | | |                                              |    |                                              |    |                                              | | |
        | | | -------------------------------------------- |    | -------------------------------------------- |    | -------------------------------------------- | | |
        | | |                                              |    |                                              |    |                                              | | |
        | | | bond0 (hed3, hed4)                           |    | bond0 (hed3, hed4)                           |    | bond0 (hed3, hed4)                           | | |
        | | |   MANAGEMENT-NET (192.168.10.0/24)           |    |   MANAGEMENT-NET (192.168.10.0/24)           |    |   MANAGEMENT-NET (192.168.10.0/24)           | | |
        | | |                                              |    |                                              |    |                                              | | |
        | | +----------------------------------------------+    +----------------------------------------------+    +----------------------------------------------+ | |
        | +----------------------------------------------------------------------------------------------------------------------------------------------------------+ |
        |                                                                                                                                                              |
        +--------------------------------------------------------------------------------------------------------------------------------------------------------------+
      </codeblock>
    </section>
  </conbody>
</concept>
