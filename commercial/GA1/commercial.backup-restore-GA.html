<!DOCTYPE html>
<html>
<head>
<title>commercial.backup-restore-GA</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<style type="text/css">
/* GitHub stylesheet for MarkdownPad (http://markdownpad.com) */
/* Author: Nicolas Hery - http://nicolashery.com */
/* Version: b13fe65ca28d2e568c6ed5d7f06581183df8f2ff */
/* Source: https://github.com/nicolahery/markdownpad-github */

/* RESET
=============================================================================*/

html, body, div, span, applet, object, iframe, h1, h2, h3, h4, h5, h6, p, blockquote, pre, a, abbr, acronym, address, big, cite, code, del, dfn, em, img, ins, kbd, q, s, samp, small, strike, strong, sub, sup, tt, var, b, u, i, center, dl, dt, dd, ol, ul, li, fieldset, form, label, legend, table, caption, tbody, tfoot, thead, tr, th, td, article, aside, canvas, details, embed, figure, figcaption, footer, header, hgroup, menu, nav, output, ruby, section, summary, time, mark, audio, video {
  margin: 0;
  padding: 0;
  border: 0;
}

/* BODY
=============================================================================*/

body {
  font-family: Helvetica, arial, freesans, clean, sans-serif;
  font-size: 14px;
  line-height: 1.6;
  color: #333;
  background-color: #fff;
  padding: 20px;
  max-width: 960px;
  margin: 0 auto;
}

body>*:first-child {
  margin-top: 0 !important;
}

body>*:last-child {
  margin-bottom: 0 !important;
}

/* BLOCKS
=============================================================================*/

p, blockquote, ul, ol, dl, table, pre {
  margin: 15px 0;
}

/* HEADERS
=============================================================================*/

h1, h2, h3, h4, h5, h6 {
  margin: 20px 0 10px;
  padding: 0;
  font-weight: bold;
  -webkit-font-smoothing: antialiased;
}

h1 tt, h1 code, h2 tt, h2 code, h3 tt, h3 code, h4 tt, h4 code, h5 tt, h5 code, h6 tt, h6 code {
  font-size: inherit;
}

h1 {
  font-size: 28px;
  color: #000;
}

h2 {
  font-size: 24px;
  border-bottom: 1px solid #ccc;
  color: #000;
}

h3 {
  font-size: 18px;
}

h4 {
  font-size: 16px;
}

h5 {
  font-size: 14px;
}

h6 {
  color: #777;
  font-size: 14px;
}

body>h2:first-child, body>h1:first-child, body>h1:first-child+h2, body>h3:first-child, body>h4:first-child, body>h5:first-child, body>h6:first-child {
  margin-top: 0;
  padding-top: 0;
}

a:first-child h1, a:first-child h2, a:first-child h3, a:first-child h4, a:first-child h5, a:first-child h6 {
  margin-top: 0;
  padding-top: 0;
}

h1+p, h2+p, h3+p, h4+p, h5+p, h6+p {
  margin-top: 10px;
}

/* LINKS
=============================================================================*/

a {
  color: #4183C4;
  text-decoration: none;
}

a:hover {
  text-decoration: underline;
}

/* LISTS
=============================================================================*/

ul, ol {
  padding-left: 30px;
}

ul li > :first-child, 
ol li > :first-child, 
ul li ul:first-of-type, 
ol li ol:first-of-type, 
ul li ol:first-of-type, 
ol li ul:first-of-type {
  margin-top: 0px;
}

ul ul, ul ol, ol ol, ol ul {
  margin-bottom: 0;
}

dl {
  padding: 0;
}

dl dt {
  font-size: 14px;
  font-weight: bold;
  font-style: italic;
  padding: 0;
  margin: 15px 0 5px;
}

dl dt:first-child {
  padding: 0;
}

dl dt>:first-child {
  margin-top: 0px;
}

dl dt>:last-child {
  margin-bottom: 0px;
}

dl dd {
  margin: 0 0 15px;
  padding: 0 15px;
}

dl dd>:first-child {
  margin-top: 0px;
}

dl dd>:last-child {
  margin-bottom: 0px;
}

/* CODE
=============================================================================*/

pre, code, tt {
  font-size: 12px;
  font-family: Consolas, "Liberation Mono", Courier, monospace;
}

code, tt {
  margin: 0 0px;
  padding: 0px 0px;
  white-space: nowrap;
  border: 1px solid #eaeaea;
  background-color: #f8f8f8;
  border-radius: 3px;
}

pre>code {
  margin: 0;
  padding: 0;
  white-space: pre;
  border: none;
  background: transparent;
}

pre {
  background-color: #f8f8f8;
  border: 1px solid #ccc;
  font-size: 13px;
  line-height: 19px;
  overflow: auto;
  padding: 6px 10px;
  border-radius: 3px;
}

pre code, pre tt {
  background-color: transparent;
  border: none;
}

kbd {
    -moz-border-bottom-colors: none;
    -moz-border-left-colors: none;
    -moz-border-right-colors: none;
    -moz-border-top-colors: none;
    background-color: #DDDDDD;
    background-image: linear-gradient(#F1F1F1, #DDDDDD);
    background-repeat: repeat-x;
    border-color: #DDDDDD #CCCCCC #CCCCCC #DDDDDD;
    border-image: none;
    border-radius: 2px 2px 2px 2px;
    border-style: solid;
    border-width: 1px;
    font-family: "Helvetica Neue",Helvetica,Arial,sans-serif;
    line-height: 10px;
    padding: 1px 4px;
}

/* QUOTES
=============================================================================*/

blockquote {
  border-left: 4px solid #DDD;
  padding: 0 15px;
  color: #777;
}

blockquote>:first-child {
  margin-top: 0px;
}

blockquote>:last-child {
  margin-bottom: 0px;
}

/* HORIZONTAL RULES
=============================================================================*/

hr {
  clear: both;
  margin: 15px 0;
  height: 0px;
  overflow: hidden;
  border: none;
  background: transparent;
  border-bottom: 4px solid #ddd;
  padding: 0;
}

/* TABLES
=============================================================================*/

table th {
  font-weight: bold;
}

table th, table td {
  border: 1px solid #ccc;
  padding: 6px 13px;
}

table tr {
  border-top: 1px solid #ccc;
  background-color: #fff;
}

table tr:nth-child(2n) {
  background-color: #f8f8f8;
}

/* IMAGES
=============================================================================*/

img {
  max-width: 100%
}
</style>
</head>
<body>
<hr />
<p>layout: default
title: &quot;HP Helion OpenStack&#174; Edition: VSA Support&quot;
permalink: /helion/openstack/ga/backup.restore/
product: commercial.ga</p>
<hr />
<!--UNDER REVISION-->
<script>

function PageRefresh {
onLoad="window.refresh"
}

PageRefresh();

</script>
<p style="font-size: small;"> <a href="/helion/openstack/install/kvm/">&#9664; PREV</a> | <a href="/helion/openstack/install-overview/">&#9650; UP</a> | <a href="/helion/openstack/install/esx/">NEXT &#9654;</a> </p>
<h1>HP Helion OpenStack&#174; Back Up and Restore</h1>
<p>This page provides detailed information on how to back up and restore the Seed VM, the undercloud and the Overcloud Management Controller node. </p>
<h2>Back Up</h2>
<p>In case of the Seed VM, the Undercloud or the Overcloud Management Controller node fails you cannot bring the node back on line, we would need a mechanism to restore these 3 nodes. </p>
<p>The failures and the strategy for backup and restore the nodes is given below:</p>
<ul>
<li>Backup the Seed VM</li>
<li>Backup the undercloud</li>
<li>Backup CODN in the overcloud </li>
<li>Backup MySQL in the overcloud</li>
<li>Restore the seed VM</li>
<li>Restore the undercloud</li>
<li>Restore CODN in the overcloud </li>
<li>Restore MySQL in the overcloud</li>
<li>Re-create overcloud Management Controller</li>
<li>Re-create overcloud <code>controller0</code> / <code>controller1</code></li>
</ul>
<h2>Restore the Seed VM ## {#seed}</h2>
<p>Since SEED alone failed we would be restoring the SEED QCOW2 and hence customer would get back exactly the same VM that he lost. The Undercloud and Overcloud would not be touched.
Manual steps --- Virtual Mode</p>
<ol>
<li>
<p>Run the ce-installer.</p>
<pre><code>cd ${TRIPLEO_ROOT}/build
export HOME=/root
export HP_VM_MODE=y  // Create a set of VMs for when not testing on real hardware, otherwise you will need to provide the baremetal.csv file - see the appropriate READMEs
sudo -E bash -x tripleo/tripleo-incubator/scripts/hp_ced_host_manager.sh --create-seed
// Substitute correct NTP servers if known
sudo ssh -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null root@192.0.2.1 'export OVERCLOUD_NTP_SERVER=192.0.1.128 UNDERCLOUD_NTP_SERVER=192.0.1.128; bash -x tripleo/tripleo-incubator/scripts/hp_ced_installer.sh'
</code></pre>

</li>
<li>
<p>Verify functionality.</p>
<pre><code>ssh 192.0.2.1
root@hLinux:~# source stackrc
root@hLinux:~# nova list
root@hLinux:~# neutron net-list
root@hLinux:~# glance image-list
root@undercloud-undercloud-zwgqfk75uxhb:~# source stackrc
root@undercloud-undercloud-zwgqfk75uxhb:~# nova list
root@undercloud-undercloud-zwgqfk75uxhb:~# neutron net-list
root@undercloud-undercloud-zwgqfk75uxhb:~# glance image-list
</code></pre>

</li>
<li>
<p>Make dummy file for restore testing.</p>
<pre><code>root@hLinux:/mnt/state/root# cat restore.txt
testing 1
testing 2
testing 3
</code></pre>

</li>
<li>
<p>Simulate seed being shutdown.</p>
<p>Use the following command to shut down the Seed VM.</p>
<p><strong>Note:</strong> If the seed VM is shut down, skip this step.</p>
<pre><code>virsh shutdown seed
</code></pre>

<p>If status doesn't change to &quot;shut off&quot; in 5 minutes, quit the script and manually shutdown seed on virt-manger. </p>
</li>
<li>
<p>Backup <code>seed.qcow2</code>.</p>
<pre><code>mkdir /home/ubuntu/seed_backup
cp /var/lib/libvirt/images/seed.qcow2 /home/ubuntu/seed_backup/
</code></pre>

</li>
<li>
<p>Undefine the seed VM.</p>
<pre><code>virsh undefine seed
</code></pre>

</li>
<li>
<p>Modify the <code>hp_ced_host_manager.sh</code> and rename it to <code>hp_ced_host_manager_new.sh</code>.</p>
<pre><code>// Add this right after IMAGE_CACHE_FILE declaration: IMAGE_BACKUP_FILE=/home/ubuntu/seed_backup/seed.qcow2
// Comment out: cp $IMAGE_CACHE_FILE ${IMAGES_DIR}/$IMAGE_NAME.qcow2
// Add this right below: cp $IMAGE_BACKUP_FILE ${IMAGES_DIR}/$IMAGE_NAME.qcow2
// In the function create_seed():
// Comment out: [ -z &quot;$HP_VM_MODE&quot; ] || config_vm_baremetal
// Comment out: wait_seed_vm
// Comment out: [ -z &quot;$HP_VM_MODE&quot; ] || copy_config_vm_baremetal
</code></pre>

</li>
<li>
<p>Start creating seed</p>
<pre><code>cd ${TRIPLEO_ROOT}/build
export HOME=/root
export HP_VM_MODE=y 
sudo -E bash -x tripleo/tripleo-incubator/scripts/hp_ced_host_manager_new.sh --create-seed
</code></pre>

</li>
<li>
<p>Network fixes]</p>
<p>At this point, seed is not reachable vi the default 192.0.2.1, we need to fix network settings by logging into seed with another IP.</p>
<p>Seed VM guest has two interfaces â€“ one is connected to brbm (baremetal network) and the other is to default net (virbr0) provided by KVM host that provides dynamic IP addresses to the guest.</p>
<p>Use the following command to find out the dynamic IP.</p>
<pre><code>arp | grep virbr0 | awk '{print $1}'
</code></pre>

<p>You receive a response similar to the following:</p>
<pre><code>ssh DYNAMIC_IP (e.g. ssh 192.168.122.207)
root@hLinux:~# vi /etc/udev/rules.d/70-persistent-net.rules
</code></pre>

<p>Find the line (normally the last entry) with the correct NIC MAC address of seed, change the line's NAME=&quot;eth2&quot; to NAME=&quot;eth1&quot;, comment out any other entries whose NAME=&quot;eth1&quot;, save &amp; quit</p>
<p>In virt-manager, force off seed then restart, wait for seed up and running</p>
<p>Add route to 192.0.2.1</p>
<pre><code>route add -net $BM_NETWORK_CIDR gw $BM_NETWORK_GATEWAY
</code></pre>

<p>Defaults are as follows</p>
<pre><code>route add -net 192.0.2.0/24 gw 192.168.122.1
</code></pre>

</li>
<li>
<p>Verify successful data restore and same output as step 1]</p>
<pre><code>ssh 192.0.2.1
root@hLinux:~# cat /mnt/state/root/restore.txt
root@hLinux:~# service mysql start
root@hLinux:~# os-refresh-config
root@hLinux:~# source stackrc
root@hLinux:~# nova list
root@hLinux:~# neutron net-list
root@hLinux:~# glance image-list
root@undercloud-undercloud-zwgqfk75uxhb:~# source stackrc
root@undercloud-undercloud-zwgqfk75uxhb:~# nova list
root@undercloud-undercloud-zwgqfk75uxhb:~# neutron net-list
root@undercloud-undercloud-zwgqfk75uxhb:~# glance image-list
</code></pre>

</li>
</ol>
<h2>Restore to the same host</h2>
<p>Use the following steps to restore to the same host:</p>
<pre><code>bash -x /root/work/tripleo/tripleo-incubator/scripts/hp_ced_host_manager.sh --export-seed
virsh undefine seed
bash -x /root/work/tripleo/tripleo-incubator/scripts/hp_ced_host_manager.sh --import-seed
</code></pre>

<h2>Restore a different host</h2>
<p>Use the following steps to restore a different host: from host<em>1 to host</em>2.</p>
<ol>
<li>
<p>On host_1 make sure the seed VM is shutdown.</p>
</li>
<li>
<p>Perform the following:</p>
<pre><code>scp /var/lib/libvirt/images/seed.qcow2 ubuntu@15.126.52.77:backup
scp /var/lib/libvirt/images/seed_options ubuntu@15.126.52.77:backup
scp /root/.ssh/id_rsa ubuntu@15.126.52.77:backup
scp /root/.ssh/id_rsa.pub ubuntu@15.126.52.77:backup
virsh undefine seed
</code></pre>

</li>
<li>
<p>On host_2 (no seed vm on host)</p>
<pre><code>mkdir /home/ubuntu/backup
*** modify hp_ced_host_manager.sh to be hp_ced_host_manager_new.sh with this line changed ----&gt; export IMAGE_CACHE_FILE=/home/ubuntu/backup/seed.qcow2
cp /home/ubuntu/backup/id_rsa /root/.ssh
cp /home/ubuntu/backup/id_rsa.pub /root/.ssh
export BRIDGE_INTERFACE=brbm
bash -x /root/work/tripleo/tripleo-incubator/scripts/hp_ced_host_manager_new.sh --create-seed
SEED_IP=`arp | grep virbr0 | awk '{print $1}'`
ssh $SEED_IP touch /etc/udev/rules.d/70-persistent-net.rules
ssh $SEED_IP &quot;echo `tail -1 /etc/udev/rules.d/70-persistent-net.rules | sed 's/eth2/eth1/g'` &gt; /etc/udev/rules.d/70-persistent-net.rules&quot;
virsh destroy seed
virsh start seed
route add -net 192.0.2.0 netmask 255.255.255.0 gw 192.168.122.1
</code></pre>

</li>
</ol>
<h2>Automatic steps</h2>
<p>When Seed is shutdown due to disaster, run the following scripts </p>
<pre><code>    cd ${TRIPLEO_ROOT}/build
    ./tripleo/tripleo-incubator/scripts/hp_ced_backup.sh --seed -f dest_host_folder [-H dest_host_ip] [-u dest_host_user] [-i identity_file]
    ./tripleo/tripleo-incubator/scripts/seed_restore.sh --seed -f source_host_folder [-H source_host_ip] [-u source_host_user] [-i identity_file]
</code></pre>

<p>Now Seed shall be restored</p>
<p>hp<em>ced</em>backup.sh</p>
<p>hp<em>ced</em>restore.sh</p>
<p>Note: After taking the latest looks like community has solved this problem and we have an to export the Seed and import it again. All functionality on VM mode seems to be working. We need to test the communities solution so that the new Seed VM is recreated on a different host. </p>
<h2>Restore the undercloud</h2>
<p>If the undercloud server fails, the approach is to recreate both the seed and undercloud in ordeer to retain networking details and it is quicker to restore both. </p>
<p>The backup tool will backup following data:</p>
<ul>
<li>
<p>From the seed VM: </p>
<ul>
<li>the tripleo/tripleo-undercloud-passwords files</li>
<li>tripleo-overcloud-passwords password files</li>
<li>testenv.json file</li>
<li>undercloud-env.json file</li>
</ul>
</li>
<li>
<p>From the Undercloud machine </p>
<pre><code>- backup /mnt file
- /tftpboot file
- ls /etc/mysql/static-dbusers.json file
</code></pre>

</li>
</ul>
<p>The tool will backup the current undercloud image.</p>
<ol>
<li>
<p>Destroy SCC and UCC.</p>
<p>When the restore process needs to be executed, run the following on on the seed VM:</p>
<pre><code>virsh destroy seed
virsh undefine seed
virsh destroy baremetal_0
virsh undefine baremetal_0
</code></pre>

</li>
<li>
<p>Recreate the seed VM.</p>
<p>Recreate the undercloud vm in case using vm mode of install.</p>
<p>On a virtual server, run the following command:</p>
<pre><code>HP_VM_MODE=y bash -x ~root/tripleo/tripleo-incubator/scripts/hp_ced_start_seed.sh
</code></pre>

<p>On a baremetal server, use the following command: </p>
<p>bash -x ~root/tripleo/tripleo-incubator/scripts/hp<em>ced</em>start_seed.sh</p>
</li>
<li>
<p>Copy over the <code>tripleo/tripleo-undercloud-passwords</code> and <code>tripleo-overcloud-passwords</code> password files from the desired backup folder</p>
</li>
<li>
<p>Recreate UCC.</p>
<p>Run the installer script with the skip overcloud option:</p>
<pre><code>bash -x ~root/tripleo/tripleo-incubator/scripts/hp_ced_installer.sh --skip-overcloud --skip-demo
</code></pre>

</li>
<li>
<p>Stop services on UCC.</p>
<p>Once the undercloud is up and running stop the following services </p>
<pre><code>service keystone stop
service nova-api stop
service rabbitmq-server stop
service mysql stop
</code></pre>

</li>
<li>
<p>Restore <code>/mnt</code> and <code>/tftpboot</code> on UCC.</p>
<pre><code>cd /mnt
sudo rm -r /state
</code></pre>

</li>
<li>
<p>Copy the <code>state.tar</code> for the backed-up <code>mnt</code> file to the <code>/mnt</code> directory.</p>
<pre><code>cd /tftpboot
sudo rm -r *
</code></pre>

</li>
<li>
<p>Copy the <code>tftpboot.tar</code> file for the backed-up <code>tftpboot</code> file to the <code>/tftpboot</code> directory.</p>
</li>
<li>
<p>Restart all services.</p>
<pre><code>service mysql start
os-refresh-config
service mysql restart
os-refresh-config
</code></pre>

</li>
<li>
<p>Verify UCC.</p>
<p>Verify if the newly installed undercloud is working fine. From the seed VM run</p>
<pre><code>. stackrc
nova list
</code></pre>

<p>The nova list should give all the old overcloud nodes</p>
<pre><code>heat stack-list
</code></pre>

<p>Above command should give back the old heat list</p>
</li>
<li>
<p>Now perform some lifecycle operations using <code>nova reboot</code>.</p>
<p>A soft reboot attempts a graceful shut down and restart of the instance. By default, when you reboot a server, it is a soft reboot. </p>
<pre><code>nova --reboot idofovercloudcontroller
</code></pre>

<p>The overcloud controller should get rebooted and should get back the same ip as it had earlier</p>
</li>
</ol>
<p>Now we need to restore the Undercloud image if it was upgraded by Sherpa</p>
<p>We already have the backup of the undercloud image that was backed up</p>
<p>Follow &quot;Updating the undercloud&quot; link to restore the upgraded image</p>
<h2>Restore the overcloud management controller ##</h2>
<ol>
<li>
<p>Remove the failed node from RabbitMQ.</p>
<p>From the seed node, ssh to one of the remaining controllers (any one) and remove the failed controller from the RabbitMQ cluster.</p>
<pre><code>ssh heat-admin@&lt;node&gt; 'rabbitmqctl cluster_status (to check status)'
ssh heat-admin@&lt;node&gt; 'sudo rabbitmqctl forget_cluster_node &lt;down node&gt;'
ssh heat-adimn@&lt;node&gt; 'sudo rabbitmqctl cluster_status (to verify removal)'
</code></pre>

</li>
<li>
<p>Generate heat template.</p>
<p>Generate heat template (yaml file) to pass to the heat stack-update command for dropping a controller node. From the seed VM run the following:</p>
<pre><code>cd ~/tripleo/tripleo-heat-templates/
python ./tripleo_heat_merge/merge.py --scale controller=1 --scale NovaCompute=1 --scale SwiftStorage=2 --scale BlockStorage=0 overcloud-source.yaml block-storage.yaml swift-source-ce.yaml swift-storage-server.yaml ssl-source.yaml nova-compute-config.yaml overcloud-controller-mgmt-ce.yaml overcloud-sherpa.yaml &gt; overcloud-ce-drop-ctrlnode.yaml
</code></pre>

<p>The example above drops the <code>controller1</code> node. </p>
<p>Heat template for controller management node : Need to hand edit overcloud-ce.yaml file  .( Example : see the attachment )</p>
</li>
<li>
<p>Stack update.</p>
<p>From the seed VM run the following</p>
<pre><code>source ~root/tripleo/tripleo-undercloud-passwords
TE_DATAFILE=~root/tripleo/ce_env.json
source ~root/tripleo/tripleo-incubator/undercloudrc

heat stack-update -e /root/tripleo/overcloud-env.json -t 360 -f /root/tripleo/tripleo-heat-templates/overcloud-ce-drop-ctrlnode.yaml -P 'ExtraConfig= ....' -P controllerImage=&lt;ctrlImageid&gt; -P controllerMgmtImage=&lt;ctrlMgmtImageid&gt; overcloud
</code></pre>

<p>The example above drops the <code>controller1</code> node.</p>
<p>ExtraConfig : these are config parameters that are passed during installation steps   
</p>
<p>controllerImage : is the imageid of controller that is in your glance,</p>
<p>controllerMgmtImage: is the imageid of controllerMgmt that is in your glance   )</p>
</li>
<li>
<p>Run these commands on nodes.</p>
<p>Check status of nodes: node status - Status/Power State   :   ACTIVE/Running:
Update these files on all controller nodes and compute nodes that are in overcloud stack. </p>
<p>From the seed node run the following: </p>
<pre><code>ssh heat-admin@&lt;node&gt; 'sudo sed -i &quot;/diff/ s/$/ \&amp;\&amp; true/&quot; /opt/stack/os-config-refresh/configure.d/51-hosts'
</code></pre>

<p>Example: </p>
<pre><code>ssh heat-admin@192.0.2.43 'sudo sed -i &quot;/diff/ s/$/ \&amp;\&amp; true/&quot; /opt/stack/os-config-refresh/configure.d/51-hosts') 
</code></pre>

<p>From the seed node run the following: </p>
<pre><code>ssh heat-admin@&lt;node&gt; 'sudo pkill -u rabbitmq'
</code></pre>

</li>
</ol>
<p>To Add Controller Nodes :</p>
<ol>
<li>Generate heat template:  </li>
<li>Follow  above step &quot; To Drop Controller Nodes - [1. Generate heat template]&quot;  to generate new template by increasing scale count &quot;--scale controller= .. &quot; . </li>
</ol>
<p>TODO: cater for controller 0 and mgmt controller (either by trickle or prebuilt templates</p>
<p>[2. Stack update ]</p>
<p>To Add Controller management node -  use original(during installation) template - /root/tripleo/tripleo-heat-templates/overcloud-ce.yaml.</p>
<p>From the seed node run the following:
cd ~root/tripleo/tripleo-heat-templates/
python ./tripleo<em>heat</em>merge/merge.py --scale controller=2 --scale NovaCompute=1 --scale SwiftStorage=2 --scale BlockStorage=0 overcloud-source.yaml block-storage.yaml swift-source-ce.yaml swift-storage-server.yaml ssl-source.yaml nova-compute-config.yaml overcloud-controller-mgmt-ce.yaml overcloud-sherpa.yaml &gt; overcloud-ce.yaml</p>
<p>source ~root/tripleo/tripleo-undercloud-passwords
TE<em>DATAFILE=~root/tripleo/ce</em>env.json
source ~root/tripleo/tripleo-incubator/undercloudrc</p>
<p>heat stack-update -e /root/tripleo/overcloud-env.json -t 360 -f /root/tripleo/tripleo-heat-templates/overcloud-ce.yaml -P 'ExtraConfig= ....' -P controllerImage=<ctrlImageid> -P controllerMgmtImage=<ctrlMgmtImageid> overcloud</p>
<p>( ExtraConfig : these are config parameters that are passed during installation steps( Example: Attached file ),</p>
<p>controllerImage : is the imageid of controller that is in your glance,</p>
<p>controllerMgmtImage: is the imageid of controllerMgmt that is in your glance )</p>
<p>TODO: Avoid the use of heat stack-update directly: use the installer script, avoiding the need for ExtraConfig, and imageId's</p>
<p>[3. Run these commands on nodes ] </p>
<p>Follow above steps &quot;To Drop Controller Nodes - [3. Run these commands on nodes ]  &quot;</p>
<h2>Backup and restore the MySQL cluster on the Overcloud</h2>
<p>This section deals with the disaster recovery scenarios of the 3 node Mysql cluster (Percona XtraDB Cluster) that runs in overcloud controller nodes. Percona Cluster takes care of syncup of the data between nodes if one of the nodes goes down and comes up later. But if the whole cluster goes down due to some issue (like data corruption or mysql bug etc) and the cluster does not come up, we need a way to restore it to a previous well known state (backup) and start the cluster from that point. </p>
<p>The solution is to use the Percona Xtrabackup utility to take full backups of the mysql instance (tested only full backups as of now but can be exteneded to incremental backups as well) frequently like 1 per day on one of the active cluster nodes. Whenever the cluster goes down or some data corruption occurs, delete the current data in all of the 3 nodes of mysql (present in /mnt/state/var/lib/mysql) and restore the backup copy on the same node on which backup is taken and bootstrap the percona cluster. Later bring up rest of the nodes so that they sync the data from the recovered node of cluster.</p>
<p>The whole process is given in detail at : http://fromdual.com/xtrabackup<em>in</em>a_nutshell</p>
<p>Here are the specific commands used for backup and recovery:</p>
<h3>Backup the MySQL cluster:</h3>
<ol>
<li>
<p>Use ssh to access one of the active nodes of cluster as the <code>heat-admin</code> user.</p>
<pre><code>ssh heat-admin@&lt;controller node IP&gt; 
</code></pre>

<p>Use the IP of controller node of your environment.</p>
</li>
<li>
<p>Run the <code>innobackup</code> Perl script, which uses Percona XtraBackup internally.</p>
<pre><code>sudo innobackupex --galera-info /mnt/state/backups (replace /mnt/state/backups with the backup location of your environment)
</code></pre>

<p>This creates a timestamped folder (for ex. &quot;2013-11-06_00-00-00&quot;)  to contain all backup files.</p>
</li>
</ol>
<p>For more information about <code>innobackupex</code>, see: http://www.percona.com/doc/percona-xtrabackup/2.1/innobackupex/innobackupex<em>option</em>reference.html</p>
<ol>
<li>
<p>Prepare the backup to be consistent at a point-in-time.</p>
<pre><code>sudo innobackupex  --apply-log /mnt/state/backups/&lt;timestamped-folder-path&gt; (use the timestamped path generated in above step)
</code></pre>

</li>
<li>
<p>Copy the backup to a remote location.</p>
</li>
</ol>
<h3>Recover the MySQL cluster:</h3>
<ol>
<li>
<p>Use SSH to access each of the three nodes using <code>heat-admin</code> and elevate to root, and delete the MySQL data directory on each node using the following command: </p>
<pre><code>ssh heat-admin@192.0.2.24 (replace 192.0.2.24 with controller1 ip address) 'sudo rm -rf /mnt/state/var/lib/mysql'

ssh heat-admin@192.0.2.25 (replace 192.0.2.25 with controller0 ip address) 'sudo rm -rf /mnt/state/var/lib/mysql'

ssh heat-admin@192.0.2.26 (replace 192.0.2.25 with mgmt controller ip address) 'sudo rm -rf /mnt/state/var/lib/mysql'
</code></pre>

</li>
<li>
<p>Copy the backup from remote location to a local location on controller0 (controller on which the backup is taken).</p>
</li>
<li>
<p>Run the Percona Xtrabackup utility using the innobackupex command</p>
<pre><code>sudo innobackupex --copy-back /mnt/state/backups/&lt;timestamped-folder-path&gt; (replace /mnt/state/backups/&lt;timestamped-folder-path&gt; with actual local location)
</code></pre>

</li>
<li>
<p>Change the permissions of MySQL data directory to the <code>mysql</code> user and group.</p>
<pre><code>sudo chown -R mysql:mysql /mnt/state/var/lib/mysql
</code></pre>

</li>
<li>
<p>Bootstrap the MySQL cluster on controller0.</p>
<pre><code>sudo /etc/init.d/mysql bootstrap-pxc
</code></pre>

</li>
<li>
<p>Start the MySQL services on the other controller nodes so that they can sync up their data with the restored MySQL cluster.</p>
<pre><code>sudo service mysql start
</code></pre>

</li>
</ol>

</body>
</html>
<!-- This document was created with MarkdownPad, the Markdown editor for Windows (http://markdownpad.com) -->
