<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE topic
  PUBLIC "-//OASIS//DTD DITA Topic//EN" "http://docs.oasis-open.org/dita/v1.1/OS/dtd/topic.dtd" ><topic xml:lang="en-us" id="topic9421">
<title>HP Helion 1.0 Development Platform: Best Practices</title>
<prolog>
<metadata>
<othermeta name="layout" content="default"/>
<othermeta name="product-version" content="HP Helion Development Platform"/>
<othermeta name="product-version" content="HP Helion Development Platform 1.0"/>
<othermeta name="role" content="Application Developer"/>
<othermeta name="role" content="Security Engineer"/>
<othermeta name="role" content="ISV Developer"/>
<othermeta name="role" content="Service Developer"/>
<othermeta name="role" content="Network Administrator"/>
<othermeta name="role" content="Systems Administrator"/>
<othermeta name="role" content="Jayme P"/>
<othermeta name="product-version1" content="HP Helion Development Platform"/>
<othermeta name="product-version2" content="HP Helion Development Platform 1.0"/>
</metadata>
</prolog>
<body>
<p>
<!--PUBLISHED-->
 <!--./devplatform/helion/admin/best-practices/1.0index.md-->
 <!--permalink: /als/v1/admin/best-practices/--></p>
<p>

</p>
<section id="applying-updates"> <title>Applying Updates</title>
<ul>
<li>
<xref type="section" href="#topic9421/backup-migration">Backup &amp; Migration</xref>

<ul>
<li>
<xref type="section" href="#topic9421/limitations">Limitations</xref>

<ul>
<li>
<xref type="section" href="#topic9421/custom-services">Custom Services</xref>
</li>
<li>
<xref type="section" href="#topic9421/hard-coded-database-connection-info">Hard-coded Database Connection
Info</xref>
</li>
<li>
<xref type="section" href="#topic9421/deas">DEAs</xref>
</li>
</ul>
</li>
<li>
<xref type="section" href="#topic9421/exporting-the-server-data">Exporting the server data</xref>
</li>
<li>
<xref type="section" href="#topic9421/scheduled-backups">Scheduled backups</xref>
</li>
<li>
<xref type="section" href="#topic9421/importing-the-server-data">Importing the server data</xref>
</li>
</ul>
</li>
<li>
<xref type="section" href="#topic9421/upgrade">Upgrading (v1.0 and later)</xref>
</li>
<li>
<xref type="section" href="#topic9421/server-monitoring-with-new-relic">Server Monitoring with New
Relic</xref>
</li>
<li>
<xref type="section" href="#topic9421/system-monitoring-with-nagios">System Monitoring with Nagios</xref>
</li>
<li>
<xref type="section" href="#topic9421/storage">Persistent Storage</xref>

<ul>
<li>
<xref type="section" href="#topic9421/relocating-services-droplets-and-containers">Relocating Services, Droplets, and
Containers</xref>
</li>
<li>
<xref type="section" href="#topic9421/enabling-filesystem-quotas">Enabling Filesystem Quotas</xref>
</li>
</ul>
</li>
</ul>
<p>Major version upgrades of Application Lifecycle Service can be done using <xref href="../../../../devplatform/helion/admin/server/1.0upgrade.dita#upgrade" type="section" scope="external"  >
<i>kato node
upgrade</i>
</xref> or a <xref type="section" href="#topic9421/bestpractices-migration">
<i>migration to a new VM
or cluster</i>
</xref>, but patch releases (normally
minor fixes to particular components) can be applied in place using the
<xref href="../../../../devplatform/helion/admin/reference/1.0kato-ref.dita#kato-command-ref-patch" type="section" scope="external"  >
<i>kato patch</i>
</xref>
command.</p>
<p>To see a list of patches available from HP, run the following
command on any Application Lifecycle Service VM:</p>
<codeblock>
  <codeph>kato patch status
</codeph>
</codeblock>
<p>The command will list the updates available. For example:</p>
<codeblock>
  <codeph>1 update available to be installed.

Known updates:
  dea-memory-usage-reporting: Fix the reporting of helion stats usage on the DEA end.
    severity: required
    roles affected: dea
</codeph>
</codeblock>
<p>To apply all patches to all relevant cluster nodes:</p>
<codeblock>
  <codeph>kato patch install
</codeph>
</codeblock>
<p>To apply a particular patch, specify it by name:</p>
<codeblock>
  <codeph>kato patch install dea-memory-usage-reporting
</codeph>
</codeblock>
<p>Applying patches will automatically restart all patched roles. To
prevent this, use the <codeph>--no-restart</codeph> option.</p>
<p>To apply a patch only to the local Application Lifecycle Service VM (not the whole cluster),
use the <codeph>--only-this-node</codeph> option.</p>
</section>
<section id="backup-migration"> <title>Backup &amp; Migration</title>
<p>This section describes backing up Application Lifecycle Service data and importing it into a
new Application Lifecycle Service system. The export/import cycle is required for:</p>
<ul>
<li>backups of system data</li>
<li>moving an Application Lifecycle Service cluster to a new location</li>
</ul>
</section>
<section id="limitations"> <title>Limitations</title>
<p>Before deciding on a backup, upgrade or migration strategy, it's
important to understand what data the Application Lifecycle Service system can save, and what
may have to be reset, redeployed, or reconfigured. This is especially
important when migrating to a new cluster.</p>
</section>
<section id="custom-services"> <title>Custom Services</title>
<p>Application Lifecycle Service can export and import data from built-in data services running
on Application Lifecycle Service nodes, but it has no mechanism to handle data in <xref href="../../../../devplatform/helion/admin/cluster/1.0external-db.dita#external-db" type="section" scope="external"  >
<i>external
databases</i>
</xref> (unless
<codeph>kato export|import</codeph> has also been modified to
recognize the custom service).</p>
<p>Backing up or moving such databases should be handled separately, and
user applications should be reconfigured and/or redeployed to connect
properly to the new database host if the database is not implemented as
an Application Lifecycle Service data service.</p>
</section>
<section id="hard-coded-database-connection-info"> <title>Hard-coded Database Connection Info</title>
<p>Applications which write database connection details during staging
rather than taking them from environment variables at run time, must be
re-staged (e.g. redeployed or updated) to pick up the new service
location and credentials. Restarting the application will not
automatically force restaging.</p>
</section>
<section id="deas"> <title>DEAs</title>
<p>Droplet Execution Agent (DEA) nodes are not migrated directly from old
nodes to new nodes. Instead, the application droplets (zip files
containing staged applications) are re-deployed to new DEA nodes from
the Controller.</p>
</section>
<section id="exporting-the-server-data"> <title>Exporting the server data</title>
<p>Data export is done with the <xref href="../../../../devplatform/helion/admin/reference/1.0kato-ref.dita#kato-command-ref-data-export" type="section" scope="external"  >
<i>kato data
export</i>
</xref>
command. The command can export:</p>
<ul>
<li>internal Application Lifecycle Service data (users, groups, quotas, settings, etc.)</li>
<li>application droplets</li>
<li>data services</li>
</ul>
<p>Start by logging into the VM via <codeph>ssh</codeph>:</p>
<codeblock>
  <codeph>$ ssh helion@helion-xxxx.local
</codeph>
</codeblock>
<p>A single-node micro cloud VM can be backed up with a single command:</p>
<codeblock>
  <codeph>$ kato data export --only-this-node
</codeph>
</codeblock>
<p>A clustered setup can be backed up with a single command:</p>
<codeblock>
  <codeph>$ kato data export --cluster
</codeph>
</codeblock>
<p>Once the export completes, you can use
<xref href="http://manpages.ubuntu.com/manpages/lucid/man1/scp.1.html" scope="external" format="html" >scp</xref> or
another utility (e.g. sftp, rsync) to move the .tgz file to another
system, or save the file directly to a mounted external filesystem by
specifying the full path and filename during export (see backup example
below).</p>
<p>
  <b>Note</b>
</p>
<p>Exporting data can take several minutes. For clusters with constant
usage or large numbers of users, apps, and databases, put the exporting
system in <xref href="../../../../devplatform/helion/admin/console/1.0customize.dita#console-settings" type="section" scope="external"  >
<i>Maintenance Mode</i>
</xref>
(e.g. during a scheduled maintenance window) before exporting.</p>
</section>
<section id="scheduled-backups"> <title>Scheduled backups</title>
<p>Regular backup of controller data, apps, droplets, and service data is
recommended for any production system. Implementation of a regular
backup routine is left to the discretion of the Application Lifecycle Service administrator,
but using
<xref href="http://manpages.ubuntu.com/manpages/oneiric/man1/crontab.1.html" scope="external" format="html" >cron/crontab</xref>
is one simple way is to automate this. For example, you could create an
entry like the following in the root user's crontab on the filesystem
node:</p>
<codeblock>
  <codeph>0 3 * * * su - helion /bin/bash -c '/home/helion/bin/kato data export --cluster /mnt/nas/helion-backup.tgz'
</codeph>
</codeblock>
<p>This runs <codeph>kato data export --cluster</codeph> every morning
at 3AM as <codeph>root</codeph> using the <codeph>helion</codeph> user's login environment (required) and saves a .tgz file to a
mounted external filesystem.</p>
<p>Scheduled (non-interactive) backups using the <codeph>kato export</codeph> command will need to be run by <codeph>root</codeph> as
some shell operations performed in the export require <codeph>sudo</codeph> when run interactively. For clusters, passwordless <xref href="https://help.ubuntu.com/community/SSH/OpenSSH/Configuring#disable-password-authentication" type="section" scope="external" format="html" >SSH key
authentication</xref>
between the Core node and all other nodes will also need to be set up.
The command should be run on the node hosting the 'filesystem' role, as
some shell commands need to be run locally for that service.</p>
</section>
<section id="importing-the-server-data"> <title>Importing the server data</title>
<p>To import Application Lifecycle Service data, transfer the exported .tgz file to the target
VM or note the hostname of the old VM / Core node.</p>
<p>
  <b>Note</b>
</p>
<p>Before importing data to a new microcloud or cluster, make sure you have
completed first-user (admin) setup in the Application Lifecycle Service Web UI and accepted
the terms and conditions.</p>
<p>
  <b>Note</b>
</p>
<p>All roles in the new cluster should be started prior to proceeding with
import. If you would like all services to be imported, their
corresponding roles must be enabled (see also <xref href="../../../../devplatform/helion/admin/reference/1.0known-issues.dita#known-issues-rabbit-import" type="section" scope="external"  >
<i>Importing Apps using
RabbitMQ
2.4</i>
</xref>).</p>
<p>Login to the Application Lifecycle Service VM (or Core node) and run
<codeph>kato data import</codeph> with the relevant options. For
example, to import all data into a new cluster from a .tgz file:</p>
<codeblock>
  <codeph>$ kato data import --cluster helion-export-xxxxxxxxxx.tgz
</codeph>
</codeblock>
<p>To import data from a running Application Lifecycle Service system instead, specify the
hostname of the old Core node:</p>
<codeblock>
  <codeph>$ kato data import --cluster helion-host.example.com
</codeph>
</codeblock>
</section>
<section id="upgrade"> <title>Upgrading (v1.0 and later)</title>
<p>The <codeph>kato node upgrade</codeph> command was added in
Application Lifecycle Service 1.0 to allow upgrading Application Lifecycle Service systems in place. See
<xref href="../../../../devplatform/helion/admin/server/1.0upgrade.dita#upgrade" type="section" scope="external"  >
<i>Upgrading Application Lifecycle Service</i>
</xref> for full
instructions.</p>
</section>
<section id="server-monitoring-with-new-relic"> <title>Server Monitoring with New Relic</title>
<p>To use New Relic for server monitoring, you'll need a <xref href="http://newrelic.com/" scope="external" format="html" >New Relic
account</xref> and a License Key. Install the
<codeph>newrelic-sysmond</codeph> package and start the monitoring
daemon on each Application Lifecycle Service VM as per the <xref href="http://docs.newrelic.com/docs/server/server-monitor-installation-ubuntu-and-debian" scope="external" format="html" >New Relic Server Monitor
installation
(Ubuntu)</xref>
instructions.</p>
</section>
<section id="system-monitoring-with-nagios"> <title>System Monitoring with Nagios</title>
<p>Though Application Lifecycle Service has an internal mechanism for supervising processes on a
server or cluster (<xref href="http://supervisord.org/" scope="external" format="html" >Supervisor</xref>), it is
advisable to add some external monitoring for production systems.
<xref href="http://www.nagios.org/" scope="external" format="html" >Nagios</xref> is a free, open source system
monitoring tool that can provide this external monitoring.</p>
<p>Detailed instructions on installing and configuring Nagios can be found
in the <xref href="http://nagios.sourceforge.net/docs/3_0/toc.html" scope="external" format="html" >Nagios Core
Documentation</xref>
</p>
</section>
<section id="storage"> <title>Persistent Storage</title>
<p>Cloud hosting providers have different default partition sizes and
configurations. The default root volumes on some cloud hosted VM
instances are often fairly small and are usually ephemeral. Data service
and filesystem nodes should always be backed by some kind of persistent
storage, with enough free filesystem space to accommodate the projected
use of the services.</p>
</section>
<section id="relocating-services-droplets-and-containers"> <title>Relocating Services, Droplets, and Containers</title>
<p>To move database services, application droplets, and application
containers to larger partitions:</p>
<ul>
<li>mount the filesystem and/or block storage service on the instance
(with <xref type="section" href="#topic9421/bestpractices-filesystem-quotas">
<i>quotas enabled</i>
</xref>),</li>
<li>create directories for the items you wish to move,</li>
<li>run the <xref href="../../../../devplatform/helion/admin/reference/1.0kato-ref.dita#kato-command-ref-relocate" type="section" scope="external"  >
<i>kato
relocate</i>
</xref>
command(s).</li>
</ul>
<p>For example:</p>
<codeblock>
  <codeph>$ kato stop
...
$ kato relocate services /mnt/ebs/services
...
$ kato relocate droplets /mnt/ebs/droplets
...
$ kato relocate containers /mnt/containers
...
</codeph>
</codeblock>
<p>
  <b>Note</b>
</p>
<p>For performance reasons, Application Lifecycle Service containers should not be relocated to
block volumes.</p>
</section>
<section id="enabling-filesystem-quotas"> <title>Enabling Filesystem Quotas</title>
<p>The Application Lifecycle Service filesystem quotas cannot be enforced by the system unless
they are mounted on partitions which support Linux quotas. This may need
to be specified explicitly when running the <codeph>mount</codeph>
command. The <xref href="../../../../devplatform/helion/admin/reference/1.0kato-ref.dita#kato-command-ref-relocate" type="section" scope="external"  >
<i>kato
relocate</i>
</xref> command
will warn if this is necessary.</p>
<p>For the example above, the <codeph>mount</codeph> step might look
like this:</p>
<codeblock>
  <codeph>$ sudo mount -o remount,usrjquota=aquota.user,grpjquota=aquota.group,jqfmt=vfsv0 /mnt/containers
$ sudo quotacheck -vgumb /mnt/containers
$ sudo quotaon -v /mnt/containers
</codeph>
</codeblock>
<p>To ensure the quotas are preserved after reboot, edit
<i>/etc/init.d/setup_helion_lxc</i> to include mount commands for each
partition. The example above would require a block such as this:</p>
<codeblock>
  <codeph># enable quotas for Application Lifecycle Service containers
if [[ -f "/mnt/containers/aquota.user" ]]; then
  mount -o remount,usrjquota=aquota.user,grpjquota=aquota.group,jqfmt=vfsv0 /mnt/containers
  quotaon -v /mnt/containers
fi
</codeph>
</codeblock>
</section>
</body>
</topic>
