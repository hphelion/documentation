<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE topic
  PUBLIC "-//OASIS//DTD DITA Topic//EN" "http://docs.oasis-open.org/dita/v1.1/OS/dtd/topic.dtd" ><topic xml:lang="en-us" id="topic11928">
<title>HPE Helion 2.0 Development Platform: Log Streams</title>
<prolog>
<metadata>
<othermeta name="layout" content="default"/>
<othermeta name="product-version" content="HPE Helion Development Platform"/>
<othermeta name="product-version" content="HPE Helion Development Platform 2.0"/>
<othermeta name="role" content="Application Developer"/>
<othermeta name="role" content="ISV Developer"/>
<othermeta name="role" content="Service Developer"/>
<othermeta name="role" content="Network Administrator"/>
<othermeta name="role" content="Systems Administrator"/>
<othermeta name="role" content="Security Engineer"/>
<othermeta name="role" content="Jayme P"/>
</metadata>
</prolog>
<body>
<ul>
<li>
<xref type="section" href="#topic11928/logyard">Logyard</xref>
</li>
<li>
<xref type="section" href="#topic11928/debugging-logyard">Debugging Logyard</xref>
</li>
<li>
        <xref type="section" href="#topic11928/drains">Drains</xref>
        <ul>
          <li>
            <xref type="section" href="#topic11928/system-drains">System Drains</xref>
          </li>
          <li>
            <xref type="section" href="#topic11928/log-format">Log Format</xref>
          </li>
          <li>
            <xref type="section" href="#topic11928/saving-custom-log-formats">Saving Custom Log
              Formats</xref>
          </li>
          <li>
            <xref type="section" href="#topic11928/custom-drains">Custom Drains</xref>
          </li>
          <li>
            <xref type="section" href="#topic11928/application-drains">Application Drains</xref>
          </li>
          <li>
            <xref type="section" href="#topic11928/drain-status">Drain Status</xref>
          </li>
        </ul></li>
<li>
        <xref type="section" href="#topic11928/keys">Keys</xref>
        <ul>
          <li>
            <xref type="section" href="#topic11928/apptail">apptail</xref>
          </li>
          <li>
            <xref type="section" href="#topic11928/event">event</xref>
          </li>
          <li>
            <xref type="section" href="#topic11928/systail">systail</xref>
          </li>
          <li>
            <xref type="section" href="#topic11928/managing-the-systail-stream">Managing the systail
              stream</xref>
          </li>
        </ul></li>
<li>
        <xref type="section" href="#topic11928/configuration">Configuration</xref>
        <ul>
          <li>
            <xref type="section" href="#topic11928/drain-timeouts">Drain Timeouts</xref>
          </li>
          <li>
            <xref type="section" href="#topic11928/user-drain-limit">User Drain Limit</xref>
          </li>
          <li>
            <xref type="section" href="#topic11928/apptail-limits">Apptail Limits</xref>
          </li>
        </ul></li>
</ul>
<p>Application and system logs in Application Lifecycle Service are aggregated into streams
which can be viewed, tailed, filtered, and/or sent via drains to other
log aggregators for archiving or analysis. There are three general types
of streams:</p>
<ul>
<li>
<b>Application log streams</b>: application logs (plus relevant events)
from all instances</li>
<li>
<b>System log streams</b>: Application Lifecycle Service and other system logs from all
nodes (dmesg, dea.log, auth.log, etc.)</li>
<li>
<b>Cloud event streams</b>: cloud events from all nodes (see Cloud
Events in the Management Console)</li>
</ul>
<p>A <b>message</b> is a single log line or event in a stream.</p>
<p>Each message has a <b>key</b> which identifies <i>which</i> stream it belongs to (see <i><xref
          href="#topic11928/keys" format="dita">Keys</xref></i> below).</p>
<section id="logyard"> <title>Logyard</title>
<p>Log streams are handled by three processes which run on all Application Lifecycle Service
nodes:</p>
<ul>
<li>
<b>logyard</b>: listens for incoming log messages and forwarding them
to a configurable list of drains</li>
<li>
<b>systail</b>: sends system logs (/s/log/*, etc.) to <b>logyard</b> to
be in turn forwarded to drains</li>
<li>
<b>logyard_sieve</b>: listens for all system logs and extracts vital
events back to <b>logyard</b>
</li>
</ul>
<p>
<b>apptail</b> is an additional process which runs only on DEA nodes. It
sends user application logs to <b>logyard</b>, injecting relevant
application-specific events from the <b>logyard_sieve</b> stream.</p>
</section>
<section id="drains"> <title>Drains</title>
<p>A "drain" is a receiver for a log stream. Logyard has four kinds:</p>
<ul>
<li>TCP (e.g. &lt;tcp://10.0.11.101:12345&gt;)</li>
<li>UDP (e.g. udp://logs.papertrailapp.com:12345)</li>
<li>Redis (e.g. redis://192.168.1.157:5000/)</li>
<li>file (e.g. &lt;file:///s/logs/custom-drain-1.log&gt;)</li>
</ul>
</section>
<section id="system-drains"> <title>System Drains</title>
<p>Drains for system log and cloud event streams can be added by admins
  with the <xref href="../reference/kato-ref.dita#topic39432/kato-command-ref-log-drain-add" type="section"   >kato log
drain</xref>
command. For example:</p>
<codeblock>kato log drain add --prefix systail.kato mydrain udp://logs.papertrailapp.com:12345</codeblock>
<p>This creates a UDP drain that receives messages from <b>kato.log</b> (on
all nodes in the cluster) and forwards them to
<xref href="https://papertrailapp.com/" scope="external" format="html" >Papertrail</xref> on port 12345.</p>
  <p>The <codeph>--prefix</codeph> flag takes a <xref href="#topic11928/keys" format="dita">
<i>key</i>
</xref>
prefix as its argument.</p>
<p>To delete the drain:</p>
<codeblock>kato log drain delete mydrain</codeblock>
  <p>The <xref href="../reference/kato-ref.dita#topic39432/kato-command-ref-history" type="section"><i>kato history</i></xref> command
uses a built-in drain which forwards to a Redis server on the Primary
node.</p>
<p>The 'file' drain type will append to a local file. To overwrite the file
instead, add the 'overwrite=1' option:</p>
<codeblock>kato log drain add debug file:///s/logs/debug-1.log overwrite=1</codeblock>
</section>
<section id="log-format"> <title>Log Format</title>
<p>Log drains can emit entries in a variety of formats:</p>
<ul>
<li>verbatim (default): Log entries as they appear in the source log
files (plain text).</li>
<li>json: Log entries wrapped as JSON objects, with keys identifying
each part of the entry.</li>
<li>custom: Values of the specified JSON keys arranged in an arbitrary
format.</li>
</ul>
<p>For example, to add a drain with just the timestamp, application name
and message:</p>
<codeblock>kato log drain add -p apptail -f ' - : ' \
&gt; all-apps file:///s/logs/apptail-short.log</codeblock>
<p>JSON keys are enclosed in double curly braces and prefixed with a
period. The spaces, hyphen, and colon here are functioning as
delimiters. The resulting entry might look like this:</p>
<codeblock>2013-01-22T16:01:14-08:00 - myenv: Application 'myenv' is now running on DEA 27da51</codeblock>
  <p>Different JSON keys are available in different <xref href="#topic11928/keys" format="dita">
<i>log
streams</i>
</xref>:</p>
<p>
<b>apptail.</b>:</p>
<ul>
<li>text: actual log line</li>
<li>unix_time: timestamp (seconds since 1 January 1970)</li>
<li>human_time: formatted time</li>
<li>node_id: DEA host IP of this app instance</li>
<li>filename: log file from which this line originated</li>
<li>source: e.g. app, staging, helion.dea, helion.stager, appstore</li>
<li>instance_index: instance number</li>
<li>app_guid: GUID of this app</li>
<li>app_name: application name</li>
<li>app_space: GUID of the space this app belongs to</li>
<li>syslog.priority: syslog priority</li>
<li>syslog.time: syslog formatted time</li>
</ul>
<p>
<b>event.</b>:</p>
<ul>
<li>text: event description</li>
<li>unix_time: timestamp</li>
<li>human_time: formatted time</li>
<li>node_id: Node IP from which this event originated</li>
<li>type: type of event (eg: process_stop)</li>
<li>severity: INFO, WARN, ERROR</li>
<li>process: the process generating the event</li>
<li>info: event-specific information as JSON</li>
<li>syslog.priority: syslog priority</li>
<li>syslog.time: syslog formatted time</li>
</ul>
<p>
<b>systail.</b>:</p>
<ul>
<li>text: actual log line</li>
<li>unix_time: timestamp</li>
<li>human_time: formatted time</li>
<li>node_id: Node IP from which this log line originated</li>
<li>name: name of the component (eg: redis_gateway)</li>
<li>syslog.priority: syslog priority</li>
<li>syslog.time: syslog formatted time</li>
</ul>
  <p>You can see a list of the default drain formats using <xref href="../reference/kato-ref.dita#topic39432/kato-command-ref-config" type="section"   >
<i>kato config
get</i>
</xref>:</p>
<codeblock>kato config get logyard drainformats
apptail: ! ' .: '
event: ! '@:  -- via '
systail: ! '@: '
[...]</codeblock>
<p>These default log formats are used when the corresponding prefix is used
and no format options ("-f") are specified. For example
<codeph>kato drain add -p systail.dea ...</codeph> would format the
drain using the <i>systail</i> drain format.</p>
</section>
<section id="saving-custom-log-formats"> <title>Saving Custom Log Formats</title>
<p>Custom formats for drains can be saved as a named type in the Logyard
configuration. To do this, add the formatting string to a new key in
logyard/drainformats. For example, to save the log format used in the
**all-apps **drain example above:</p>
<codeblock>kato config set logyard drainformats/simplefmt " - : "</codeblock>
<p>You can use this named format when setting up new drains. For example, a
shorter command for creating the <b>all-apps</b> drain would be:</p>
<codeblock>kato log drain add -p apptail -f simplefmt all-apps file:///s/logs/apptail-short.log</codeblock>
<p>A custom <i>systail</i> log stream might look like this:</p>
<codeblock>kato config set logyard drainformats/systail-papertrail ' - @ -- '</codeblock>
<p>This could be forwarded to the Papertrail log analysis service:</p>
<codeblock>kato log drain add papertrail udp://logs.papertrailapp.com:45678 -f systail-papertrail</codeblock>
<p>You can also change the default apptail, event, and systail drain
formats to modify the output of any drains using these prefixes (e.g.
  <xref href="../../user/reference/client-ref-management.dita#topic50918/command-drain-add" type="section"   >helion drain</xref>, Cloud
  Events in the Management Console, and <xref href="../reference/kato-ref.dita#topic39432/kato-command-ref-log-tail" type="section">kato log tail</xref>
respectively).</p>
</section>
<section id="custom-drains"> <title>Custom Drains</title>
<p>You can add custom drains to Logyard to look for certain events or parse
certain log messages (e.g. tracking application push requests or user
logins). Examples of custom drains and more advanced usage of Logyard
can be found in the <xref href="https://github.com/hpcloud/logyard-devguide/blob/master/README.md" scope="external" format="html" >Logyard Developer
Guide</xref>
</p>
</section>
<section id="application-drains"> <title>Application Drains</title>
<p>Drains for application log streams can be added by end users with the <xref
          href="../../user/reference/client-ref-management.dita#topic50918/command-drain-add"
          type="section">
          <i>helion drain add</i>
        </xref> command. See the <xref href="../../user/deploy/app-logs.dita#topic5165">Application Logs</xref> section of the documentation for an example.</p></section>
<section id="drain-status"> <title>Drain Status</title>
<p>You can check the status of all drains on Application Lifecycle Service with the
<codeph>kato log drain status</codeph> subcommand. For example:</p>
<codeblock>kato log drain status
appdrain.1.mine         192.168.68.5    RUNNING[53]
appdrain.1.mydrain      192.168.68.5    RETRYING[75]  invalid port 3424252
builtin.apptail         192.168.68.5    RUNNING[3]
builtin.cloudevents     192.168.68.5    RUNNING[3]
builtin.katohistory     192.168.68.5    RUNNING[3]</codeblock>
<p>If the RETRYING drain hits a <xref href="#topic11928/drain-timeouts" format="dita"><i>drain
            timeout</i></xref>, its status will change to FATAL.</p>
</section>
<section id="keys"> <title>Keys</title>
<p>Each message in a log stream is prefixed with a key, identifying what type of message it is or to
        which log stream it belongs. The following keys are available for use in defining drains
        using the <codeph>--prefix</codeph> flag for <xref
          href="../reference/kato-ref.dita#topic39432/kato-command-ref-log-drain-add"><i>kato log
            drain add</i></xref> ).</p>
<p>Systail keys are <xref href="#topic11928/managing-the-systail-stream" format="dita"
            ><i>configurable</i></xref> .</p>
</section>
<section id="apptail"> <title>apptail</title>
<codeblock>apptail.\&lt;app.id\&gt;</codeblock>
</section>
<section id="event"> <title>event</title>
<ul>
<li>event.\&lt;eventname&gt; <ul>
            <li>process_stop</li>
            <li>process_exit</li>
            <li>kato_action</li>
            <li>timeline</li>
            <li>nginx_error</li>
            <li>vcap_error</li>
            <li>vcap_warning</li>
            <li>service_provision</li>
          </ul></li>
</ul>
</section>
<section id="systail"> <title>systail</title>
<ul>
<li>systail.\&lt;processname&gt;</li>
<li>systail.\&lt;processname&gt;.\&lt;nodeip&gt; <ul>
            <li>auth</li>
            <li>dmesg</li>
            <li>dpkg</li>
            <li>kato</li>
            <li>kernel</li>
            <li>nginx_error</li>
            <li>supervisord</li>
            <li>cc_nginx_error</li>
            <li>app_mdns</li>
            <li>app_store</li>
            <li>applog_redis</li>
            <li>apptail</li>
            <li>avahi_publisher</li>
            <li>cc_nginx</li>
            <li>cloud_controller_ng</li>
            <li>logyard_sieve</li>
            <li>dea_ng</li>
            <li>dockerd</li>
            <li>aok</li>
            <li>filesystem_gateway</li>
            <li>filesystem_node</li>
            <li>harbor_gateway</li>
            <li>harbor_node</li>
            <li>harbor_proxy_connector</li>
            <li>harbor_redis</li>
            <li>health_manager</li>
            <li>logyard</li>
            <li>memcached_gateway</li>
            <li>memcached_node</li>
            <li>mongodb_gateway</li>
            <li>mongodb_node</li>
            <li>mysql</li>
            <li>mysql_gateway</li>
            <li>mysql_node</li>
            <li>nats_server</li>
            <li>nginx</li>
            <li>postgresql</li>
            <li>postgresql_gateway</li>
            <li>postgresql_node</li>
            <li>prealloc</li>
            <li>rabbit_gateway</li>
            <li>rabbit_node</li>
            <li>redis_gateway</li>
            <li>redis_node</li>
            <li>redis_server</li>
            <li>router</li>
            <li>router2g</li>
            <li>stager</li>
            <li>systail</li>
          </ul></li>
</ul>
</section>
<section id="managing-the-systail-stream"> <title>Managing the systail stream</title>
<p>The list above shows the default systail keys. These can keys can be
  modified with the <xref href="../reference/kato-ref.dita#topic39432/kato-command-ref-config" type="section"   >
<i>kato
config</i>
</xref> command to
add arbitrary system log files to the stream or change the log file
source for an existing key.</p>
<ul>
<li>
<p>To retrieve the current list of log files being streamed:</p>

<codeblock>kato config get systail log_files</codeblock>
</li>
<li>
<p>To remove a log file from the stream:</p>

<codeblock>kato config del systail log_files/dpkg</codeblock>
</li>
<li>
<p>To add a new log file to the stream:</p>

<codeblock>kato config set systail log_files/dpkg /var/log/dpkg.log</codeblock>
</li>
</ul>
<p>Restart the <codeph>systail</codeph> process after adding or
removing log files:</p>
<codeblock>kato process restart systail</codeblock>
      <note type="caution"> Do not remove the default Application Lifecycle Service log stream keys (i.e. anything
        in the <i><xref href="#topic11928/systail" format="dita">systail</xref></i> list above) as
        this would affect the output of <codeph>kato tail</codeph>.</note>
</section>
<section id="configuration"> <title>Configuration</title>
<p>Application Lifecycle Service has a number of configurable limits on application log drains
to help prevent performance problems the logging subsystems. These
settings can all be viewed and set with <xref href="../reference/kato-ref.dita#topic39432/kato-command-ref-config" type="section"   >
<i>kato
config</i>
</xref> commands as
described below:</p>
</section>
<section id="drain-timeouts"> <title>Drain Timeouts</title>
<ul>
<li>
<p>
<b>logyard</b> <b>retrylimits</b>: If a drain gets disconnected (e.g. if
the log aggregation service goes down), Logyard will retry the
connection at the following intervals:</p>

<ul>
<li>once every 5 seconds for 1 to 2 minutes</li>
<li>once every 30 seconds for 5 minutes</li>
<li>once every 1 minute for 10 minutes</li>
<li>once every 5 minutes until connect or destroyed</li>
</ul>
<p>This ensures that once connectivity is restored, the drains will
re-establish their connections within (at most) 5 minutes.</p>

<p>Application drains will retry for one day. Temporary drains (e.g.
<codeph>kato tail</codeph>) will retry for 25 minutes. All
other drains will retry indefinitely.</p>

<p>These timeouts can be configured. To see a list of the configured
  timeouts, use <xref href="../reference/kato-ref.dita#topic39432/kato-command-ref-config" type="section"   >
<i>kato config
get</i>
</xref>. For
example:</p>

<codeblock>kato config get logyard retrylimits
appdrain.: 24h
tmp.: 25m</codeblock>

  <p>To set a time-out (minimum 21m), use <xref href="../reference/kato-ref.dita#topic39432/kato-command-ref-config" type="section"   >
<i>kato config
set</i>
</xref>. For
example, to set the timeout limit to 10 hours on all drains named
with the prefix "papertrail":</p>

<codeblock>kato config set logyard retrylimits/papertrail 10h</codeblock>

<p>These limits will take effect on new drains, deleted/re-created
drains, or for all matching drains after
<codeph>kato process restart logyard</codeph> has been run on
all nodes.</p>
</li>
</ul>
</section>
<section id="user-drain-limit"> <title>User Drain Limit</title>
<ul>
<li>
<p>
<b>cloud_controller_ng</b> <b>max_drains_per_app</b> (default 2):
limits the number of drains an application can have. Once this limit
is reached, users will see the following notification when trying to
add a new drain:</p>

<codeblock>Adding drain [fail] ... Error 123: Per-app drain limit (2) reached.</codeblock>

<p>To change the limit, set <codeph>max_drains_per_app</codeph> in
the cloud_controller_ng configuration. For example, to change this
limit to 5 drains:</p>

<codeblock>kato config set cloud_controller_ng max_drains_per_app 5</codeblock>
</li>
</ul>
</section>
<section id="apptail-limits"> <title>Apptail Limits</title>
<ul>
<li>
<p>
<b>apptail</b> <b>read_limit</b> (default 16MB): defines the maximum
number of bytes to read from the end of application log files. This
is done to prevent performance problems during restart of the
<codeph>apptail</codeph> process (or nodes running the process)
if the log file sources have grown extremely large.</p>

<p>When this limit is reached, a warning such as the following will
appear in both the Cloud Events stream and the application's log
stream:</p>

<codeblock>WARN -- [exampleapp] Skipping much of a large log file (stderr); size (26122040 bytes) &gt; read_limit (15728640 bytes)</codeblock>

<p>To change the read_limit to 100MB:</p>

<p>kato config set apptail read_limit 100</p>
</li>
<li>
<p>
<b>apptail</b> <b>rate_limit</b> (default 400): limits the number of log
lines per second that can be read from an application log file. The
<codeph>apptail</codeph> process reads (at most) the specified
number of log lines per second, after which it will wait for one
second before resuming. A line similar to the <codeph>read_limit</codeph> warning above is inserted in the stream to explain the
missing data.</p>

<p>To change the rate_limit to 300 lines:</p>

<codeblock>kato config set apptail rate_limit 300</codeblock>
</li>
</ul>
</section>
<section id="debugging-logyard"> <title>Debugging Logyard</title>
<p>Use <codeph>kato log stream debug</codeph> to monitor
Logyard-related log activity. The command tails the logyard, apptail,
systail, and logyard_sieve streams.</p>
</section>
</body>
</topic>
