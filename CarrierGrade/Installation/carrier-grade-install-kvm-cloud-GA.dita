<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE topic
  PUBLIC "-//OASIS//DTD DITA Topic//EN" "http://docs.oasis-open.org/dita/v1.1/OS/dtd/topic.dtd" ><topic xml:lang="en-us" id="topic1107">
<title>HP Helion <tm tmtype="reg">OpenStack</tm> Carrier Grade 2.0 Alpha: Deploying the KVM Region</title>
<prolog>
  <metadata>
    <othermeta name="layout" content="default"/>
    <othermeta name="product-version" content="HP Helion Openstack Carreir Grade 1.1"/>
    <othermeta name="role" content="Storage Administrator"/>
    <othermeta name="role" content="Storage Architect"/>
    <othermeta name="role" content="Michael B"/>
    <othermeta name="product-version1" content="HP Helion Openstack Carreir Grade 1.1"/>
  </metadata>
</prolog>
<body>


 <!--./CarrierGrade/Installation/carrier-grade-install-pb-hlm-cloud.md-->
 <!--permalink: /helion/openstack/carrier/install/pb/hlm-cloud/-->
<p>After the HLM VM is up and running and HP Helion OpenStack is installed, use the following steps
      to deploy the KVM region.</p>
  <section>
      <title>Bring Up Controller-0 in the KVM Region</title>
      <ol>
        <li>Make sure other servers to be used in KVM region are shutdown.</li>
        <li>Use the <codeph>HP-HCG-Server-host-installer-15.05-b10.iso</codeph> to boot the
          controller
          node.<codeblock>mount HP-HCG-Server-host-installer-15.05-b10.iso</codeblock></li>
        <li>Follow the install wizard. Select the Graphics mode for the controller only. Do not
          select <codeph>Controller+Compute</codeph>.</li>
        <li>After the reboot, log in as user name <codeph>wrsroot</codeph> and password
            <codeph>wrsroot</codeph>. Make sure you change the password.</li>
        <li>Temporarily assign an IP address to the PXE NIC - eth0. Use the IP you have reserved for
          the KVM PXE. <codeblock>ip addr add &lt;CIDR> dev eth0
ifconfig eth0 up</codeblock></li>
        <li> Set the default gateway to the PXE network gateway
          <codeblock>route add default gw &lt;CIDR_gateway_IP&gt;</codeblock></li></ol>
  </section>
    
    <section>
      <p><b>Install the KVM region license</b></p>
      <p>The servers in the KVM region require a specific license file to be installed. You must
        download this file from the <xref
          href="https://helion.hpwsportal.com/catalog.html#/Home/Show" format="html"
          scope="external">HP Helion Download Network(HDN)</xref>. </p>
      <p>Before installing the patch, make sure the KVM region controller-0 was properly installed
        by the HP Helion OpenStack Carrier Grade installation. </p>
      <ol id="ol_mdt_dd3_ys">
        <!--<li>In a browser, navigate to <xref href="https://helion.hpwsportal.com/catalog.html#/Home/Show" format="html" scope="external">HP Helion Download Network(HDN)</xref>. <ul id="ul_lvg_jb2_xs"><li>Click <b>Sign In</b> to log in using your account. </li><li>After signing in, click the <b>Downloads</b> link in the menu on the left side of the page.</li><li>On the <b>Downloads</b> page, locate HP Helion OpenStack Carrier Grade and click <b>Download</b></li></ul>.</li>-->
        <li>Download and extract the <b id="productShow_apcodeph">Helion Carrier Grade 2.0.0
            Windriver License patch signature file</b> and the associated signature and checksum
          files. For information on performing verifications of the download, see the Prerequistues. </li>
        <li>Copy the following files to the <codeph>/home/wrsroot/</codeph> directory of the
          controller-0. The files are located in the <codeph>/root/cg-hlm/windriver-files</codeph>
          directory on the HLM host.<ul id="ul_mpn_hnr_bt">
            <li><codeph>HCG_2.0_WR_license.lic.txt</codeph></li>
            <li><codeph>region_config</codeph>
            </li>
            <li><codeph>cakey.pem</codeph></li>
          </ul></li>
        <li>Restart <codeph>controller-0</codeph> to load the license file.</li>
      </ol>
    </section><section><title>Install the KVM region cloud</title>
      <ol>
        <li>Execute the following command to install the KVM region cloud:
              <codeblock>sudo config_region</codeblock><p><image
              href="../../media/CGH-install-KVM.png" width="500" id="image_c2w_4kk_bt"/></p>Ignore
          the message which displays during <codeph>config_region</codeph> process.
              <codeblock>Step 9 of 29 [####  ]dm-6 WRITE SAME failed. Manually zeroing. </codeblock><p><image
              href="../../media/CGH-install-kvm-error.png" width="500"/></p></li>
        <li>After <codeph>controller-0</codeph> is deployed, deploy the remaining nodes as
            <codeph>controller-1</codeph> and <codeph>compute-'n'</codeph>.
              <codeblock>system host-add --hostname controller-1 --personality controller --mgmt_mac &lt;mgmt_mac&gt; --bm_mac &lt;bm_mac&gt; --bm_ip &lt;ilo_ip&gt; --bm_type ilo4 --bm_username &lt;ilo_user&gt; --bm_password &lt;ilo_password&gt;
system host-add --hostname &lt;unique-compute-name&gt; --personality compute --mgmt_mac &lt;mgmt_mac&gt; --mgmt_ip &lt;mgmt_ip&gt; --bm_mac &lt;ilo_mac&gt; --bm_ip &lt;ilo_ip&gt; --bm_type ilo4 --bm_username &lt;ilo_user&gt;  --bm_password &lt;ilo_password&gt;</codeblock><p><image
              href="../../media/CGH-install-kvm-host-add.png" id="image_tv5_wz1_ct" width="300"
            /></p></li>
        <li>While registering compute nodes, make sure you specify the <codeph>mgmt_ip</codeph>.
          This IP should from the KVM CLM range (refer to the <codeph>region_config</codeph> file)
          and must not overlap controller IPs. It is safe to start after a block of 10 IPs.</li>
        <li>Configure the controller and compute nodes to one-time PXE booting from the
          network.</li>
        <li>Restart the nodes.</li>
        <li>Access the Horizon dashboard using the CAN network IP (HTTPS). </li>
        <li><xref href="../AdminGuideNew/Dashboard/carrier-grade.dashboard.launch.dita#topic1160"
            >Log in to the Horizon interface</xref> and monitor the status of nodes being PXE
          booted. After succesful PXE boot, Operational State as Disabled and Availability State as
          Online in the <b>Admin</b>, then <b>Inventory</b> page. <p><b>Note:</b>The Horizon
            Dashboard will be running on the first IP address of the CLM network range (refer to the
              <codeph>ip_start_address</codeph> value provided for the CLM network in the
              <codeph>definition.json</codeph> during the non-KVM Region deployment). </p><p>The
            log-in credentials for Horizon are as
            follows:</p><codeblock>username: admin 
password:  &lt;random> </codeblock><p>The
            Horizon password is randomly generated during the installation. You can locate the
            password in the <codeph>stackrc</codeph> file on any of the non-KVM region
            controllers.</p></li></ol> 
    </section>
  <section id="unlock"><title>Configure and unlock the compute controllers</title>
    <p>After the controller-1 and the compute nodes come up successfully after PXE boot, execute the
        following commands from controller-0 to unlock  each compute node in the inventory, based on
        your deployment.</p>
      <p><b>Note:</b> If you are using a bonded interface, <xref href="#topic1107/nic" format="dita"
          >also follow the instructions below</xref> after completing these steps.</p>
    <p><b>For KVM deployments</b></p>
    <ol>
      <li>Create the Infra interface. See <xref
        href="../AdminGuideNew/HostManagement/carrier-grade-admin-wr-host-management-inventory-detail-interfaces.dita#topic6151"
      /> or <i>Interfaces</i> in the Administrtor Guide.</li>
      <li>Create a Provider Network. See <xref
        href="../AdminGuideNew/Networks/carrier-grade.dashboard.network.admin.create.provider.dita#topic3878"
      /> or <i>Setting Up a VXLAN Provider Network</i> in the Administrator Guide.</li>
      <li>Create VLAN Ranges on the provider network using the <b>Create Segmentation
        Range</b> option. See <xref
          href="../AdminGuideNew/Networks/carrier-grade.dashboard.network.admin.create.segment.dita#topic2171"
        /> or <i>Setting Up a VXLAN Provider Network</i> in the Administrator Guide.</li>
      <li><xref href="carrier-grade-install-kvm-network-interface.dita#topic1107">Create data
        interface.</xref> See <i>Configuring Endpoint IP Addresses</i> in the Administrator
        Guide.</li>
      <li>Optionally, change the default CPU allocations and/or the default memory allocations
        (huge pages) on each processor, such as the NUMA (Non-Uniform Memory Access) nodes.
        See <i>Processor</i> in the Administrator Guide.</li>
    
    <li><xref
      href="../AdminGuideNew/HostManagement/carrier-grade-admin-wr-host-management-host-lock.dita#topic3241"
      >Unlock the compute nodes</xref>. Compute nodes will reboot.  Keep polling the status on
      the inventory page to show <b>Available</b> and <b>Online</b>.</li>
        <li>If you are using a bonded interface, see <xref href="#topic1107/nic" format="dita">For
            bonded NIC environments</xref>.</li>
      </ol> 
    <p><b>For KVM with DCN or KVM + ESX deployments</b></p>
    <ol>
            <li>After the controller-1 and the compute nodes come up successfully after PXE boot,
          execute the following commands from controller-0 to unlock the compute nodes.<ol
            id="ol_p42_d35_lt">
            <li>Create the Infra interface:
              <codeblock>system host-if-add –V &lt;bls/infra VLAN ID&gt; –nt &lt;network_type> &lt;host-name or ID> &lt;interface_name> &lt;interface_type> &lt;port or interfaces></codeblock></li>
            <li>Add an IP address to the Infra interface:
              <codeblock>system host-addr-add &lt;host-name or ID> &lt;interface_name> &lt;ipv4/ipv6_address> &lt;prefix-length></codeblock></li>
            <li>Configure the VRS interface:
                <codeblock>system host-if-modify &lt;host-name or ID> -n &lt;interface_name> -nt &lt;network_type> --ipv4-mode=static eth-x </codeblock><p>Where
                  <codeph>eth-x</codeph> is the interface on which untagged TUL is
              presented.</p></li>
            <li>Add an IP address to the VRS interface:
              <codeblock>system host-addr-add &lt;host-name or ID> vrs &lt;ipv4/ipv6_address> &lt;prefix_length></codeblock></li>
            <li>Update the host:
                <codeblock> system host-update &lt;host-name or ID> vsc_controllers=&lt;ipv4/ipv6_address>,&lt;ipv4/ipv6_address> </codeblock><p>Enter
                the IP address of the VSC controllers</p></li>
            <li>Unlock the host: <codeblock>system host-unlock &lt;host-name or ID></codeblock></li>
          </ol><p><b>Example
          commands:</b></p><codeblock>system host-if-add –V 722 –nt infra compute-3 infra vlan pxeboot0
system host-addr-add compute-3 infra 10.70.22.81 24
system host-if-modify compute-3 -n vrs -nt data-vrs --ipv4-mode=static eth4
system host-addr-add compute-3 vrs 10.70.5.83 24
system host-update compute-3 vsc_controllers=10.70.5.31,10.70.5.32
system host-unlock compute-3        </codeblock></li>
            <li>Perform the following steps on controller-0 to ensure instance launching succeeds.
              Repeat the commands for each compute node.
              <codeblock>source /etc/nova/openrc
nova aggregate-create remote_storage_hosts
nova aggregate-set-metadata remote_storage_hosts localstorage=false
nova aggregate-add-host remote_storage_hosts &lt;compute host name&gt;</codeblock></li>
        <li>If you are using a bonded interface, see <xref href="#topic1107/nic" format="dita">For
            bonded NIC environments</xref>.</li>
      
      </ol>
  </section>
  <section id="nic"><title>For bonded NIC environments</title>
      <p>If you are using a bonded NIC environment, after configuring and unlocking the compute
        nodes, perform these steps:</p>
      <ol id="ol_nr5_ddw_mt">
        <li>Use the following commands to delete MGMT interface:
          <codeblock>system host-list ( used to gather compute name or id# )
system host-if-list ( used to gather UUID of interface mgmt to remove )
system host-if-modify -nt "none" compute-0 pxeboot0 ( used to remove pxeboot flag off interface )
system host-if-delete compute-0 95e7b495-1454-49d1-8123-301215503e86      </codeblock></li>
      
    <li>Use the following commands to create a bonded interface and setup node to be unlocked:
          <codeblock>system host-if-add -a 802.3ad -x layer2 -nt pxeboot compute-0 bond0 ae "none" eth0 eth1
system host-if-add -V 303 -nt mgmt compute-0 mgmt vlan bond0
system host-if-add -V 74 -nt infra compute-0 infra vlan bond0
system host-addr-add compute-0 infra 172.16.74.244 24
system host-if-add -a balanced -x layer2 -nt "none" compute-0 bondvrs ae "none" eth2 eth3
system host-if-modify compute-0 -nt data-vrs --ipv4-mode=static bondvrs
system host-addr-add compute-0 bondvrs 10.30.6.244 24
system host-update compute-0 vsc_controllers=10.30.6.31,10.30.6.32</codeblock></li></ol>
    </section>
  
  <section id="next-step"> <title>Next Steps</title>
      <p><xref href="carrier-grade-install-metadata.dita#topic10581">Configure the DCN Metadata
          Agent</xref> (KVM + ESX deployments only)</p>
  </section>
</body>
</topic>
