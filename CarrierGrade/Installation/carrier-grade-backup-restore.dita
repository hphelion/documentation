<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE topic
  PUBLIC "-//OASIS//DTD DITA Topic//EN" "http://docs.oasis-open.org/dita/v1.1/OS/dtd/topic.dtd" >
<topic xml:lang="en-us" id="topic10581">
  <title>HP Helion <tm tmtype="reg">OpenStack</tm> Carrier Grade 1.1: Backup and Restore the HLM
    Node and MySQL Cluster</title>
  <prolog>
    <metadata>
      <othermeta name="layout" content="default"/>
      <othermeta name="product-version" content="HP Helion Openstack Carreir Grade 1.1"/>
      <othermeta name="role" content="Storage Administrator"/>
      <othermeta name="role" content="Storage Architect"/>
      <othermeta name="role" content="Michael B"/>
      <othermeta name="product-version1" content="HP Helion Openstack Carreir Grade 1.1"/>
    </metadata>
  </prolog>
  <body>
    <!-- https://wiki.hpcloud.net/pages/viewpage.action?pageId=53513771 -->
    <p>This page explains how to backup and restore the HLM VM in the event of catastrophic failure.
      The page also explains how to <xref href="#topic10581/mysql" format="dita">recover the <tm
          tmtype="reg">Percona</tm>
        <tm tmtype="reg">XtraDB</tm> cluster</xref> on the cloud controllers in the event of a
      database corruption.</p>
    <p>The HP Helion OpenStack cloud installation provides highly optimized <tm tmtype="reg">MySQL</tm>
      databases inside of the HP Helion Public Cloud. A MySQL node is installed on each of the three
      controller nodes in the non-KVM region. The installation also includes the Percona XtraDB
      application, which takes care of synchronization of the data between nodes if one of the nodes
      goes down and comes back later. You can use Percona XtraDB to backup and restore the MySQL
      nodes.</p>
    <section><title>When to Backup the HLM VM</title>
      <p>You should create a backup from HLM VM as follows:</p>
      <ul>
        <li>when the HP Helion OpenStack Carrier Grade installation is complete,</li>
        <li>when any change is made to the HP Helion OpenStack Carrier Grade components, </li>
        <li>after synching the files on the HLM VM. The files should be synced periodically.</li>
      </ul>
    </section>
    <section>
      <title>When to Restore the HLM VM</title>
      <p>You should restore the HLM VM if there are any issues with the HP Helion OpenStack Carrier
        Grade components, for example:</p>
      <ul>
        <li>there is any problem with a VM;</li>
        <li>there is any problem in the OS level;</li>
        <li>there is any problem with the installation that cannot be corrected.</li>
      </ul>
      <p><b>Important:</b> During the restore process the original HLM VM will be deleted from the
        KVM Host. </p>
    </section>
    <section><title>Backing up the HLM VM</title>
      <p>To back up the HLM VM, use the following steps:</p>
      <ol>
        <li>Log in to the HLM host.</li>
        <li>Backup the <codeph>/root/infra-ansible-playbooks</codeph> folder by copying the folders
          to a remote system. This will backup the <codeph>group_vars</codeph> folder used to create
          the HLM VM. </li>
        <li>Backup the following folders to a remote system: <ul>
            <li>
              <codeph>/root</codeph> - This backs up all the source code, packages, hlinux netboot
              as well as cloud folders</li>
            <li><codeph>/opt</codeph> - This backs up all the installed code/configuration and also
              h* scripts</li>
            <li><codeph>/var/log/hlm</codeph> - This backs up all generated log files </li>
            <li><codeph>/root/.ssh</codeph> - This backs up ssh keys generated per cloud used to
              access cloud nodes </li>
          </ul></li>
      </ol>
    </section>
    <section><title>Restore the HLM VM</title>
      <p>To restore the HLM VM, use the following steps:</p>
      <ol>
        <li>Log in to the HLM host.</li>
        <li>Copy the <codeph>/root/infra-ansible-playbooks</codeph> folder from the backup location
          to the HLM host.</li>
        <li>Re-create the HLM VM by executing from <codeph>/root/infra-ansible-playbooks</codeph>
          folder: <codeblock>ansible-playbook -i hosts setup_hlm_onBM.yml</codeblock></li>
        <li>Log in to the HLM VM.</li>
        <li>Copy the following files from the backup folder to the same location on the HLM VM:
          <ul><li><codeph>/root</codeph></li>
        <li><codeph>/opt</codeph></li>
        <li><codeph>/var/log/hlm</codeph></li>
        <li><codeph>/root/.ssh</codeph></li></ul></li>
      </ol>
    </section>
    <section id="mysql"><title>Backup and Restore the MySQL cluster</title>
      <p>This section deals with the disaster recovery scenarios of the three node MySQL cluster
        (Percona XtraDB Cluster) that runs in cloud controller nodes. </p>
      <p>If an entire cluster goes down, due to an issue (such as data corruption or MySQL defect),
        and the cluster does not come back up, you must restore the cluster to a previous well-known
        state (backup) and start the cluster from that point.</p>
      <p>You should use to take full backups of the MySQL custer frequently, such as on a daily
        basis. Backing up the node on any single controller will backup the full cluster.</p>
      <p>If the full cluster goes down or some data corruption occurs, delete the current data in
        all of the three nodes of MySQL and restore the backup copy on the same node from which
        backup was taken. Then, bootstrap the cluster and bring up rest of the nodes to synchronize
        the data with the recovered node of cluster.</p>
    </section>
    <section><title>Backing up the MySQL cluster</title>
      <p>Use the following steps to back up the MySQL cluster:</p>
      <ol>
        <li>Execute the following command to SSH into one of the controllers in the non-KVM region.
          This procedure assumes you are using <codeph>Controller0</codeph>:
            <codeblock>ssh &lt;ip-address-controller0></codeblock><p>Where
              <codeph>&lt;ip-address-controller0></codeph> is the IP address of
              <codeph>controller0</codeph> node of your environment.</p></li>

        <li>Take full backup using Percona XtraBackup by running the <codeph>innobackup</codeph>
          perl script. <codeblock>sudo innobackupex --galera-info /backups</codeblock><p>Where
              <codeph>/backups</codeph> is the backup location of your environment.</p><p>The script
            creates a timestamped folder (for example: <codeph>2013-11-06_00-00-00</codeph>) that
            contains all backup files. The backup file contains the local node state at the time of
            the backup. </p><p>More info about <codeph>innobackupex</codeph> is at: <xref
              href="http://www.percona.com/doc/percona-xtrabackup/2.1/innobackupex/innobackupex_option_reference.html"
              format="html" scope="external"
              >http://www.percona.com/doc/percona-xtrabackup/2.1/innobackupex/innobackupex_option_reference.html</xref>.</p></li>

        <li>Prepare the backup to be consistent. The <codeph>apply-log</codeph> option creates log
          files that the <codeph>innobackupex</codeph> script uses to make sure the restore works
          properly.
            <codeblock>sudo innobackupex --apply-log /backups/&lt;timestamped-folder-path></codeblock><p>Where
              <codeph>&lt;timestamped-folder-path></codeph> is the path to the timestamped folder
            generated in previous step.</p></li>

        <li>Copy the timestamped backup folder to a remote location.</li>
      </ol>
    </section>
    <section><title>Restore the MySQL cluster</title>
      <p>Use the following steps to restore the MySQL cluster:</p>
      <ol>
        <li>Stop the MySQL instance on all the three cluster nodes.
          <codeblock>sudo /etc/init.d/mysql stop</codeblock></li>
        <li>Delete the current data in the MySQL nodes on each of the three cluster nodes.<ol
            id="ol_ccd_g5v_dt">
            <li>SSH into each MySQL node.</li>
          <li>Execute the following command:
              <codeblock>sudo rm -rf /var/lib/mysql/*</codeblock></li></ol></li>
        <li>Copy the timestamped backup folder from the remote location to any location on the
          controller from which you created the backup.</li>
        <li>Perform a Percona XtraBackup recovery using the <codeph>innobackupex</codeph> command
            <codeblock>sudo innobackupex --copy-back /backups/&lt;timestamped-folder-path> </codeblock><p>Where
              <codeph>&lt;timestamped-folder-path></codeph> is the path to the timestamped backup
            folder you copied to the contoller.</p></li>
        <li>Change the permissions of MySQL data folder for the MySQL user and group.
          <codeblock>sudo chown -R mysql:mysql /var/lib/mysql </codeblock></li>
        <li>Start the MySQL cluster on the controller in bootstrap mode.
          <codeblock>sudo /etc/init.d/mysql bootstrap-pxc</codeblock></li>
        <li>SSH to each of the other controllers in the non-KVM region and restart the MySQL
          service. <codeblock>sudo service mysql start</codeblock><p>The other MySQL nodes in the
            cluster will automatically sync data with the restored MySQL node. When this command is
            complete, the MySQL cluster is fully restored to the last known .</p></li>
      </ol>
    </section>
  </body>
</topic>
