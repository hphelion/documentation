<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE topic
  PUBLIC "-//OASIS//DTD DITA Topic//EN" "http://docs.oasis-open.org/dita/v1.1/OS/dtd/topic.dtd" ><topic xml:lang="en-us" id="topic6261">
<title>HP Helion OpenStack(R) Carrier Grade (Beta): Configuring PCI Passthrough Ethernet Interfaces</title>
<prolog>
<metadata>
<othermeta name="layout" content="default"/>
<othermeta name="product-version" content="HP Helion OpenStack(R)"/>
<othermeta name="product-version" content="HP Helion OpenStack(R) 1.1"/>
<othermeta name="role" content="Systems Administrator"/>
<othermeta name="role" content="Cloud Architect"/>
<othermeta name="role" content="Storage Administrator"/>
<othermeta name="role" content="Network Administrator"/>
<othermeta name="role" content="Service Developer"/>
<othermeta name="role" content="Cloud Administrator"/>
<othermeta name="role" content="Application Developer"/>
<othermeta name="role" content="Network Engineer"/>
<othermeta name="role" content="Paul F"/>
<othermeta name="product-version1" content="HP Helion OpenStack(R)"/>
<othermeta name="product-version2" content="HP Helion OpenStack(R) 1.1"/>
</metadata>
</prolog>
<body><section id="top" />
<p>
<!--UNDER REVISION-->
 <!--./CarrierGrade/AdminGuideNew/ConfigPlanning/carrier-grade-admin-wr-config-pci-pass.md-->
 <!--permalink: /helion/openstack/carrier/configuration/plan/pci-passthru/--></p>
<!-- From the Titanium Server Admin Guide -->
<p>A passthrough Ethernet interface is a physical PCI Ethernet NIC on a compute node to which a virtual machine is granted direct access. This minimizes packet processing delays but at the same time demands special operational considerations.</p>
<!-- ===================== horizontal rule ===================== -->
<p>
<b>Note:</b> This feature applies only to servers in the VNF Region.</p>
<!-- ===================== horizontal rule ===================== -->
<p>For all purposes, a PCI passthrough interface behaves as if it were physically attached to the virtual machine.</p>
<p>Any potential throughput limitations coming from the virtualized environment, such as the ones introduced by internal copying of data buffers, are eliminated. However, by bypassing the virtualized environment, the use of PCI passthrough Ethernet devices introduces several restrictions that must be taken into consideration, including:</p>
<ul>
<li>no support for LAG, QoS, ACL, or host interface monitoring</li>
<li>no support for live migration</li>
<li>no access the compute node's AVS switch</li>
</ul>
<p>A passthrough interface bypasses the compute node's AVS switch completely, and is attached instead directly to the provider network's access switch. Therefore, proper routing of traffic to connect the passthrough interface to a particular tenant network depends entirely on the VLAN tagging options configured on both the passthrough interface and the access port on the switch.</p>
<p>The access switch routes incoming traffic based on a VLAN ID, which ultimately determines the tenant network to which the traffic belongs. The VLAN ID is either explicit, as found in incoming tagged packets, or implicit, as defined by the access port's default VLAN ID when the incoming packets are untagged. In both cases the access switch must be configured to process the proper VLAN ID, which has to be known in advance.</p>
<p>To configure the access switch:</p>
<ol>
<li>
        <xref href="../Dashboard/carrier-grade.dashboard.launch.dita">Launch the HP Helion
          OpenStack(R) Horizon Dashboard</xref> as the admin user.</li>
<li>
        <xref href="../HostManagement/carrier-grade-admin-wr-host-management-host-lock.dita">Lock
          the compute node</xref> you want to configure.</li>
<li>Configure the Ethernet interface to be used as a PCI passthrough interface.<p>a. Click
            <b>Inventory</b> on the <b>System Panel</b> section of the <b>Admin</b> menu, and then
          selecting the <b>Hosts</b> tab.</p><p>b. In the <b>Hosts</b> list, click the name of the
          compute node where the PCI interface is available.</p><p>c. Click the <b>Interfaces</b>
          tab, and finally click the <b>Edit Interface</b> button associated with the interface you
          want to configure.</p><p>d. Specify the interface to associtate.</p><p>e. Select
            <codeph>pci-passthrough</codeph> under <b>Network Type</b>.</p><p>f. Select the provider
          network to connect with.</p><p>e. Click <b>Save</b>.</p></li>
<li>Create the <codeph>net0</codeph> tenant network by click <b>Networks</b> on the <b>Admin</b>
          menu.<p>a. Click <b>Create Network</b>
        </p><p>b. In the <b>Select Network</b> screen, select a network that has access to the
          tenant network.</p><p>c. Set the segmentation ID to <codeph>10</codeph>.</p><p>d. Click
            <b>Create Network</b>.</p></li>
<li>Configure the access switch.<p>Configure the physical port on the access switch used to connect
          to Ethernet interface eth8 as an access port with default VLAN ID of 10. Traffic across
          the connection is therefore untagged, and effectively integrated into the targeted tenant
          network.</p><p>You can also use a trunk port on the access switch so that it handles
          tagged packets as well. However, this opens the possibility for guest applications to join
          other tenant networks using tagged packets with different VLAN IDs, which might compromise
          the security of the system. See L2 Access Switches for other details regarding the
          configuration of the access switch.</p></li>
<li>
        <xref href="../HostManagement/carrier-grade-admin-wr-host-management-host-lock.dita">Unlock
          the compute node</xref>.</li>
<li>Launch the virtual machine.<p>a. Log into Horizon as a non-admin user to the web management
          interface.</p><p>b. Click <b>Instance</b> on the <b>Compute</b> section of the
            <b>Pronect</b> menu.</p><p>c. Click <b>Launch Instance</b>.</p><p>d. In the <b>Launch
            Instance</b> screen, configure the necessary options for the new virtual machine. In
          particular, click the <b>Networking</b> tab and add a PCI passthrough interface on the
          tenant network. Add other network interfaces as needed.</p><p>e. Click the Launch button
          to proceed.</p></li>
</ol>
<p>The interface can also be configured using the following CLI commands:</p>
<codeblock><codeph>system host-if-modify \
-nt pci-passthrough -p group0-data0 compute-0 eth8
</codeph></codeblock>
<p>Passthrough interfaces can be attached from the CLI when booting a new virtual machine, as illustrated below:</p>
<codeblock><codeph>nova boot \
--nic net-id=704e9f3b,vif-model=pci-passthrough my-new-vm
</codeph></codeblock>
<p>The new virtual machine instance is up now. It has a PCI passthrough connection to the tenant network identified with VLAN ID 10.</p>
<p>Access switches must be properly configured to ensure that virtual machines using PCI-passthrough or <xref href="../ConfigPlanning/carrier-grade-admin-wr-config-sr-iov.dita" >SRIOV Ethernet interfaces</xref> have the expected connectivity. In a common scenario, the virtual machine using these interfaces connects to external end points only, that is, it does not connect to other virtual machines in the same TiS cluster.</p>
<p>In this case:</p>
<ul>
<li>Traffic between the virtual machine and the access switch can be tagged or untagged.</li>
<li>The connecting port on the access switch is part of a port-based VLAN.</li>
<li>If the port is tagged, the allowed VLAN ID range must not overlap with VLAN ID ranges used by the AVS ports.</li>
<li>The port-based VLAN provides the required connectivity to external switching and routing equipment needed by
guest applications to establish connections to the intended end points.</li>
</ul>
<p>For connectivity to other virtual machines in the TiS cluster the following configuration is also required:</p>
<ul>
<li>The VLAN ID used for the tenant network, 10 in this example, and the default port VLAN ID of the access port on the switch are the same. This ensures that incoming traffic from the virtual machine is tagged internally by the switch as belonging to VLAN ID 10, and switched to the appropriate exit ports.</li>
<li>The target virtual machines are reachable through another port on the compute node, which is managed by the
AVS.</li>
<li>That other port is configured as usual, as a VLAN trunk port, and the tenant network's VLAN ID (10) is included in the tagged range. This ensures that VLAN 10 is common to both the passthrough/SR-IOV interface and the AVS port.</li>
</ul>
<p>
  <xref type="section" href="#topic6261/top"> Return to Top </xref>
</p>
<!-- ===================== horizontal rule ===================== -->
</body>
</topic>
