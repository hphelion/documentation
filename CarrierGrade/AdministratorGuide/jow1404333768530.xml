<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE topic   PUBLIC "-//OASIS//DTD DITA Topic//EN" "http://docs.oasis-open.org/dita/v1.1/OS/dtd/topic.dtd" >
<topic domains="(topic concept topic)                            (topic hi-d)                            (topic indexing-d)                            (topic pr-d)                            (topic sw-d)                            (topic ui-d)                            (topic wr-sw-d)                            (topic xml-d)   " id="jow1404333768530" xml:lang="en-us">
    <!-- Modification History
   -->
    <title >Processor</title>
    <shortdesc >The <uicontrol >Processor</uicontrol> tab on the
            <wintitle >Inventory Detail</wintitle> page presents processor details for
        a host, as illustrated below.</shortdesc>
    <prolog>
        <author >Pedro Sanchez</author>
    </prolog>
    <body>
        <fig id="fig_N10027_N10024_N10001" >
            <image href="jow1404333763192.image" id="image_iqn_jlz_l4"  width="6in"/>
        </fig>
        <p >The <uicontrol >Processor</uicontrol> tab includes the following items:</p>
        <ul id="ul_stv_nlz_l4">
            <li >
                <p >processor model, number of processors, number of cores per
                    processor, and Hyper-Threading status (enabled or disabled).</p>
            </li>
            <li >
                <p >the CPU assignments. See section <xref href="jow1404333787693.xml#jow1404333787693/cpu-profiles" /> for more details.</p>
            </li>
        </ul>
        <p >Two buttons are also available as follows:</p>
        <dl>
            <dlentry >
                <dt ><uicontrol >Create CPU Profile</uicontrol></dt>
                <dd >
                    <p >Clicking this button displays the <wintitle >Create CPU Profile</wintitle> window, where
            the current CPU assignment can be given a name, as illustrated below.</p>
                    <fig id="fig_N1006F_N10064_N1005B_N10058_N10024_N10001" >
                        <image href="jow1404333764867.image" id="image_mj3_zmz_l4"  width="4in"/>
                    </fig>
                    <p >In this example, you are about to create a CPU Profile named
              <codeph >HP-360-C1</codeph> out of the current CPU assignments found in a
            compute node.</p>
                </dd>
            </dlentry>
            <dlentry >
                <dt ><uicontrol >Edit CPU Assignments</uicontrol></dt>
                <dd >
                    <p >This button is available only when the host is in the locked
                        state.</p>
                    <p >Clicking this button displays the <wintitle >Edit CPU Assignments</wintitle> window,
            where the current CPU assignment can be changed, as illustrated below for a compute
            node.</p>
                    <fig id="fig_N1009D_N1008E_N10085_N10058_N10024_N10001" >
                        <image href="jow1404333766847.image" id="image_khm_xsz_l4"  width="5in"/>
                    </fig>
                    <p >Currently, the number of platform cores is limited to one for
                        each host. In the example above, this is indicated by the read-only platform
                        fields that allocate one core from processor 0.</p>
                    <p >AVS cores can be configured for each processor independently.
                        This means that the single logical vSwitch running on a compute node can
                        make use of cores in multiple processors, or NUMA nodes. Optimal data path
                        performance is achieved however, when all AVS cores, the physical ports, and
                        the virtual machines that use them, are all running on the same processor.
                        However, having AVS cores on all processors ensures that all virtual
                        machines, regardless of the core they run on, are efficiently serviced. The
                        example allocates two cores from processor 0 to the AVS threads.</p>
                    <p >One physical core per processor can be configured as a shared CPU, which can
                        be used by multiple VMs for low-load tasks.  To use the shared physical CPU,
                        each VM must be configured with a shared vCPU ID. For more information, see
                            <xref href="jow1426625051841.xml" />.</p>
                    <p >All other cores are automatically available for allocation to virtual machine
            threads.</p>
                </dd>
            </dlentry>
        </dl>
<!--        <section id="section_N100DD_N10029_N10001" >
            <title >CPU Topology From the CLI</title>
            <p >You can use the <cmdname >vm-topology</cmdname>
                command from the CLI on the controller nodes to explore the enumeration of sockets,
                cores, and logical processors on a compute node. The command can be executed without
                root privileges or Keystone authentication. Here is an example:</p>
            <codeblock ><systemoutput >$ </systemoutput><userinput >vm-topology -s topology</userinput><systemoutput >
compute-1:  Model:SandyBridge, Arch:x86_64, Vendor:Intel, Sockets=2, Cores/Socket=12, Threads/Core=1
+-\-\-\-\-\-\-\-\-\-\-\-+-\-\-+-\-\-+-\-\-+... +-\-\-\-+-\-\-\-+-\-\-\-+-\-\-\-+... +-\-\-\-+
|     cpu_id | 0 | 1 | 2 |... | 11 | 12 | 13 | 14 |... | 23 |
+-\-\-\-\-\-\-\-\-\-\-\-+-\-\-+-\-\-+-\-\-+... +-\-\-\-+-\-\-\-+-\-\-\-+-\-\-\-+... +-\-\-\-+
|  socket_id | 0 | 0 | 0 |... |  0 |  1 |  1 |  1 |... |  1 |
|    core_id | 0 | 1 | 2 |... | 13 |  0 |  1 |  2 |... | 13 |
|  thread_id | 0 | 0 | 0 |... |  0 |  0 |  0 |  0 |... |  0 |
| sibling_id | - | - | - |... |  - |  - |  - |  - |... |  - |
+-\-\-\-\-\-\-\-\-\-\-\-+-\-\-+-\-\-+-\-\-+... +-\-\-\-+-\-\-\-+-\-\-\-+-\-\-\-+... +-\-\-\-+

compute-2:  Model:SandyBridge, Arch:x86_64, Vendor:Intel, Sockets=2, Cores/Socket=12, Threads/Core=2
+-\-\-\-\-\-\-\-\-\-\-\-+-\-\-\-+-\-\-\-+-\-\-\-+... +-\-\-\-+-\-\-\-+-\-\-\-+-\-\-\-+... +-\-\-\-+-\-\-\-+
|     cpu_id |  0 |  1 |  2 |... | 11 | 12 | 13 | 14 |... | 46 | 47 |
+-\-\-\-\-\-\-\-\-\-\-\-+-\-\-\-+-\-\-\-+-\-\-\-+... +-\-\-\-+-\-\-\-+-\-\-\-+-\-\-\-+... +-\-\-\-+-\-\-\-+
|  socket_id |  0 |  0 |  0 |... |  0 |  1 |  1 |  1 |... |  1 |  1 |
|    core_id |  0 |  1 |  2 |... | 13 |  0 |  1 |  2 |... | 12 | 13 |
|  thread_id |  0 |  0 |  0 |... |  0 |  0 |  0 |  0 |... |  1 |  1 |
| sibling_id | 24 | 25 | 26 |... | 35 | 36 | 37 | 38 |... | 22 | 23 |
+-\-\-\-\-\-\-\-\-\-\-\-+-\-\-\-+-\-\-\-+-\-\-\-+... +-\-\-\-+-\-\-\-+-\-\-\-+-\-\-\-+... +-\-\-\-+-\-\-\-+</systemoutput></codeblock>
            <p >The example shows two compute nodes, <codeph >compute-1</codeph> with two sockets, 12 cores per socket, and no
                Hyper-Threading (Threads/Core=1), and <codeph >compute-2</codeph> with two sockets, 12 cores per socket, and
                Hyper-Threading enabled with two logical processors per core (Threads/Core=2). The
                rows <codeph >cpu_id</codeph> and <codeph >sibling_id</codeph> on <codeph >compute-2</codeph> node show the hyperthread sibling processors; cores in
                this compute node can therefore be described by the sequence [0, 24] [1, 25] [2, 26]
                ... [46, 22] [47, 23].</p>
            <p >Use the command <cmdname >vm-topology -\-help</cmdname> to list other available options
                to include information about virtual machine flavors, instances (servers), server
                groups, and  migrations in progress.</p>
        </section>
-->    </body>
</topic>